<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Andrés Millán Muñoz" />
  <meta name="keywords" content="TFG, Raytracing, Ray tracing, Monte
Carlo, DGIIM" />
  <title>Raytracing (WIP name)</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="https://unpkg.com/bamboo.css/dist/light.min.css">
  <link rel="stylesheet" href="./headers/style.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Raytracing (WIP name)</h1>
<p class="author">Andrés Millán Muñoz</p>
</header>
<nav id="TOC" role="doc-toc">
<h2 id="toc-title">Tabla de contenidos</h2>
<ul>
<li><a href="#abstract">Abstract</a></li>
<li><a href="#dedicatoria">Dedicatoria</a></li>
<li><a href="#introducción">Introducción</a>
<ul>
<li><a href="#qué-es-ray-tracing">¿Qué es ray tracing?</a></li>
<li><a href="#vale-y-qué-vamos-a-hacer-entonces">Vale, ¿y qué vamos a
hacer entonces?</a></li>
</ul></li>
<li><a href="#notación">Notación</a></li>
<li><a href="#los-fundamentos">Los fundamentos</a>
<ul>
<li><a href="#eligiendo-direcciones">Eligiendo direcciones</a></li>
</ul></li>
<li><a href="#metodología-o-cómo-se-hizo-este-trabajo">Metodología; o
cómo se hizo este trabajo</a>
<ul>
<li><a href="#github">Github</a>
<ul>
<li><a href="#github-actions">Github Actions</a></li>
<li><a href="#github-projects">Github Projects</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
<h1 id="abstract">Abstract</h1>
<p>Se procederá a analizar los algoritmos modernos de visualización 3D
realista usando métodos de Monte-Carlo, y su implementación en hardware
gráfico moderno (GPUs) específicamente diseñadas para aceleración de
Ray-Tracing. Se diseñará e implementará un sistema software de síntesis
de imágenes realistas por path tracing y muestreo directo de fuentes de
luz, que haga uso del hardware gráfico, y se analizará su eficiencia en
tiempo en relación a la calidad de las imágenes y en comparación con una
implementación exclusivamente sobre CPU.</p>
<p>Se realizará una revisión bibliográfica de los métodos de Montecarlo
que se aplican de manera habitual para la visualización de imagenes 3D.
Se examinarán los puntos fuertes y débiles de cada una de las técnicas,
con el objetivo de minimizar el error en la recosntrucción de la imagen
sin que esto suponga un alto coste computacional. Se investigarán las
soluciones propuestas para el futuro del área.</p>
<hr>
<p><em>Translation. It’ll be left as is until there’s a definitive
abstract</em></p>
<h1 id="dedicatoria">Dedicatoria</h1>
<p><em>Aquí es donde me pongo ñoño</em></p>
<p>¡Parece que has llegado un poco pronto! Si lo has hecho
voluntariamente, ¡muchas gracias! Este proyecto debería estar finalizado
en verano de 2022.</p>
<p>Mientras tanto, actualizaré poco a poco el contenido. Si quieres ir
comprobando los progresos, puedes visitar <a
href="github.com/Asmilex/Raytracing">Asmilex/Raytracing</a> en Github
para ver el estado del desarrollo.</p>
<h1 id="introducción">Introducción</h1>
<p>Ser capaces de capturar un momento.</p>
<p>Desde siempre, este ha sido uno de los sueños de la humanidad. La
capacidad de retener lo que ven nuestros ojos comenzó con simples
pinturas ruprestres. Con el tiempo, el arte evolucionó, así como la
capacidad de retratar nuestra percepción con mayor fidelidad.</p>
<p>A inicios del siglo XVIII, se caputaron las primeras imágenes con una
cámara gracias a Nicéphore Niépce. Sería una imagen primitiva, claro;
pero era funcional. Gracias a la compañía Kodak, la fotografía se
extendió al consumidor rápidamente sobre 1890. Más tarde llegaría la
fotografía digital, la cual simplificaría muchos de los problemas de las
cámaras tradicionales.</p>
<p>Hablando de digital. Los ordenadores personales modernos nacieron
unos años más tarde. Los usuarios eran capaces de mostrar imágenes en
pantalla, que cambiaban bajo demanda. Y, entonces, nos hicimos una
pregunta…</p>
<p>¿Podríamos <strong>simular la vida real</strong> para mostrarla en
pantalla?</p>
<p>Como era de esperar, esto es complicado de lograr. Para conseguirlo,
hemos necesitado crear abstracciones de conceptos que nos resultan
naturales, como objetos, luces y seres vivos. <em>“Cosas”</em> que un
ordenador no entiende, y sin embargo, para nosotros
<em>funcionan</em>.</p>
<p>Así, nació la geometría, los puntos de luces, texturas, sombreados, y
otros elementos de un escenario digital. Pero, por muchas abstracciones
elegantes que tengamos, no nos basta. Necesitamos visualizarlas. Y como
podemos imaginarnos, esto es un proceso costoso.</p>
<p>La <strong>rasterización</strong> es el proceso mediante el cual
estos objetos tridimensionales se transforman en bidimensionales.
Proyectando acordemente el entorno a una cámara, conseguimos colorear un
pixel, de forma que represente lo que se ve en ese mundo.</p>
<p>[TODO insertar imagen rasterización. NOTE quizás debería extender un
poco más esta parte? Parece que se queda algo coja la explicación.]</p>
<p>Aunque esta técnica es bastante eficiente en términos de computación
y ha evolucionado mucho, rápidamente saturamos sus posibilidades.
Conceptos como <em>shadow maps</em>, <em>baked lightning</em>, o
<em>reflection cubemaps</em> intentan solventar lo que no es posible con
rasterización: preguntrarnos <em>qué es lo que se encuentra alrededor
nuestra</em>.</p>
<p>En parte, nos olvidamos de la intuitiva realidad, para centrarnos en
aquello computacionalmente viable.</p>
<p>Y, entonces, en 1960 el trazado de rayos con una simple idea
intuitiva .</p>
<h2 id="qué-es-ray-tracing">¿Qué es ray tracing?</h2>
<p>En resumidas cuentas, <em>ray tracing</em> (o trazado de rayos en
español), se basa en disparar fotones desde nuestras luces digitales y
hacerlos rebotar en la escena.</p>
<p>De esta forma, simulamos cómo se comporta la luz. Al impactar en un
objeto, sufre un cambio en su trayectoria. Este cambio origina nuevos
rayos, que vuelven a dispersarse por la escena. Estos nuevos rayos
dependerán de las propiedades del objeto con el que hayan impactado. Con
el tiempo necesario, lo que veremos desde nuestra cámara será una
representación fotorealista de lo que habita en ese universo.</p>
<p>Esta técnica, tan estúpidamente intuitiva, se ha hecho famosa por su
simpleza y su elegancia. <em>Pues claro</em> que la respuesta a
“<em>¿Cómo simulamos fielmente una imagen en un ordenador?</em>” es
“<em>Representando la luz de forma realista</em>”.</p>
<p>Aunque, quizás intuitiva no sea la palabra. Podemos llamarla
<em>natural</em>, eso sí. A fin de cuentas, fue a partir del siglo XVIII
cuando empezamos a entender que podíamos capturar la luz. Nuestros
antepasados tenían teorías, pero no podían explicar por qué
<em>veíamos</em> el mundo.</p>
<p>Ahora sí que sabemos cómo funciona. Entendiendo el por qué lo hace
nos permitirá programarlo. Y, resulta que funciona impresionantemente
bien.</p>
<p>Atrás se quedan los <em>hacks</em> necesarios para rasterización. Los
cubemaps no son esenciales para los reflejos, y no necesitamos cámaras
virtuales para calcular sombras. Ray tracing permite simular fácilmente
efectos como reflejos, refracción, desenfoque de movimiento, aberración
cromática… Incluso fenómenos físicos propios de las particulas y las
ondas.</p>
<blockquote>
<p>Espera. Si tan bueno es, ¿por qué no lo usamos en todos lados?</p>
</blockquote>
<p>Por desgracia, el elefante en la sala es el rendimiento. Como era de
esperar, disparar rayos a diestro y siniestro es costoso. <strong>Muy
costoso</strong>.</p>
<p>A diferencia del universo, nosotros no nos podemos permitir el lujo
de usar fotones de tamaño infinitesimal y dispersiones casi infinitas.
Nos pasaríamos una eternidad esperando. Y para ver una imagen en nuestra
pantalla necesitaremos estar vivos, claro.</p>
<p>Debemos evitar la fuerza bruta. Dado que la idea es tan elegante, la
respuesta no está en el <em>“qué”</em>, sino en el <em>“cómo”</em>. Si
<strong>disparamos y dispersamos rayos con cabeza</strong> seremos
capaces de obtener lo que buscamos en un tiempo razonable.</p>
<p>Hace unos años, al hablar de tiempo razonable, nos referiríamos a
horas. Quizás días. Producir un <em>frame</em> podría suponer una
cantidad de tiempo impensable para un ordenador de consumidor. Hoy en
día también ocurre esto, claro está. Pero la tecnología evoluciona.</p>
<p>Podemos bajarlo a milisegundos.</p>
<p>Hemos entrado en la era del <strong>real time ray
tracing</strong>.</p>
<h2 id="vale-y-qué-vamos-a-hacer-entonces">Vale, ¿y qué vamos a hacer
entonces?</h2>
<p>TODO hablar de los objetivos del trabajo.</p>
<hr>
<p>Referencias que pasar después:</p>
<ol type="1">
<li>https://www.wikiwand.com/en/History_of_photography#/1816_to_1833:_Ni%C3%A9pce’s_earliest_fixed_images</li>
<li>https://www.wikiwand.com/es/Kodak#/Historia</li>
<li>https://www.wikiwand.com/en/Computer#/Digital_computers</li>
<li>https://www.wikiwand.com/en/Rendering_(computer_graphics)#/Chronology_of_important_published_ideas</li>
<li>Ray tracing gems I (p 16), gems II.</li>
<li>https://blogs.nvidia.com/blog/2018/03/19/whats-difference-between-ray-tracing-rasterization/</li>
<li>https://www.wikiwand.com/en/Ray_tracing_(graphics)</li>
<li>https://sciencebehindpixar.org/pipeline/rendering#:~:text=They%20said%20it%20takes%20at,to%20render%20that%20many%20frames.</li>
<li></li>
</ol>
<h1 id="notación">Notación</h1>
<p>Antes de comenzar, asentemos la notación que utilizaremos.</p>
<p>Para denotar a los <strong>puntos</strong>, usaremos letras
mayúsculas como <span class="math inline">\(P\)</span> o <span
class="math inline">\(Q\)</span>. Los <strong>escalares</strong> vendrán
dados por letras minúsculas, como <span class="math inline">\(a\)</span>
o <span class="math inline">\(b\)</span>; mientras que los
<strong>vectores</strong> irán en letra minúscula negrita (p.e.: <span
class="math inline">\(\mathbf{v}\)</span> o <span
class="math inline">\(\mathbf{w}\)</span>). Además, serán vectores
columnas. Aquellos normalizados los representaremos con un gorrito:
<span class="math inline">\(\hat{\mathbf{v}} =
\frac{\mathbf{v}}{\Vert\mathbf{v}\Vert}\)</span>. Las
<strong>matrices</strong>, por otra parte, vendrán dadas por letra
mayúscula en negrita, como <span
class="math inline">\(\mathbf{M}\)</span>. También son columna.</p>
<p>El producto escalar vendrá dado por <span
class="math inline">\(\mathbf{v} \cdot \mathbf{w}\)</span>, y el
vectorial por <span class="math inline">\(\mathbf{v} \times
\mathbf{w}\)</span>.</p>
<p>La notación usada para las <strong>variables aleatorias</strong> será
la habitual: mayúsculas como <span class="math inline">\(X\)</span>. Su
valor esperado vendrá dado por <span
class="math inline">\(E\left[X\right]\)</span> y la varianza por <span
class="math inline">\(V\left[X\right]\)</span>.</p>
<blockquote>
<p>TODO: notación para las funciones de densidad y distribución. TODO:
acceso a componentes de un vector/matriz?</p>
</blockquote>
<h1 id="los-fundamentos">Los fundamentos</h1>
<p>Empecemos por definir lo que es un rayo.</p>
<p>Un rayo es una función <span class="math inline">\(P(t) = O +
tD\)</span>, donde <span class="math inline">\(O\)</span> es el origin,
<span class="math inline">\(D\)</span> la dirección, y <span
class="math inline">\(t \in \mathbb{R}\)</span>. Podemos considerarlo
una interpolación entre dos puntos en el espacio, donde <span
class="math inline">\(t\)</span> controla la posición en la que nos
encontramos.</p>
<p>Por ejemplo, si <span class="math inline">\(t = 0\)</span>,
obtendremos el origen. Si <span class="math inline">\(t = 1\)</span>,
obtendremos el punto correspondiente a la dirección. Usando valores
negativos vamos <em>hacia atrás</em>.</p>
<p><img src="./img/rayo.png" /></p>
<p>Dado que estos puntos estarán generalmente en <span
class="math inline">\(\mathbb{R}^3\)</span>, podemos escribirlo como</p>
<p><span class="math display">\[
P(t) = (O_x, O_y, O_z) + t (D_x, D_y, D_z)
\]</span></p>
<p>Estos rayos los <em>dispararemos</em> a través de una cámara virtual,
que estará enfocando a la escena. De esta forma, los haremos rebotar con
los objetos que se encuentren en el camino del rayo. A este proceso lo
llamaremos <strong>ray casting</strong>.</p>
<blockquote>
<p>TODO foto de cámara - pixel - rayo - objeto.</p>
</blockquote>
<p>Generalmente, nos quedaremos con el primer objeto que nos encontremos
en su camino. Aunque, a veces, nos interesará saber todos con los que se
encuentre.</p>
<p>Cuando un rayo impacta con un objeto, adquirirá parte de las
propiedades lumínicas del punto de impacto. Por ejemplo, cuánta luz
proporciona la lámpara que tiene encima la esfera de la figura
anterior.</p>
<p>Una vez recojamos la información que nos interese, aplicaremos otro
raycast desde el nuevo punto de impacto, escogiendo una nueva dirección
determinada. Esta dirección dependerá del tipo de material del objeto.
Y, de hecho, algunos serán capaces de invocar varios rayos.</p>
<p>Por ejemplo, los espejos reflejan la luz casi de forma perfecta;
mientras que otros elementos como el agua o el cristal reflejan
<em>y</em> refractan luz, así que necesitaremos generar dos nuevos
raycast.</p>
<p>Usando suficientes rayos obtendremos la imagen de la escena. A este
proceso de <strong>ray casting recursivo</strong> es lo que se conoce
como ray tracing.</p>
<p>Como este proceso puede continuar indefinidamente, tendremos que
controlar la profundidad de la recursión. A mayor profundidad, mayor
calidad de imagen; pero también, mayor tiempo de ejecución.</p>
<h2 id="eligiendo-direcciones">Eligiendo direcciones</h2>
<p>Una de las partes más importantes de ray tracing, y a la que quizás
dedicaremos más tiempo es a la elección de la dirección.</p>
<p>Hay varios factores que entran en juego a la hora de decidir qué
hacemos cuando impactamos una nueva geometría:</p>
<ol type="1">
<li><strong>¿Cómo es la superficie del material?</strong> A mayor
rugosidad, mayor aleatoriedad en la dirección. Por ejemplo, no es lo
mismo el asfalto de una carretera que una lámina de aluminio
impecable.</li>
<li><strong>¿Cómo de fiel es nuestra geometría?</strong> Queramos o no,
debemos</li>
</ol>
<h1 id="metodología-o-cómo-se-hizo-este-trabajo">Metodología; o cómo se
hizo este trabajo</h1>
<p>TODO - hablar de las fases de desarrollo. Interpretación propia de
Agile. Documentación y código desarrollado a la par, mediante issues.
Adaptación de los requisitos conforme se avanza. Beneficios de una
página web (seguramente debería ser su propia sección)</p>
<h2 id="github">Github</h2>
<p>TODO - Hablar de cómo se utiliza Github y sus tecnologías para
agrupar todo el trabajo. Hablar de la guía de estilos, y cómo los emojis
ayudan a identificar rápidamente secciones.</p>
<h3 id="github-actions">Github Actions</h3>
<p>TODO - Hablar de cómo se usa el sistema de integración continua para
construir la web y el pdf</p>
<h3 id="github-projects">Github Projects</h3>
<p>TODO - Hablar de cómo se gestiona el trabajo mediante issues,
recapitulados todos con Projects.</p>
</body>
</html>
