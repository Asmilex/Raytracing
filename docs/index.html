<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Andrés Millán Muñoz" />
  <meta name="keywords" content="TFG, Raytracing, Ray tracing, Monte
Carlo, DGIIM" />
  <title>Los fundamentos de Ray Tracing</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <link rel="stylesheet" href="https://unpkg.com/bamboo.css/dist/light.min.css">
  <link rel="stylesheet" href="./headers/style.css">
  <link rel="icon" type="image/x-icon" href="./img/favicon.svg">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script>
  
  <!-- pandoc-eqnos: equation style -->
  <style>
    .eqnos { display: inline-block; position: relative; width: 100%; }
    .eqnos br { display: none; }
    .eqnos-number { position: absolute; right: 0em; top: 50%; line-height: 0; }
  </style>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Los fundamentos de Ray Tracing</h1>
<p class="author">Andrés Millán Muñoz</p>
</header>
<nav id="TOC" role="doc-toc">
<h2 id="toc-title">Tabla de contenidos</h2>
<ul>
<li><a href="#abstract">Abstract</a></li>
<li><a href="#dedicatoria">Dedicatoria</a></li>
<li><a href="#introducción">Introducción</a>
<ul>
<li><a href="#qué-es-ray-tracing">¿Qué es ray tracing?</a></li>
<li><a href="#vale-y-qué-vamos-a-hacer-entonces">Vale, ¿y qué vamos a
hacer entonces?</a></li>
</ul></li>
<li><a href="#las-bases">Las bases</a>
<ul>
<li><a href="#eligiendo-direcciones">Eligiendo direcciones</a></li>
<li><a href="#intersecciones-rayo---objeto">Intersecciones rayo -
objeto</a>
<ul>
<li><a href="#superficies-implícitas">Superficies implícitas</a></li>
<li><a href="#superficies-paramétricas">Superficies
paramétricas</a></li>
<li><a href="#intersecciones-con-esferas">Intersecciones con
esferas</a></li>
<li><a href="#intersecciones-con-triángulos">Intersecciones con
triángulos</a></li>
</ul></li>
</ul></li>
<li><a href="#integración-de-monte-carlo">Integración de Monte Carlo</a>
<ul>
<li><a href="#repaso-de-probabilidad">Repaso de probabilidad</a>
<ul>
<li><a href="#variables-aleatorias-discretas">Variables aleatorias
discretas</a></li>
<li><a href="#variables-aleatorias-continuas">Variables aleatorias
continuas</a></li>
<li><a href="#esperanza-y-varianza-de-una-variable-aleatoria">Esperanza
y varianza de una variable aleatoria</a></li>
</ul></li>
<li><a href="#el-estimador-de-monte-carlo">El estimador de Monte
Carlo</a></li>
<li><a href="#escogiendo-puntos-aleatorios">Escogiendo puntos
aleatorios</a>
<ul>
<li><a href="#método-de-la-transformada-inversa">Método de la
transformada inversa</a></li>
<li><a href="#método-del-rechazo">Método del rechazo</a></li>
</ul></li>
<li><a href="#importance-sampling"><em>Importance sampling</em></a></li>
</ul></li>
<li><a href="#transporte-de-luz">Transporte de luz</a>
<ul>
<li><a href="#unidades-radiométricas-básicas">Unidades radiométricas
básicas</a>
<ul>
<li><a href="#potencia">Potencia</a></li>
<li><a href="#irradiancia">Irradiancia</a></li>
<li><a href="#ángulos-sólidos">Ángulos sólidos</a></li>
<li><a href="#intensidad-radiante">Intensidad radiante</a></li>
<li><a href="#radiancia">Radiancia</a></li>
</ul></li>
<li><a href="#integrales-radiométricas">Integrales radiométricas</a>
<ul>
<li><a href="#una-nueva-expresión-de-la-irradiancia-y-el-flujo">Una
nueva expresión de la irradiancia y el flujo</a></li>
<li><a href="#integrando-sobre-área">Integrando sobre área</a></li>
</ul></li>
<li><a
href="#dispersión-de-luz-las-familias-de-funciones-de-distribución-bidireccionales">Dispersión
de luz: las familias de funciones de distribución bidireccionales</a>
<ul>
<li><a
href="#la-función-de-distribución-de-reflectancia-bidireccional-brdf">La
función de distribución de reflectancia bidireccional (BRDF)</a></li>
<li><a
href="#la-función-de-distribución-de-transmitancia-bidireccional-btdf">La
función de distribución de transmitancia bidireccional (BTDF)</a></li>
<li><a
href="#juntando-la-brdf-y-la-btdf-en-la-función-de-distribución-de-dispersión-bidireccional">Juntando
la BRDF y la BTDF en La función de distribución de dispersión
bidireccional</a></li>
<li><a href="#reflectancia-hemisférica">Reflectancia
hemisférica</a></li>
<li><a href="#reflejos">Reflejos</a></li>
</ul></li>
<li><a href="#la-rendering-equation"><strong>La rendering
equation</strong></a></li>
</ul></li>
<li><a href="#construyamos-un-path-tracer">¡Construyamos un path
tracer!</a>
<ul>
<li><a href="#requisitos-de-real-time-ray-tracing">Requisitos de
<em>real time ray tracing</em></a>
<ul>
<li><a href="#arquitecturas-de-gráficas">Arquitecturas de
gráficas</a></li>
<li><a href="#frameworks-y-api-de-ray-tracing-en-tiempo-real">Frameworks
y API de ray tracing en tiempo real</a></li>
</ul></li>
<li><a href="#setup-del-proyecto">Setup del proyecto</a></li>
<li><a href="#compilación">Compilación</a></li>
<li><a href="#estructuras-de-aceleración">Estructuras de aceleración</a>
<ul>
<li><a href="#botom-level-acceleration-structure-blas">Botom-Level
Acceleration Structure (BLAS)</a></li>
<li><a href="#top-level-acceleration-structure-tlas">Top-Level
Acceleration Structure (TLAS)</a></li>
</ul></li>
<li><a href="#ray-tracing-pipeline">Ray tracing pipeline</a></li>
<li><a href="#shaders">Shaders</a>
<ul>
<li><a href="#shader-binding-table">Shader binding table</a></li>
<li><a href="#tipos-de-shaders">Tipos de shaders</a></li>
</ul></li>
<li><a href="#asmiray">Asmiray</a></li>
<li><a href="#transporte-de-luz-1">Transporte de luz</a>
<ul>
<li><a href="#materiales-y-objetos">Materiales y objetos</a></li>
</ul></li>
<li><a href="#fuentes-de-luz">Fuentes de luz</a>
<ul>
<li><a href="#point-lights-spotlights">Point lights +
spotlights</a></li>
<li><a href="#fuentes-de-área">Fuentes de área</a></li>
</ul></li>
</ul></li>
<li><a href="#análisis-de-rendimiento">Análisis de rendimiento</a></li>
<li><a href="#el-futuro-de-ray-tracing">El futuro de Ray
Tracing</a></li>
<li><a href="#metodología-de-trabajo">Metodología de trabajo</a>
<ul>
<li><a href="#influencias">Influencias</a></li>
<li><a href="#ciclos-de-desarrollo">Ciclos de desarrollo</a></li>
<li><a href="#diseño">Diseño</a>
<ul>
<li><a href="#bases-del-diseño">Bases del diseño</a></li>
<li><a href="#tipografías">Tipografías</a></li>
<li><a href="#paleta-de-colores">Paleta de colores</a></li>
</ul></li>
<li><a href="#flujo-de-trabajo-y-herramientas">Flujo de trabajo y
herramientas</a>
<ul>
<li><a href="#pandoc">Pandoc</a></li>
<li><a href="#figma">Figma</a></li>
<li><a href="#otros-programas">Otros programas</a></li>
</ul></li>
<li><a href="#github">Github</a>
<ul>
<li><a
href="#integración-continua-con-github-actions-y-github-pages">Integración
continua con Github Actions y Github Pages</a></li>
<li><a href="#issues-y-github-projects">Issues y Github
Projects</a></li>
<li><a href="#estilo-de-commits">Estilo de commits</a></li>
</ul></li>
</ul></li>
<li><a href="#glosario-de-términos">Glosario de términos</a>
<ul>
<li><a href="#notación">Notación</a></li>
<li><a href="#radiometría"><span>Radiometría</span></a></li>
</ul></li>
<li><a href="#bibliografía">Bibliografía</a></li>
</ul>
</nav>
<h1 class="unnumbered" id="abstract">Abstract</h1>
<p>Se procederá a analizar los algoritmos modernos de visualización 3D
realista usando métodos de Monte-Carlo, y su implementación en hardware
gráfico moderno (GPUs) específicamente diseñadas para aceleración de
Ray-Tracing. Se diseñará e implementará un sistema software de síntesis
de imágenes realistas por path tracing y muestreo directo de fuentes de
luz, que haga uso del hardware gráfico, y se analizará su eficiencia en
tiempo en relación a la calidad de las imágenes y en comparación con una
implementación exclusivamente sobre CPU.</p>
<p>Se realizará una revisión bibliográfica de los métodos de Montecarlo
que se aplican de manera habitual para la visualización de imagenes 3D.
Se examinarán los puntos fuertes y débiles de cada una de las técnicas,
con el objetivo de minimizar el error en la recosntrucción de la imagen
sin que esto suponga un alto coste computacional. Se investigarán las
soluciones propuestas para el futuro del área.</p>
<hr>
<p><em>Translation. It’ll be left as is until there’s a definitive
abstract</em></p>
<h1 class="unnumbered" id="dedicatoria">Dedicatoria</h1>
<p>¡Parece que has llegado un poco pronto! Si lo has hecho
voluntariamente, ¡muchas gracias! Este proyecto debería estar finalizado
en verano de 2022. Mientras tanto, actualizaré poco a poco el contenido.
Si quieres ir comprobando los progresos, puedes visitar <a
href="github.com/Asmilex/Raytracing">Asmilex/Raytracing</a> en Github
para ver el estado del desarrollo.</p>
<p>Aun así, hay mucha gente que me ha ayudado a sacar este proyecto
hacia delante.</p>
<p>Gracias, en primer lugar, a mi familia por permitirme acabar la
carrera. A Cristina, Jorge, Jose OC, Lucas, Mari, Marina y Sergio por
ayudarme con el contenido, feedback del desarrollo y guía de diseño.</p>
<h1 id="introducción">Introducción</h1>
<p>Ser capaces de capturar un momento.</p>
<p>Desde siempre, este ha sido uno de los sueños de la humanidad. La
capacidad de retener lo que ven nuestros ojos comenzó con simples
pinturas ruprestres. Con el tiempo, el arte evolucionó, así como la
capacidad de retratar nuestra percepción con mayor fidelidad.</p>
<p>A inicios del siglo XVIII, se caputaron las primeras imágenes con una
cámara gracias a Nicéphore Niépce. Sería una imagen primitiva, claro;
pero era funcional. Gracias a la compañía Kodak, la fotografía se
extendió al consumidor rápidamente sobre 1890. Más tarde llegaría la
fotografía digital, la cual simplificaría muchos de los problemas de las
cámaras tradicionales.</p>
<p>Hablando de digital. Los ordenadores personales modernos nacieron
unos años más tarde. Los usuarios eran capaces de mostrar imágenes en
pantalla, que cambiaban bajo demanda. Y, entonces, nos hicimos una
pregunta…</p>
<p>¿Podríamos <strong>simular la vida real</strong> para mostrarla en
pantalla?</p>
<p>Como era de esperar, esto es complicado de lograr. Para conseguirlo,
hemos necesitado crear abstracciones de conceptos que nos resultan
naturales, como objetos, luces y seres vivos. <em>“Cosas”</em> que un
ordenador no entiende, y sin embargo, para nosotros
<em>funcionan</em>.</p>
<p>Así, nació la geometría, los puntos de luces, texturas, sombreados, y
otros elementos de un escenario digital. Pero, por muchas abstracciones
elegantes que tengamos, no nos basta. Necesitamos visualizarlas. Y como
podemos imaginarnos, esto es un proceso costoso.</p>
<p>La <strong>rasterización</strong> es el proceso mediante el cual
estos objetos tridimensionales se transforman en bidimensionales.
Proyectando acordemente el entorno a una cámara, conseguimos colorear un
pixel, de forma que represente lo que se ve en ese mundo.</p>
<blockquote>
<p>TODO insertar imagen rasterización. NOTE ¿quizás debería extender un
poco más esta parte? Parece que se queda algo coja la explicación.</p>
</blockquote>
<p>Aunque esta técnica es bastante eficiente en términos de computación
y ha evolucionado mucho, rápidamente saturamos sus posibilidades.
Conceptos como <em>shadow maps</em>, <em>baked lightning</em>, o
<em>reflection cubemaps</em> intentan solventar lo que no es posible con
rasterización: preguntrarnos <em>qué es lo que se encuentra alrededor
nuestra</em>.</p>
<p>En parte, nos olvidamos de la intuitiva realidad, para centrarnos en
aquello computacionalmente viable.</p>
<p>Y, entonces, en 1960 el trazado de rayos con una simple idea
intuitiva.</p>
<h2 id="qué-es-ray-tracing">¿Qué es ray tracing?</h2>
<p>En resumidas cuentas, <em>ray tracing</em> (o trazado de rayos en
español), se basa en disparar fotones desde nuestras luces digitales y
hacerlos rebotar en la escena.</p>
<p>De esta forma, simulamos cómo se comporta la luz. Al impactar en un
objeto, sufre un cambio en su trayectoria. Este cambio origina nuevos
rayos, que vuelven a dispersarse por la escena. Estos nuevos rayos
dependerán de las propiedades del objeto con el que hayan impactado. Con
el tiempo necesario, lo que veremos desde nuestra cámara será una
representación fotorealista de lo que habita en ese universo.</p>
<p>Esta técnica, tan estúpidamente intuitiva, se ha hecho famosa por su
simpleza y su elegancia. <em>Pues claro</em> que la respuesta a
“<em>¿Cómo simulamos fielmente una imagen en un ordenador?</em>” es
“<em>Representando la luz de forma realista</em>”.</p>
<p>Aunque, quizás intuitiva no sea la palabra. Podemos llamarla
<em>natural</em>, eso sí. A fin de cuentas, fue a partir del siglo XVIII
cuando empezamos a entender que podíamos capturar la luz. Nuestros
antepasados tenían teorías, pero no podían explicar por qué
<em>veíamos</em> el mundo.</p>
<p>Ahora sí que sabemos cómo funciona. Entendiendo el por qué lo hace
nos permitirá programarlo. Y, resulta que funciona impresionantemente
bien.</p>
<p>Atrás se quedan los <em>hacks</em> necesarios para rasterización. Los
cubemaps no son esenciales para los reflejos, y no necesitamos cámaras
virtuales para calcular sombras. Ray tracing permite simular fácilmente
efectos como reflejos, refracción, desenfoque de movimiento, aberración
cromática… Incluso fenómenos físicos propios de las particulas y las
ondas.</p>
<blockquote>
<p>Espera. Si tan bueno es, ¿por qué no lo usamos en todos lados?</p>
</blockquote>
<p>Por desgracia, el elefante en la sala es el rendimiento. Como era de
esperar, disparar rayos a diestro y siniestro es costoso. <strong>Muy
costoso</strong>.</p>
<p>A diferencia del universo, nosotros no nos podemos permitir el lujo
de usar fotones de tamaño infinitesimal y dispersiones casi infinitas.
Nos pasaríamos una eternidad esperando. Y para ver una imagen en nuestra
pantalla necesitaremos estar vivos, claro.</p>
<p>Debemos evitar la fuerza bruta. Dado que la idea es tan elegante, la
respuesta no está en el <em>“qué”</em>, sino en el <em>“cómo”</em>. Si
<strong>disparamos y dispersamos rayos con cabeza</strong> seremos
capaces de obtener lo que buscamos en un tiempo razonable.</p>
<p>Hace unos años, al hablar de tiempo razonable, nos referiríamos a
horas. Quizás días. Producir un <em>frame</em> podría suponer una
cantidad de tiempo impensable para un ordenador de consumidor. Hoy en
día también ocurre esto, claro está. Pero la tecnología evoluciona.</p>
<p>Podemos bajarlo a milisegundos.</p>
<p>Hemos entrado en la era del <strong>real time ray
tracing</strong>.</p>
<h2 id="vale-y-qué-vamos-a-hacer-entonces">Vale, ¿y qué vamos a hacer
entonces?</h2>
<blockquote>
<p>TODO: WIP</p>
</blockquote>
<p>Estos son los objetivos del trabajo:</p>
<ul>
<li>Path tracer inspirado en Shirley’s <em>RT In One Weekend</em>
series.
<ul>
<li>Muestreo directo de fuentes de luz.</li>
<li>Comparativa de rendimiento en tiempo real <em>vs</em> offline
renderer.</li>
</ul></li>
<li>Métodos de Monte Carlo. Estudio del error producido por cada uno.
Comprobar cómo de “buena” es cada solución.</li>
<li>Futuro del área.</li>
</ul>
<hr>
<h2 class="unlisted unnumbered" id="referencias">Referencias</h2>
<p><span class="citation" data-cites="wikipedia-contributors-2022A">(<a
href="#ref-wikipedia-contributors-2022A" role="doc-biblioref">Wikipedia:
history of photography 2022</a>)</span>, <span class="citation"
data-cites="wikipedia-contributors-2022B">(<a
href="#ref-wikipedia-contributors-2022B" role="doc-biblioref">Wikipedia:
Kodak 2022</a>)</span>, <span class="citation"
data-cites="wikipedia-contributors-2022C">(<a
href="#ref-wikipedia-contributors-2022C" role="doc-biblioref">Wikipedia:
Computer 2022</a>)</span>, <span class="citation"
data-cites="wikipedia-contributors-2022D">(<a
href="#ref-wikipedia-contributors-2022D" role="doc-biblioref">Wikipedia:
rendering (computer graphics) 2022</a>)</span>, <span class="citation"
data-cites="caulfield-2020">(<a href="#ref-caulfield-2020"
role="doc-biblioref">Caulfield 2020</a>)</span>, <span class="citation"
data-cites="wikipedia-contributors-2022E">(<a
href="#ref-wikipedia-contributors-2022E" role="doc-biblioref">tracing
2022</a>)</span>, <span class="citation"
data-cites="unknown-author-no-date">(<a
href="#ref-unknown-author-no-date"
role="doc-biblioref"><span>“Rendering”</span> n.d.</a>)</span>, <span
class="citation" data-cites="Haines2019">(<a href="#ref-Haines2019"
role="doc-biblioref">Haines and Akenine-Möller 2019</a>)</span></p>
<ul>
<li>RT IOW series</li>
</ul>
<h1 id="las-bases">Las bases</h1>
<p>Empecemos por definir lo que es un rayo.</p>
<p>Un rayo es una función <span class="math inline">\(P(t) = O +
tD\)</span>, donde <span class="math inline">\(O\)</span> es el origin,
<span class="math inline">\(D\)</span> la dirección, y <span
class="math inline">\(t \in \mathbb{R}\)</span>. Podemos considerarlo
una interpolación entre dos puntos en el espacio, donde <span
class="math inline">\(t\)</span> controla la posición en la que nos
encontramos.</p>
<p>Por ejemplo, si <span class="math inline">\(t = 0\)</span>,
obtendremos el origen. Si <span class="math inline">\(t = 1\)</span>,
obtendremos el punto correspondiente a la dirección. Usando valores
negativos vamos <em>hacia atrás</em>.</p>
<figure>
<img src="./img/01/Rayo%20básico.png" data-margin="auto"
alt="El parámetro t nos permite controlar los puntos del rayo" />
<figcaption aria-hidden="true">El parámetro <span
class="math inline">\(t\)</span> nos permite controlar los puntos del
rayo</figcaption>
</figure>
<p>Dado que estos puntos estarán generalmente en <span
class="math inline">\(\mathbb{R}^3\)</span>, podemos escribirlo como</p>
<p><span class="math display">\[
P(t) = (O_x, O_y, O_z) + t (D_x, D_y, D_z)
\]</span></p>
<p>Estos rayos los <em>dispararemos</em> a través de una cámara virtual,
que estará enfocando a la escena. De esta forma, los haremos rebotar con
los objetos que se encuentren en el camino del rayo. A este proceso lo
llamaremos <strong>ray casting</strong>.</p>
<figure>
<img src="./img/01/Ray%20casting.png" alt="Diagrama de ray casting" />
<figcaption aria-hidden="true">Diagrama de ray casting</figcaption>
</figure>
<p>Generalmente, nos quedaremos con el primer objeto que nos encontremos
en su camino. Aunque, a veces, nos interesará saber todos con los que se
encuentre.</p>
<p>Cuando un rayo impacta con un objeto, adquirirá parte de las
propiedades lumínicas del punto de impacto. Por ejemplo, cuánta luz
proporciona la lámpara que tiene encima la esfera de la figura
anterior.</p>
<p>Una vez recojamos la información que nos interese, aplicaremos otro
raycast desde el nuevo punto de impacto, escogiendo una nueva dirección
determinada. Esta dirección dependerá del tipo de material del objeto.
Y, de hecho, algunos serán capaces de invocar varios rayos.</p>
<p>Por ejemplo, los espejos reflejan la luz casi de forma perfecta;
mientras que otros elementos como el agua o el cristal reflejan
<em>y</em> refractan luz, así que necesitaremos generar dos nuevos
raycast.</p>
<p>Usando suficientes rayos obtendremos la imagen de la escena. A este
proceso de <strong>ray casting recursivo</strong> es lo que se conoce
como ray tracing.</p>
<p>Como este proceso puede continuar indefinidamente, tendremos que
controlar la profundidad de la recursión. A mayor profundidad, mayor
calidad de imagen; pero también, mayor tiempo de ejecución.</p>
<h2 id="eligiendo-direcciones">Eligiendo direcciones</h2>
<p>Una de las partes más importantes de ray tracing, y a la que quizás
dedicaremos más tiempo, es a la elección de la dirección.</p>
<p>Hay varios factores que entran en juego a la hora de decidir qué
hacemos cuando impactamos con un nuevo objeto:</p>
<ol type="1">
<li><strong>¿Cómo es la superficie del material?</strong> A mayor
rugosidad, mayor aleatoriedad en la dirección. Por ejemplo, no es lo
mismo el asfalto de una carretera que una lámina de aluminio
impecable.</li>
<li><strong>¿Cómo de fiel es nuestra geometría?</strong></li>
<li><strong>¿Dónde se encuentran las luces en la escena?</strong>
Dependiendo de la posición, nos interesará muestrear la luz con mayor
influencia.</li>
</ol>
<p>Estas cuestiones las exploraremos a fondo en las siguientes
secciones.</p>
<h2 id="intersecciones-rayo---objeto">Intersecciones rayo - objeto</h2>
<p>Como dijimos al principio del capítulo, representaremos un rayo
como</p>
<p><span class="math display">\[
\begin{aligned}
P(t) &amp; = (O_x, O_y, O_z) + t (D_x, D_y, D_z) = \\
&amp; = (O_x + t D_x, O_y + t D_y, O_y + t D_z)
\end{aligned}
\]</span></p>
<p>Por ejemplo, tomando <span class="math inline">\(O = (1, 3, 2), D =
(1, 2, 1)\)</span>:</p>
<ul>
<li>Para <span class="math inline">\(t = 0\)</span>, <span
class="math inline">\(P(t) = (1, 3, 2)\)</span>.</li>
<li>Para <span class="math inline">\(t = 1\)</span>, <span
class="math inline">\(P(t) = (1, 3, 2) + (1, 2, 1) = (2, 5,
3)\)</span>.</li>
</ul>
<p>Nos resultará especialmente útil limitar los valores que puede tomar
<span class="math inline">\(t\)</span>. Restringiremos los posibles
puntos del dominio de forma que <span class="math inline">\(t \in
[t_{min}, t_{max})\)</span>, con <span class="math inline">\(t_{min}
&lt; t_{max}\)</span>. En general, nos interesará separarnos de las
superficies un pequeño pero no despreciable <span
class="math inline">\(\varepsilon\)</span> para evitar errores de
redondeo.</p>
<figure>
<img src="./img/01/Límites%20de%20un%20rayo.png"
alt="Separarnos un poquito del origen evitará errores de coma flotante" />
<figcaption aria-hidden="true">Separarnos un poquito del origen evitará
errores de coma flotante</figcaption>
</figure>
<p>Una de las principales cuestiones que debemos hacernos es saber
cuándo un rayo impacta con una superficie. Lo definiremos
analíticamente.</p>
<h3 id="superficies-implícitas">Superficies implícitas</h3>
<p>Generalmente, cuando hablemos de superficies, nos referiremos
superficies diferenciables <span class="citation"
data-cites="wikipedia-contributors-2022O">(<a
href="#ref-wikipedia-contributors-2022O" role="doc-biblioref">Wikipedia:
Differential geometry of surfaces 2022</a>)</span>, pues nos interesará
conocer el vector normal en cada punto.</p>
<p>Una superficie implícita es una superficie en un espacio euclidiano
definida como</p>
<p><span class="math display">\[
F(x, y, z) = 0
\]</span></p>
<p>Esta ecuación implícita define una serie de puntos del espacio <span
class="math inline">\(\mathbb{R}^3\)</span> que se encuentran en la
superficie.</p>
<p>Por ejemplo, la esfera se define como <span class="math inline">\(x^2
+ y^2 + z^2 - 1 = 0\)</span>.</p>
<p>Consideremos una superficie <span class="math inline">\(S\)</span> y
un punto regular de ella <span class="math inline">\(P\)</span>; es
decir, un punto tal que el gradiente de <span
class="math inline">\(F\)</span> en <span
class="math inline">\(P\)</span> no es 0. Se define el vector normal
<span class="math inline">\(\mathbf{n}\)</span> a la superficie en ese
punto como</p>
<p><span class="math display">\[
\mathbf{n} = \nabla F(P) = \left( \frac{\partial F(P)}{\partial x},
\frac{\partial F(P)}{\partial y}, \frac{\partial F(P)}{\partial z}\right
)
\]</span></p>
<blockquote>
<p>TODO: dibujo de la normal a una superficie.</p>
</blockquote>
<p>Dado un punto <span class="math inline">\(Q \in
\mathbb{R}^3\)</span>, queremos saber dónde interseca un rayo <span
class="math inline">\(P(t)\)</span>. Es decir, para qué <span
class="math inline">\(t\)</span> se cumple que <span
class="math inline">\(F(P(t)) = 0 \iff F(O + tD) = 0\)</span>.</p>
<p>Consideremos por ejemplo un plano, como en <span class="citation"
data-cites="ShirleyRRT">(<a href="#ref-ShirleyRRT"
role="doc-biblioref">Shirley and Morley 2003</a>)</span>. Para ello, nos
tomamos un punto <span class="math inline">\(Q_0\)</span> del plano y un
vector normal a la superficie <span
class="math inline">\(\mathbf{n}\)</span>.</p>
<p>La ecuación implícita del plano será</p>
<p><span class="math display">\[
F(Q) = (Q - Q_0) \cdot \mathbf{n} = 0
\]</span></p>
<p>Si pinchamos nuestro rayo en la ecuación,</p>
<p><span class="math display">\[
\begin{aligned}
F(P(t)) &amp; = (P(t) - Q_0) \cdot \mathbf{n} \\
        &amp; = (O + tD - Q_0) \cdot \mathbf{n} = 0 \\
\end{aligned}
\]</span></p>
<p>Resolviendo para <span class="math inline">\(t\)</span>, esto se da
si</p>
<p><span class="math display">\[
\begin{aligned}
O \cdot \mathbf{n} + tD \cdot \mathbf{n} - Q_0 \cdot \mathbf{n} &amp; =
0 &amp; \iff \\
tD \cdot \mathbf{n} &amp; = Q_0 \cdot \mathbf{n} - O \cdot \mathbf{n}
&amp; \iff \\
t &amp; = \frac{Q_0 \cdot \mathbf{n} - O \cdot \mathbf{n}}{D \cdot
\mathbf{n}}
\end{aligned}
\]</span></p>
<p>Es decir, hemos obtenido el único valor de <span
class="math inline">\(t\)</span> para el cual el rayo toca la
superficie.</p>
<p>Debemos tener en cuenta el caso para el cual <span
class="math inline">\(D \cdot \mathbf{n} = 0\)</span>. Esto solo se da
si la dirección y el vector normal a la superficie son paralelos.</p>
<blockquote>
<p>TODO: dibujo de dos rayos con un plano: uno corta a la superficie,
mientras que el otro es paralelo.</p>
</blockquote>
<h3 id="superficies-paramétricas">Superficies paramétricas</h3>
<p>Otra forma de definir una superficie en el espacio es mediante un
subconjunto <span class="math inline">\(D \subset \mathbb{R}^2\)</span>
y una serie de funciones, <span class="math inline">\(f, g, h: D
\rightarrow \mathbb{R}^3\)</span>, de forma que</p>
<p><span class="math display">\[
(x, y, z) = \left( f(u, v), g(u, v), h(u, v) \right) \\
\]</span></p>
<blockquote>
<p>En informática gráfica, hacemos algo similar cuando mapeamos una
textura a una superficie. Se conoce como UV mapping</p>
</blockquote>
<p>Demos un par de ejemplos de superficies paramétricas: - El grafo de
una función <span class="math inline">\(f: D \rightarrow
\mathbb{R}^3\)</span>, <span class="math display">\[
G(f) = \left\{(x, y, f(x, y)) \,\middle|\,  (x, y) \in D\right\}
\]</span> define una superficie diferenciable siempre que <span
class="math inline">\(f\)</span> también lo sea. - Usando coordenadas
esféricas <span class="math inline">\((r, \theta, \phi)\)</span>,
podemos parametrizar la esfera como <span class="math inline">\((x, y,
z) = (\cos\phi\sin\theta, \sin\phi\sin\theta, \cos\theta)\)</span></p>
<blockquote>
<p>TODO añadir imagen de coordenadas esféricas. U otro capítulo con
coordenadas.</p>
<p>NOTE: estoy usando (radial, polar, azimuthal). <span
class="math inline">\(\theta\)</span> corresponde con la apertura con
respecto a la vertical</p>
</blockquote>
<p>El vector normal <span class="math inline">\(\mathbf{n}\)</span> a la
superficie en un punto <span class="math inline">\((u, v)\)</span> del
dominio viene dado por</p>
<p><span class="math display">\[
\mathbf{n}(u, v) =
        \left( \frac{\partial f}{\partial u}, \frac{\partial g}{\partial
u}, \frac{\partial h}{\partial u} \right)
                \times
        \left( \frac{\partial f}{\partial v}, \frac{\partial g}{\partial
v}, \frac{\partial h}{\partial v} \right)
\]</span></p>
<p>Encontrar el punto de intersección de una superficie paramétrica con
un rayo es sencillo. Basta con encontrar aquellos puntos <span
class="math inline">\((u, v)\)</span> y <span
class="math inline">\(t\)</span> para los que</p>
<p><span class="math display">\[
\begin{aligned}
O_x + tD_x &amp; = f(u, v) \\
O_y + tD_y &amp; = g(u, v) \\
O_z + tD_z &amp; = h(u, v) \\
\end{aligned}
\]</span></p>
<p>Es posible que el rayo no impacte en ningún punto. En ese caso, el
sistema de ecuaciones no tendría solución. Otra posibilidad es que
intersequen en varios puntos.</p>
<h3 id="intersecciones-con-esferas">Intersecciones con esferas</h3>
<p>Estudiemos ahora cómo intersecan una esfera con nuestro rayo. Una
esfera de centro <span class="math inline">\(C\)</span> y radio <span
class="math inline">\(r\)</span> viene dada por aquellos puntos <span
class="math inline">\(P = (x, y, z)\)</span> que cumplen</p>
<p><span class="math display">\[
(P - C) \cdot (P - C) = r^2
\]</span></p>
<p>Podemos reescribir esta ecuación en términos de sus coordenadas para
obtener</p>
<p><span class="math display">\[
(x - C_x)^2 + (y - C_y)^2 + (z - C_z)^2 = r^2
\]</span></p>
<p>Veamos para qué valores de <span class="math inline">\(t\)</span> de
nuestro rayo se cumple esa ecuación:</p>
<p><span class="math display">\[
\begin{aligned}
(P(t) - C) \cdot (P(t) - C) &amp; = r^2 &amp; \iff \\
(O + tD - C) \cdot (O + tD - C) &amp; = r^2 &amp; \iff \\
\end{aligned}
\]</span></p>
<p>Aplicando las propiedades del producto escalar de la conmutatividad
(<span class="math inline">\(a \cdot b = b \cdot a\)</span>) y la
distributiva (<span class="math inline">\(a \cdot (b + c) = a \cdot b +
a \cdot c\)</span>), podemos escribir</p>
<p><span class="math display">\[
\begin{aligned}
((O - C) + tD) \cdot ((O - C) + tD) &amp; = r^2 &amp; \iff \\
(O - C)^2 + 2 \cdot (O - C) \cdot tD + (tD)^2 &amp; = r^2 &amp; \iff \\
D^2t^2 + 2 D \cdot (O - C)t + (O - C)^2 - r^2 &amp; = 0 &amp; \iff \\
\end{aligned}
\]</span></p>
<p>Así que tenemos una ecuación de segundo grado. Resolviéndola, nos
salen nuestros puntos de intersección:</p>
<p><span class="math display">\[
t = \frac{
    - D \cdot (O - C) \pm \sqrt{(D \cdot (O - C))^2 - 4 (D^2)((O - C)^2
- r^2)}
}{
    2 D^2
}
\]</span></p>
<p>Debemos distinguir tres casos, atiendiendo al valor que toma el
discriminante <span class="math inline">\(\Delta = \small{(D \cdot (O -
C))^2 - 4 (D^2)((O - C)^2 - r^2)}\)</span>:</p>
<ol type="1">
<li>Si <span class="math inline">\(\Delta &lt; 0\)</span>, <span
class="math inline">\(\sqrt{\Delta} \notin \mathbb{R}\)</span>, y el
rayo no impacta con la esfera</li>
<li>Si <span class="math inline">\(\Delta = 0\)</span>, el rayo impacta
en un punto, que toma el valor <span class="math inline">\(t = \frac{-D
\cdot (O - C)}{2 D \cdot D}\)</span>. Digamos que <em>pegaría</em> justo
en el borde.</li>
<li>Si <span class="math inline">\(\Delta &gt; 0\)</span>, existen dos
soluciones. En ese caso, el rayo atraviesa la esfera.</li>
</ol>
<figure>
<img src="./img/01/Intersección%20rayo%20-%20esfera.png"
alt="Puntos de intersección con una esfera." />
<figcaption aria-hidden="true">Puntos de intersección con una
esfera.</figcaption>
</figure>
<p>Para estos dos últimos, si consideramos <span
class="math inline">\(t_0\)</span> cualquier solución válida, el vector
normal resultante viene dado por</p>
<p><span class="math display">\[
\mathbf{n} = 2 (P(t_0) - C)
\]</span></p>
<p>o, normalizando,</p>
<p><span class="math display">\[
\hat{\mathbf{n}} = \frac{(P(t_0) - C)}{r}
\]</span></p>
<h3 id="intersecciones-con-triángulos">Intersecciones con
triángulos</h3>
<p>Este tipo de intersecciones serán las más útiles en nuestro path
tracer. Generalmente, nuestras geometrías estarán compuestas por mallas
de triángulos, así que conocer dónde impacta nuestro rayo será clave.
Empecemos por la base:</p>
<p>Un triángulo viene dado por tres puntos, <span
class="math inline">\(A, B\)</span>, y <span
class="math inline">\(C\)</span>; correspondientes a sus vértices. Para
evitar casos absurdos, supongamos que estos puntos son afinmente
independientes; es decir, que no están alineados.</p>
<h4 id="coordenadas-baricéntricas">Coordenadas baricéntricas</h4>
<p>Podemos describir los puntos contenidos en el plano que forman estos
vertices mediante <strong>coordenadas baricéntricas</strong>. Este
sistema de coordenadas expresa cada punto del plano como una combinación
convexa de los vértices. Es decir, que para cada punto <span
class="math inline">\(P\)</span> del triángulo existen <span
class="math inline">\(\alpha, \beta\)</span> y <span
class="math inline">\(\gamma\)</span> tales que <span
class="math inline">\(\alpha + \beta + \gamma = 1\)</span> y</p>
<p><span class="math display">\[
P = \alpha A + \beta B + \gamma C
\]</span></p>
<blockquote>
<p>TODO: triángulo con coordenadas baricéntricas.</p>
</blockquote>
<p>Debemos destacar que existen dos grados de libertad debido a la
restricción de que las coordenadas sumen 1.</p>
<p>Una propiedad de estas coordenadas que nos puede resultar útil es que
un punto <span class="math inline">\(P\)</span> está contenido en el
triángulo si y solo si <span class="math inline">\(0 &lt; \alpha, \beta,
\gamma &lt; 1\)</span>.</p>
<p>Esta propiedad y la restricción de que sumen 1 nos da una cierta
intuición de cómo funcionan. Podemos ver las coordenadas baricéntricas
como la contribución de los vértices a un punto <span
class="math inline">\(P\)</span>. Por ejemplo, si <span
class="math inline">\(\alpha = 0\)</span>, eso significa que el punto
viene dado por <span class="math inline">\(\beta B + \gamma C\)</span>;
es decir, una combinación lineal de <span
class="math inline">\(B\)</span> y <span
class="math inline">\(C\)</span>. Se encuentra en la recta que
generan.</p>
<p>Por proponer otro ejemplo, si alguna de las coordenadas fuera mayor
que 1, eso significaría que el punto estaría más allá del triángulo.</p>
<blockquote>
<p>TODO: dibujo con explicación de cómo funciona (libreta Shinrin -
Yoku)</p>
</blockquote>
<h4 id="calculando-la-intersección">Calculando la intersección</h4>
<p>Podemos eliminar una de las varibales escribiendo <span
class="math inline">\(\alpha = 1 - \beta - \gamma\)</span>, lo que nos
dice</p>
<p><span class="math display">\[
\begin{aligned}
P &amp; = (1 - \beta - \gamma) A + \beta B + \gamma C \\
  &amp; = A + (B - A) \beta + (C - A) \gamma
\end{aligned}
\]</span></p>
<p>bajo la restricción</p>
<p><span id="eq:beta_gamma" class="eqnos"><span class="math display">\[
\begin{aligned}
\beta + \gamma &amp; &lt; 1 \\
0 &amp; &lt; \beta          \\
0 &amp; &lt; \gamma
\end{aligned}
\]</span><span class="eqnos-number">(1)</span></span> </p>
<p>Un rayo <span class="math inline">\(P(t) = O + tD\)</span> impactará
en un punto del triángulo si se cumple</p>
<p><span class="math display">\[
P(t) = O + tD = A + (B - A) \beta + (C - A) \gamma
\]</span></p>
<p>cumpliendo [<a href="#eq:beta_gamma">1</a>]. Podemos expandir la
ecuación anterior en sus coordenadas para obtener</p>
<p><span class="math display">\[
\begin{aligned}
O_x + tD_x &amp; = A_x + (B_x - A_x) \beta + (C_x - A_x) \gamma \\
O_y + tD_y &amp; = A_y + (B_y - A_y) \beta + (C_y - A_y) \gamma \\
O_z + tD_z &amp; = A_z + (B_z - A_z) \beta + (C_z - A_z) \gamma \\
\end{aligned}
\]</span></p>
<p>Reordenamos:</p>
<p><span class="math display">\[
\begin{aligned}
(A_x - B_x) \beta + (A_x - C_x) \gamma+ tD_x &amp; = A_x - O_x \\
(A_y - B_y) \beta + (A_y - C_y) \gamma+ tD_y &amp; = A_y - O_y \\
(A_z - B_z) \beta + (A_z - C_z) \gamma+ tD_z &amp; = A_z - O_z
\end{aligned}
\]</span></p>
<p>Lo que nos permite escribir el sistema en forma de ecuación:</p>
<p><span class="math display">\[
\begin{pmatrix}
        A_x - B_x &amp; A_x - C_x &amp; D_x \\
        A_y - B_y &amp; A_y - C_y &amp; D_y \\
        A_z - B_z &amp; A_z - C_z &amp; D_z
\end{pmatrix}
\begin{pmatrix}
        \beta \\ \gamma \\ t
\end{pmatrix}
=
\begin{pmatrix}
        A_x - O_x \\ A_y - O_y \\ A_z - O_z
\end{pmatrix}
\]</span></p>
<p>Calcular rápidamente la solución a un sistema de ecuaciones lineales
es un problema habitual. En <span class="citation"
data-cites="ShirleyRRT">(<a href="#ref-ShirleyRRT"
role="doc-biblioref">Shirley and Morley 2003</a>)</span> se utiliza la
regla de Cramer para hacerlo, esperando que el compilador optimice las
variables intermedias creadas. Nosotros no nos tendremos que preocupar
de esto en particular, ya que el punto de impacto lo calculará la GPU
gracias a las herramientras aportadas por KHR <span class="citation"
data-cites="the-khronos-vulkan-working-group-2022">(<a
href="#ref-the-khronos-vulkan-working-group-2022"
role="doc-biblioref">The Khronos® Vulkan Working Group
2022</a>)</span>.</p>
<p>Para obtener el vector normal, podemos hacer el producto vectorial de
dos vectores que se encuentren en el plano del triángulo. Como, por
convención, los vértices se guardan en sentido antihorario visto desde
fuera del objeto, entonces</p>
<p><span class="math display">\[
\mathbf{n} = (B - A) \times (C - A)
\]</span></p>
<hr>
<h2 class="unlisted unnumbered" id="referencias-1">Referencias</h2>
<p><span class="citation" data-cites="wikipedia-contributors-2022F">(<a
href="#ref-wikipedia-contributors-2022F" role="doc-biblioref">Wikipedia:
Implicit surface 2022</a>)</span>, <span class="citation"
data-cites="wikipedia-contributors-2021A">(<a
href="#ref-wikipedia-contributors-2021A" role="doc-biblioref">Wikipedia:
Parametric surface 2021</a>)</span>, <span class="citation"
data-cites="wikipedia-contributors-2022G">(<a
href="#ref-wikipedia-contributors-2022G" role="doc-biblioref">Wikipedia:
Barycentric coordinate system 2022</a>)</span>, <span class="citation"
data-cites="Sarabia">(<a href="#ref-Sarabia" role="doc-biblioref">A.
Romero Sarabia 2021</a>)</span>, <span class="citation"
data-cites="wikipedia-contributors-2022O">(<a
href="#ref-wikipedia-contributors-2022O" role="doc-biblioref">Wikipedia:
Differential geometry of surfaces 2022</a>)</span></p>
<h1 id="integración-de-monte-carlo">Integración de Monte Carlo</h1>
<blockquote>
<p>TODO: este capítulo seguramente debería ir más tarde. De esa forma,
puedo introducir otros conceptos antes. De momento, se queda aquí.</p>
</blockquote>
<p>Una de las partes más importante de nuestro ray tracer es saber
calcular la cantidad de luz en un punto de la escena. Para ello,
necesitaríamos hallar la radianza en dicha posición mediante la
<em>rendering equation</em>. Sin embargo, es <em>muy</em> difícil
resolverla; tanto computacional como analíticamente. Por ello, debemos
atacar el problema desde otro punto de vista.</p>
<p>Las técnicas de Monte Carlo nos permitirán aproximar el valor que
toman las integrales mediante una estimación. Utilizando muestreo
aleatorio para evaluar puntos de una función, seremos capaces de obtener
un resultado suficientemente bueno.</p>
<p>Una de las propiedades que hacen interesantes a este tipo de métodos
es la <strong>independencia del ratio de convergencia y la
dimensionalidad del integrando</strong>. Sin embargo, conseguir un mejor
rendimiento tiene un precio a pagar. Dadas <span
class="math inline">\(n\)</span> muestras, la convergencia a la solución
correcta tiene un orden de <span
class="math inline">\(\mathcal{O}\left(n^{-1/2}\right) =
\mathcal{O}\left(\frac{1}{\sqrt{n}}\right)\)</span>. Es decir, para
reducir el error a la mitad, necesitaríamos 4 veces más muestras.</p>
<p>En este capítulo veremos el fundamento de la integración de Monte
Carlo, cómo muestrear distribuciones específicas y cómo afinar el
resultado final.</p>
<h2 id="repaso-de-probabilidad">Repaso de probabilidad</h2>
<p>Necesitaremos unas cuantas nociones de variable aleatoria para poder
entender la integración de Monte Carlo, así que vamos a hacer un breve
repaso.</p>
<p>Una <strong>variable aleatoria</strong> <span
class="math inline">\(X\)</span> (v.a.) es, esencialmente, una regla que
asigna un valor numérico a cada posibilidad de proceso de azar.
Formalmente, es una función definida en un espacio de probabilidad <span
class="math inline">\((\Omega, \mathcal{A}, P)\)</span> asociado a un
exprimento aleatorio:</p>
<p><span class="math display">\[
X: \Omega \rightarrow \mathbb{R}
\]</span></p>
<p>A <span class="math inline">\(\Omega\)</span> lo conocemos como
espacio muestral (conjunto de todas las posibilidades), <span
class="math inline">\(\mathcal{A}\)</span> es una <span
class="math inline">\(\sigma\)</span>-álgebra de subconjuntos de <span
class="math inline">\(\Omega\)</span> que refleja todas las
posibilidades de eventos aleatorios, y <span
class="math inline">\(P\)</span> es una función probabilidad, que asigna
a cada evento una probabilidad.</p>
<blockquote>
<p>NOTE: no sé hasta qué punto debería meterme en la definición formal
de variable aleatoria. Es una movida tremenda para poca cosa que
necesitamos. De momento, voy con lo más interesante.</p>
</blockquote>
<p>Una variable aleatoria <span class="math inline">\(X\)</span> puede
clasificarse en discreta o continua, dependiendo de cómo sea su rango
<span class="math inline">\(R_X = \left\{ x \in \mathbb{R} \,\middle|\,
\exists \omega \in \Omega : X(\omega) = x \right\}\)</span>:</p>
<h3 id="variables-aleatorias-discretas">Variables aleatorias
discretas</h3>
<p>Las v.a. discretas son aquellas cuyo rango es un conjunto
discreto.</p>
<p>Para comprender mejor cómo funcionan, pongamos un ejemplo:
Consideremos un experimento en el que lanzamos dos dados, anotando lo
que sale en cada uno. Los posibles valores que toman serán</p>
<p><span class="math display">\[
\begin{aligned}
\{ &amp; (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6),  \\
   &amp; (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6),  \\
   &amp; (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6),  \\
   &amp; (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6),  \\
   &amp; (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6),  \\
   &amp; (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)   \}
\end{aligned}
\]</span></p>
<p>Cada resultado tiene la misma probabilidad de ocurrir (claro está, si
el dado no está trucado). Como hay <span
class="math inline">\(36\)</span> posibilidades, la probabilidad de
obtener un cierto valor es de <span
class="math inline">\(\frac{1}{36}\)</span>.</p>
<p>La v.a. <span class="math inline">\(X\)</span> denotará la suma de
los valores obtenidos en cada uno. Así, por ejemplo, si al lanzar los
dados hemos obtenido <span class="math inline">\((1, 3)\)</span>, <span
class="math inline">\(X\)</span> tomará el valor <span
class="math inline">\(4\)</span>. En total, <span
class="math inline">\(X\)</span> puede tomar todos los valores
comprendidos entre <span class="math inline">\(2\)</span> y <span
class="math inline">\(12\)</span>. Este sería el <strong>espacio
muestral</strong>. Cada pareja no está asociada a un único valor de
<span class="math inline">\(X\)</span>. Por ejemplo, <span
class="math inline">\((1, 2)\)</span> suma lo mismo que <span
class="math inline">\((2, 1)\)</span>. Esto nos lleva a preguntarnos…
¿Cuál es la probabilidad de que <span class="math inline">\(X\)</span>
adquiera un cierto valor?</p>
<p>La <strong>función masa de probabilidad</strong> nos permite conocer
la probabilidad de que <span class="math inline">\(X\)</span> tome un
cierto valor <span class="math inline">\(x\)</span>. Se denota por <span
class="math inline">\(P(X = x)\)</span>.</p>
<p>En este ejemplo, la probabilidad de que <span
class="math inline">\(X\)</span> tome el valor <span
class="math inline">\(4\)</span> es</p>
<p><span class="math display">\[
\begin{aligned}
P(X = 4) &amp; = \sum{\small{\text{nº parejas que suman 4}} \cdot
\small{\text{probabilidad de que salga la pareja}}} \\
         &amp; = 3 \cdot \frac{1}{36} = \frac{1}{12}
\end{aligned}
\]</span></p>
<p>Las parejas serían <span class="math inline">\((1, 3), (2,
2)\)</span> y <span class="math inline">\((3, 1)\)</span>.</p>
<p>Por definición, si el espacio muestral de <span
class="math inline">\(X\)</span> es <span class="math inline">\(\Omega =
\{x_1, \dots, x_n\}\)</span>, la función masa de probabilidad debe
cumplir que</p>
<p><span class="math display">\[
\sum_{i = 1}^{n}{P(X = x_i)} = 1
\]</span></p>
<p>Muchas veces nos interesará conocer la probabilidad de que <span
class="math inline">\(X\)</span> se quede por debajo de un cierto valor
<span class="math inline">\(x\)</span> (de hecho, podemos caracterizar
distribuciones aleatorias gracias a esto). Para ello, usamos la
<strong>función de distribución</strong>:</p>
<p><span class="math display">\[
F_X(x) = P(X \le x) = \sum_{\substack{k \in \Omega \\ k \le x}}{P(X =
k)}
\]</span></p>
<p>Es una función continua por la derecha y monótona no decreciente.
Además, se cumple que <span class="math inline">\(0 \le F_X \le
1(x)\)</span> y <span class="math inline">\(\lim_{x \to -\infty}{F_X} =
0\)</span>, <span class="math inline">\(\lim_{x \to \infty}{F_X} =
1\)</span>.</p>
<p>En nuestro ejemplo, si consideramos <span class="math inline">\(x =
3\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
F_X(x) &amp; = \sum_{i = 1}^{3}{P(X = i)} = P(X = 1) + P(X = 2) + P(X =
3) \\
       &amp; = \frac{1}{36} + \frac{2}{36} + \frac{3}{36} = \frac{1}{12}
\end{aligned}
\]</span></p>
<h3 id="variables-aleatorias-continuas">Variables aleatorias
continuas</h3>
<p>Este tipo de variables aleatorias tienen un rango no numerable; es
decir, el conjunto de valores que puede tomar abarca un intervalo de
números.</p>
<p>Un ejemplo podría ser la altura de una persona.</p>
<p>Si en las variables aleatorias discretas teníamos funciones masa de
probabilidad, aquí definiremos las <strong>funciones de densidad de
probabilidad</strong> (o simplemente, funciones de densidad). La idea es
la misma: nos permite conocer la probabilidad de que nuestra variable
aleatoria tome un cierto valor del espacio muestral.</p>
<p>Es importante mencionar que, aunque <em>la probabilidad de que la
variable aleatoria tome un valor específico</em> es <span
class="math inline">\(0\)</span>, ya que nos encontramos en un conjunto
no numerable, sí que podemos calcular la probabilidad de que se
encuentre entre dos valores. Por tanto, si la función de densidad es
<span class="math inline">\(f_X\)</span>, entonces</p>
<p><span class="math display">\[
P(a \le X \le b) = \int_{a}^{b}{f_X(x)dx}
\]</span></p>
<p>La función de densidad tiene dos características importantes:</p>
<ol type="1">
<li><span class="math inline">\(f_X\)</span> es no negativa; esto es,
<span class="math inline">\(f_X(x) \ge 0\ \forall x \in
\Omega\)</span></li>
<li><span class="math inline">\(f_X\)</span> integra uno en todo el
espacio muestral:</li>
</ol>
<p><span class="math display">\[
\int_{\Omega}{f_X(x)} = 1
\]</span></p>
<p>Intuitivamente, podemos ver esta última propiedad como <em>si
acumulamos todos los valores que puede tomar la variable aleatoria, la
probabilidad de que te encuentres en el conjunto debe ser 1</em>. Si
tratamos con un conjunto de números reales, podemos escribir la integral
como <span class="math inline">\(\int_{-\infty}^{\infty}{f_X(x)} =
1\)</span>.</p>
<p>Una de las variables aleatorias que más juego nos darán en el futuro
será la <strong>v.a. con distribución uniforme en <span
class="math inline">\([0, 1)\)</span></strong>. La denotaremos como
<span class="math inline">\(\xi\)</span>, y escribiremos <span
class="math inline">\(\xi \sim U\left([0, 1)\right)\)</span>. La
probabilidad de que <span class="math inline">\(\xi\)</span> tome un
valor es constante, por lo que podemos definir su función de densidad
como</p>
<p><span class="math display">\[
f(\xi) = \left\{  \begin{array}{llc}
                  1 &amp; \text{si } \xi \in [0, 1) \\
                  0 &amp; \text{en otro caso.}
                  \end{array}
         \right.
\]</span></p>
<p>La probabilidad de <span class="math inline">\(\xi\)</span> tome un
valor entre dos elementos <span class="math inline">\(a, b \in [0,
1)\)</span> es</p>
<p><span class="math display">\[
P(\xi \in [a, b]) = \int_{a}^{b}{1dx} = b - a
\]</span></p>
<p>Como veremos más adelante, definiendo correctamente una función de
densidad conseguiremos mejorar el rendimiento del path tracer.</p>
<p>La función de distribución <span
class="math inline">\(F_X(x)\)</span> podemos definirla como:</p>
<p><span class="math display">\[
F_X(x) = P(X \le x) = \int_{-\infty}^{x}{f_X(t)dt}
\]</span></p>
<p>Es decir, dado un <span class="math inline">\(x\)</span>, ¿cuál sería
la probabilidad de que <span class="math inline">\(X\)</span> se quede
por debajo de <span class="math inline">\(x\)</span>?</p>
<p>El Teorema Fundamental del Cálculo nos permite relacionar función de
distribución y función de densidad directamente:</p>
<p><span class="math display">\[
f_X(x) = \frac{dF_X(x)}{dx}
\]</span></p>
<h3 id="esperanza-y-varianza-de-una-variable-aleatoria">Esperanza y
varianza de una variable aleatoria</h3>
<p>La <strong>esperanza de una variable aleatoria</strong>, denotada
<span class="math inline">\(E[X]\)</span>, es una generalización de la
media ponderada. Nos informa del <em>valor esperado</em> de dicha
variable aleatoria.</p>
<p>En el caso de las variables discretas, se define como</p>
<p><span class="math display">\[
E[X] = \sum_{x_i \in \Omega}{x_i p_i}
\]</span></p>
<p>donde <span class="math inline">\(x_i\)</span> son los posibles
valores que puede tomar la v.a., y <span
class="math inline">\(p_i\)</span> la probabilidad asociada a cada uno
de ellos; es decir, <span class="math inline">\(p_i = P[X =
x_i]\)</span></p>
<p>Para una variable aleatoria continua real, la esperanza viene dada
por</p>
<p><span class="math display">\[
E[X] = \int_{-\infty}^{\infty}{x f_X(x) dx}
\]</span></p>
<p>aunque, generalizando a una v.a. con espacio muestral <span
class="math inline">\(\Omega\)</span>, la esperanza se puede generalizar
como</p>
<p><span class="math display">\[
E[X] = \int_{\Omega}{x f_X(x) dx}
\]</span></p>
<p>Pongamos un par de ejemplos del cálculo de la esperanza. En el <a
href="#variables-aleatorias-discretas">ejemplo de las variables
discretas</a>, la esperanza venía dada por</p>
<p><span class="math display">\[
E[X] = \sum_{i = 2}^{12}{i \cdot P[X = i]} = 2 \cdot \frac{1}{36} + 3
\cdot \frac{2}{36} + \dots + 12 \cdot \frac{1}{36} = 7
\]</span></p>
<p>Para variables aleatorias uniformes en <span
class="math inline">\((a, b)\)</span> (es decir, <span
class="math inline">\(X \sim U(a, b)\)</span>), la esperanza es</p>
<p><span class="math display">\[
E[X] = \int_{a}^{b}{x \cdot \frac{1}{b - a}dx} = \frac{a + b}{2}
\]</span></p>
<p>La esperanza tiene unas cuantas propiedades que nos resultarán muy
útiles. Estas son:</p>
<ul>
<li><strong>Linealidad</strong>:
<ul>
<li>Si <span class="math inline">\(X, Y\)</span> son dos v.a., <span
class="math inline">\(E[X + Y] = E[X] + E[Y]\)</span></li>
<li>Si <span class="math inline">\(a\)</span> es una constante, <span
class="math inline">\(X\)</span> una v.a., entonces <span
class="math inline">\(E[aX] = aE[X]\)</span></li>
<li>Análogamente, para ciertas <span class="math inline">\(X_1, \dots,
X_k\)</span>, <span class="math inline">\(E\left[\sum_{i =
1}^{k}{X_i}\right] = \sum_{i = 1}^{k}{E[X_i]}\)</span></li>
<li>Estas propiedades no necesitan que las variables aleatorias sean
independientes. Este hecho será clave para las técnicas de Monte
Carlo.</li>
</ul></li>
<li>La <strong>Ley del estadístico insconciente</strong> (<em>Law of the
unconscious statistician</em>, o LOTUS): dada una variable aleatoria
<span class="math inline">\(X\)</span> y una función medible <span
class="math inline">\(g\)</span>, la esperanza de <span
class="math inline">\(g(X)\)</span> se puede calcular como</li>
</ul>
<p><span class="math display">\[
E[g(X)] = \int_{\Omega}{g(x) f_X(x) dx}
\]</span></p>
<p><strong>Esta propiedad será clave en nuestro desarrollo</strong>.</p>
<p>Será habitual encontrarnos con el problema de que no conocemos la
distribución de una variable aleatoria <span
class="math inline">\(Y\)</span>. Sin embargo, si encontramos una
transformación medible de una variable aleatoria <span
class="math inline">\(X\)</span> de forma que obtengamos <span
class="math inline">\(Y\)</span> (esto es, <span
class="math inline">\(\exists g\)</span> función medible tal que <span
class="math inline">\(g(X) = Y\)</span>), entonces podemos calcular la
esperanza de <span class="math inline">\(Y\)</span> fácilmente. Esta
propiedad hará que las variables aleatorias con distribución uniforme
adquieran muchísima importancia. Generar números aleatorios en <span
class="math inline">\([0, 1)\)</span> es muy fácil, así <a
href="#método-de-la-transformada-inversa">que obtendremos otras v.a.s a
partir de <span class="math inline">\(\xi\)</span></a>.</p>
<p>Otra medida muy útil de una variable aleatoria es <strong>la
varianza</strong>. Nos permitirá medir cómo de dispersa es la
distribución con respecto a su media. La denotaremos como <span
class="math inline">\(Var[X]\)</span>, y se define como</p>
<p><span class="math display">\[
Var[X] = E\left[(X - E[X])^2\right]
\]</span></p>
<p>Si desarrollamos esta definición, podemos conseguir una expresión
algo más agradable:</p>
<p><span class="math display">\[
\begin{aligned}
   Var[X] &amp; = E\left[(X - E[X])^2\right] = \\
          &amp; = E\left[X^2 + E[X]^2 - 2XE[X]\right] = \\
          &amp; = E\left[X^2\right] + E[X]^2 - 2E[X]E[X] = \\
          &amp; = E\left[X^2\right] - E\left[X\right]^2
\end{aligned}
\]</span></p>
<p>Hemos usado que <span class="math inline">\(E[E[X]] = E[X]\)</span> y
la linealidad de la esperanza.</p>
<p>Enunciemos un par de propiedades que tiene, similares a la de la
esperanza:</p>
<ul>
<li>La varianza saca constantes al cuadrado: <span
class="math inline">\(Var[aX] = a^2Var[X]\)</span></li>
<li><span class="math inline">\(Var[X + Y] =\)</span> <span
class="math inline">\(Var[X] + Var[Y] + 2Cov[X, Y]\)</span>, donde <span
class="math inline">\(Cov[X, Y]\)</span> es la covarianza de <span
class="math inline">\(X\)</span> y <span
class="math inline">\(Y\)</span>.
<ul>
<li>En el caso en el que <span class="math inline">\(X\)</span> e <span
class="math inline">\(Y\)</span> sean incorreladas (es decir, la
covarianza es <span class="math inline">\(0\)</span>), <span
class="math inline">\(Var[X + Y] =\)</span> <span
class="math inline">\(Var[X] + Var[Y]\)</span>.</li>
</ul></li>
</ul>
<p>La varianza nos será útil a la hora de medir el error cometido por
una estimación de Monte Carlo.</p>
<h2 id="el-estimador-de-monte-carlo">El estimador de Monte Carlo</h2>
<p>Tras este breve repaso de probabilidad, estamos en condiciones de
definir el estimador de Monte Carlo. Primero, vamos con su versión más
sencilla.</p>
<p>Los estimadores de Monte Carlo nos permiten hallar la esperanza de
una variable aleatoria, digamos, <span class="math inline">\(Y\)</span>,
sin necesidad de calcular explícitamente su valor. Para ello, tomamos
unas cuantas muestras <span class="math inline">\(Y_1, \dots,
Y_N\)</span> que sigan la misma distribución que <span
class="math inline">\(Y\)</span> con media <span
class="math inline">\(\mu\)</span>. Entonces, consideramos el estimador
de <span class="math inline">\(\mu\)</span> <span class="citation"
data-cites="mcbook">(<a href="#ref-mcbook" role="doc-biblioref">Owen
2013</a>)</span>:</p>
<p><span id="eq:mc_simple" class="eqnos"><span class="math display">\[
\hat\mu_N = \frac{1}{N} \sum_{i = 1}^{N}{Y_i}
\]</span><span class="eqnos-number">(2)</span></span></p>
<p>Haciendo la esperanza de este estimador, vemos que</p>
<p><span class="math display">\[
\begin{aligned}
E[\hat\mu_N] &amp; = E\left[\frac{1}{N} \sum_{i = 1}^{N}{Y_i}\right] =
\frac{1}{N} E\left[\sum_{i = 1}^{N}{Y_i}\right] \\
             &amp; = \frac{1}{N} \sum_{i = 1}^{N}{E\left[Y_i\right]} =
\frac{1}{N} \sum_{i = 1}^{N}{\mu} = \\
             &amp; = \mu
\end{aligned}
\]</span></p>
<p>A este tipo de estimadores se les llama insesgados.</p>
<p>Generalmente nos encontraremos en la situación en la que <span
class="math inline">\(Y = f(X)\)</span>, donde <span
class="math inline">\(X\)</span> sigue una distribución con función de
densidad <span class="math inline">\(p_X(x)\)</span>, y <span
class="math inline">\(f: S \rightarrow \mathbb{R}\)</span>. En ese caso,
sabemos que la esperanza de <span class="math inline">\(Y\)</span> se
puede calcular como</p>
<p><span class="math display">\[
\mu = E[Y] = E[f(X)] = \int_{S}{f(x)p_X(x)dx}
\]</span></p>
<p>Lo que estamos buscando es calcular <span
class="math inline">\(\int_{S}{f(x)dx}\)</span>. Entonces, ¿qué ocurre
si intentamos compensar en [<a href="#eq:mc_simple">2</a>] con la
función de densidad?</p>
<p><span class="math display">\[
\begin{aligned}
&amp; E\left[\frac{1}{N} \sum_{i =
1}^{N}{\frac{f(X_i)}{p_X(X_i)}}\right] = \frac{1}{N} \sum_{i =
1}^{N}{E\left[\frac{f(X_i)}{p_X(X_i)}\right]} = \\
&amp; = \frac{1}{N} \sum_{i =
1}^{N}{\left(\int_{S}{\frac{f(x)}{p_X(x)}p_X(x)dx}\right)} = \\
&amp; = \frac{1}{N} N \int_{S}{f(x)dx} = \\
&amp; = \int_{S}{f(x)dx}
\end{aligned}
\]</span></p>
<p>¡Genial! Esto nos da una forma de calcular la integral de una función
usando muestras de variables aleatorias con cierta distribución.
Llamaremos al estimador de Monte Carlo</p>
<p><span id="eq:mc_integral" class="eqnos"><span class="math display">\[
\hat{F}_N = \frac{1}{N} \sum_{i = 1}^{N}{\frac{f(X_i)}{p_X(X_i)}}
\]</span><span class="eqnos-number">(3)</span></span></p>
<p>Es importante mencionar que <span
class="math inline">\(p_X(x)\)</span> debe ser distinto de 0 cuando
<span class="math inline">\(f\)</span> también lo sea.</p>
<p>Podemos particularizar el caso en el que nuestras muestras <span
class="math inline">\(X_i\)</span> sigan una distribución uniforme en
<span class="math inline">\([a, b]\)</span>. Si eso ocurre, su función
de densidad es <span class="math inline">\(p_X(x) = \frac{1}{b -
a}\)</span>, así que podemos simplificar un poco [<a
href="#eq:mc_integral">3</a>]:</p>
<p><span class="math display">\[
\hat{F}_N = \frac{b - a}{N} \sum_{i = 1}^{N}{f(X_i)}
\]</span></p>
<p>Elegir correctamente la función de densidad <span
class="math inline">\(p_X\)</span> será clave. Si conseguimos escogerla
debidamente, reduciremos mucho el error que genera el estimador. Esto es
lo que se conoce como <em>importance sampling</em>.</p>
<blockquote>
<p>TODO: añadir enlace al capítulo de importance sampling.</p>
</blockquote>
<p>Podemos calcular el error cuadrático medio de la estimación si
volvemos al estimador de la media <span
class="math inline">\(\hat\mu_N\)</span> [<a
href="#eq:mc_simple">2</a>]. Para ello, necesitamos la varianza: como
<span class="math inline">\(\hat\mu_N\)</span> es insesgado, tenemos
que</p>
<p><span class="math display">\[
\begin{aligned}
Var[\hat\mu_N] &amp; = Var\left[\frac{1}{N} \sum_{i = 1}^{N}{Y_i}\right]
= \frac{1}{N^2} Var\left[\sum_{i = 1}^{N}{Y_i}\right] = \\
               &amp; = \frac{1}{N^2} \sum_{i = 1}^{N}{Var[Y_i]} =
\frac{1}{N^2} N Var[Y] = \\
               &amp; = \frac{Var[Y]}{N}
\end{aligned}
\]</span></p>
<p>El error cuadrático medio es <span class="math display">\[
\sqrt{Var[\hat\mu_N]} = \sqrt{\frac{Var[Y]}{N}} =
\frac{\sqrt{Var[Y]}}{\sqrt{N}}
\]</span></p>
<p>así que, como adelantamos al inicio del capítulo, la estimación tiene
un error del orden <span
class="math inline">\(\mathcal{O}(N^{-1/2})\)</span>. Esto nos dice que,
para reducir el error a la mitad, debemos tomar 4 veces más
muestras.</p>
<p>Pongamos un ejemplo de estimador de Monte Carlo para una caja de
dimensiones <span class="math inline">\(\small{[x_0, x_1] \times [y_0,
y_1] \times [z_0, z_1]}\)</span>. Si queremos estimar la integral de la
función <span class="math inline">\(f: \mathbb{R}^3 \rightarrow
\mathbb{R}\)</span></p>
<p><span class="math display">\[
\int_{x_0}^{x_1} \int_{y_0}^{y_1} \int_{z_0}^{z_1}{f(x, y, z)dx dy dz}
\]</span></p>
<p>mediante una variable aleatoria <span class="math inline">\(X \sim
U(\small{[x_0, x_1] \times [y_0, y_1] \times [z_0, z_1]})\)</span> con
función de densidad <span class="math inline">\(p(x, y, z) =
\frac{1}{x_1 - x_0} \frac{1}{y_1 - y_0} \frac{1}{z_1 - z_0}\)</span>,
tomamos el estimador</p>
<p><span class="math display">\[
\hat{F}_N = \frac{1}{(x_1 - x_0) \cdot (y_1 - y_0) \cdot (z_1 - z_0)}
\sum_{i = 1}^{N}{f(X_i)}
\]</span></p>
<p>Otro ejemplo clásico de estimador de Monte Carlo es calcular el valor
de <span class="math inline">\(\pi\)</span>. Se puede hallar integrando
una función que valga <span class="math inline">\(1\)</span> en el
interior de la circunferencia de radio unidad y <span
class="math inline">\(0\)</span> en el exterior:</p>
<p><span class="math display">\[
\begin{aligned}
f = \begin{cases}
      1 &amp; \text{si } x^2 + y^2 \le 1 \\
      0 &amp; \text{en otro caso}
    \end{cases} \Longrightarrow \pi = \int_{-1}^{1} \int_{-1}^{1}{f(x,
y)}\ dxdy
\end{aligned}
\]</span></p>
<p>Para usar el estimador de [<a href="#eq:mc_integral">3</a>],
necesitamos saber la probabilidad de obtener un punto dentro de la
circunferencia.</p>
<p>Bien, consideremos que una circunferencia de radio <span
class="math inline">\(r\)</span> se encuentra inscrita en un cuadrado.
El área de la circunferencia es <span class="math inline">\(\pi
r^2\)</span>, mientras que la del cuadrado es <span
class="math inline">\((2r)^2 = 4r^2\)</span>. Por tanto, la probabilida
de obtener un punto dentro de la circunferencia es <span
class="math inline">\(\frac{\pi r^2}{4r^2} = \frac{\pi}{4}\)</span>.
Podemos tomar <span class="math inline">\(p(x, y) =
\frac{1}{4}\)</span>, de forma que</p>
<p><span class="math display">\[
\pi \approx \frac{4}{N} \sum_{i = 1}^{N}{f(x_i, y_i)}, \text{  con }
(x_i, y_i) \sim U(\small{[-1, 1] \times [-1, 1]})
\]</span></p>
<h2 id="escogiendo-puntos-aleatorios">Escogiendo puntos aleatorios</h2>
<p>Una de las partes clave del estimador de Monte Carlo [<a
href="#eq:mc_integral">3</a>] es saber escoger la función de densidad
<span class="math inline">\(p_X\)</span> correctamente. En esta sección,
veremos algunos métodos para conseguir distribuciones específicas
partiendo de funciones de densidad sencillas.</p>
<h3 id="método-de-la-transformada-inversa">Método de la transformada
inversa</h3>
<blockquote>
<p><strong>En resumen</strong>: Para conseguir una muestra de una
distribución específica <span class="math inline">\(F_X\)</span>:</p>
<ol type="1">
<li>Generar un número aleatorio <span class="math inline">\(\xi \sim
U(0, 1)\)</span>.</li>
<li>Hallar la inversa de la función de distribución deseada <span
class="math inline">\(F_X\)</span>, denotada <span
class="math inline">\(F_X^{-1}(x)\)</span>.</li>
<li>Calcular <span class="math inline">\(F_X^{-1}(\xi) =
X\)</span>.</li>
</ol>
</blockquote>
<p>Este método nos permite conseguir muestras de cualquier distribución
continua a partir de variables aleatorias uniformes, siempre que se
conozca la inversa de la función de distribución.</p>
<p>Sea <span class="math inline">\(X\)</span> una variable aleatoria con
función de distribución <span class="math inline">\(F_X\)</span><a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a>. Queremos buscar una transformación
<span class="math inline">\(T: [0, 1] \rightarrow \mathbb{R}\)</span>
tal que <span class="math inline">\(T(\xi) \stackrel{\text{\small d}}{=}
X\)</span>, siendo <span class="math inline">\(\xi\)</span> una v.a.
uniformemente distribuida. Para que esto se cumpla, se debe dar</p>
<p><span class="math display">\[
\begin{aligned}
F_X(x) &amp; = P[X &lt; x] = \\
       &amp; = P[T(\xi) &lt; x] = \\
       &amp; = P(\xi &lt; T^{-1}(x)) = \\
       &amp; = T^{-1}(x)
\end{aligned}
\]</span></p>
<p>Este último paso se debe a que, como <span
class="math inline">\(\xi\)</span> es uniforme en <span
class="math inline">\((0, 1)\)</span>, <span class="math inline">\(P[\xi
&lt; x] = x\)</span>. Es decir, hemos obtenido que <span
class="math inline">\(F_X\)</span> es la inversa de <span
class="math inline">\(T\)</span>.</p>
<blockquote>
<p>TODO: dibujo similar a <a
href="https://cs184.eecs.berkeley.edu/public/sp22/lectures/lec-12-monte-carlo-integration/lec-12-monte-carlo-integration.pdf">este:
p.52</a></p>
</blockquote>
<p>Como ejemplo, vamos a muestrear la función <span
class="math inline">\(f(x) = x^2,\ x \in [0, 2]\)</span>.</p>
<p>Primero, normalizamos esta función para obtener una función de
densidad <span class="math inline">\(p_X(x)\)</span>. Es decir, buscamos
<span class="math inline">\(p_X(x) = c f(x)\)</span> tal que</p>
<p><span class="math display">\[
\begin{aligned}
1 &amp; = \int_{0}^{2}{p_X(x)dx} = \int_{0}^{2}{c f(x)dx} = c
\int_{0}^{2}{f(x)dx} = \\
  &amp; = \left.\frac{cx^3}{3}\right\rvert_{2}^{3} = \frac{8c}{3} \\
  &amp; \Rightarrow c = \frac{3}{8} \\
  &amp; \Rightarrow p_X(x) = \frac{3x^2}{8}
\end{aligned}
\]</span></p>
<p>A continuación, integramos la función de densidad para obtener la de
distribución <span class="math inline">\(F_X\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
F_X(x) = \int_{0}^{x}{p_X(x)dx} = \int_{0}^{x}{\frac{3x^2}{8}} =
\frac{x^3}{8}
\end{aligned}
\]</span></p>
<p>Solo nos queda conseguir la muestra. Para ello,</p>
<p><span class="math display">\[
\begin{aligned}
\xi &amp; = F_X(x)  = \frac{x^3}{8} \iff \\
x &amp; = \sqrt[3]{8 \xi}
\end{aligned}
\]</span></p>
<p>Sacando un número aleatorio <span class="math inline">\(\xi\)</span>,
y pasándolo por la función obtenida, conseguimos un elemento con
distribución <span class="math inline">\(f(x)\)</span>.</p>
<h3 id="método-del-rechazo">Método del rechazo</h3>
<blockquote>
<p><strong>En resumen</strong>: Para conseguir una muestra de una
variable aleatoria <span class="math inline">\(X\)</span> con función de
densidad <span class="math inline">\(p_X\)</span>:</p>
<ol type="1">
<li>Obtener una muestra <span class="math inline">\(y\)</span> de <span
class="math inline">\(Y\)</span> , y otra <span
class="math inline">\(\xi\)</span> de <span class="math inline">\(U(0,
1)\)</span>.</li>
<li>Comprobar si <span class="math inline">\(\xi &lt;
\frac{p_X(y)}{Mp_Y(y)}\)</span>. Si es así, aceptarla. Si no, sacar otra
muestra.</li>
</ol>
</blockquote>
<p>El método anterior presenta principalmente dos problemas:</p>
<ol type="1">
<li>No siempre es posible integrar una función para hallar su función de
densidad.</li>
<li>La inversa de la función de distribución, <span
class="math inline">\(F_X^{-1}\)</span> no tiene por qué existir.</li>
</ol>
<p>Como alternativa, podemos usar este método (en inglés, <em>rejection
method</em>). Para ello, necesitamos una variable aleatoria <span
class="math inline">\(Y\)</span> con función de densidad <span
class="math inline">\(p_Y(y)\)</span>. El objetivo es conseguir una
muestra de <span class="math inline">\(X\)</span> con función de
densidad <span class="math inline">\(p_X(x)\)</span>.</p>
<p>La idea principal es aceptar una muestra de <span
class="math inline">\(Y\)</span> con probabilidad <span
class="math inline">\(p_X/Mp_Y\)</span>, con <span
class="math inline">\(1 &lt; M &lt; \infty\)</span>. En esencia, estamos
jugando a los dardos: si la muestra de <span
class="math inline">\(y\)</span> que hemos obtenido se queda por debajo
de la gráfica de la función <span class="math inline">\(Mp_Y &lt;
p_X\)</span>, estaremos obteniendo una de <span
class="math inline">\(p_X\)</span>.</p>
<blockquote>
<p>TODO dibujo de la gráfica <span
class="math inline">\(\frac{p_X(y)}{Mp_Y(y)}\)</span>.</p>
<p>¿Quizás haga falta una demostración también? No estoy satisfecho con
este apartado ahora mismo. Necesita trabajo.</p>
</blockquote>
<p>El algoritmo consiste en:</p>
<ol type="1">
<li>Obtener una muestra de <span class="math inline">\(Y\)</span>,
denotada <span class="math inline">\(y\)</span>, y otra de <span
class="math inline">\(U(0, 1)\)</span>, llamada <span
class="math inline">\(\xi\)</span>.</li>
<li>Comprobar si <span class="math inline">\(\xi &lt;
\frac{p_X(y)}{Mp_Y(y)}\)</span>.
<ol type="1">
<li>Si se cumple, se acepta <span class="math inline">\(y\)</span> como
muestra de <span class="math inline">\(p_X\)</span></li>
<li>En caso contrario, se rechaza <span class="math inline">\(y\)</span>
y se vuelve al paso 1.</li>
</ol></li>
</ol>
<h2 id="importance-sampling"><em>Importance sampling</em></h2>
<p>Con la llegada de ray tracing en tiempo real surge una obligación por
optimizar los pocos rayos que se pueden trazar. Una de las preguntas que
nos debemos hacer es <em>hacia dónde</em> generamos el rayo.</p>
<p>En esta sección daremos respuesta a este dilema. Estudiaremos cómo
las fuentes de luz afectan a la calidad de la imagen final. Veremos
técnicas de reducción del error, las cuales nos permitirán acelerar
enormemente el cómputo de la escena.</p>
<hr>
<h2 class="unlisted unnumbered" id="referencias-2">Referencias</h2>
<p><span class="citation" data-cites="wikipedia-contributors-2021B">(<a
href="#ref-wikipedia-contributors-2021B" role="doc-biblioref">Wikipedia:
Rendering equation 2021</a>)</span>, <span class="citation"
data-cites="wikipedia-contributors-2021C">(<a
href="#ref-wikipedia-contributors-2021C" role="doc-biblioref">Wikipedia:
Variable aleatoria 2021</a>)</span>, <span class="citation"
data-cites="wikipedia-contributors-2022H">(<a
href="#ref-wikipedia-contributors-2022H" role="doc-biblioref">Wikipedia:
Distribución de probabilidad 2022</a>)</span>, <span class="citation"
data-cites="wikipedia-contributors-2022I">(<a
href="#ref-wikipedia-contributors-2022I" role="doc-biblioref">Wikipedia:
Función de probabilidad 2022</a>)</span>, <span class="citation"
data-cites="wikipedia-contributors-2022J">(<a
href="#ref-wikipedia-contributors-2022J" role="doc-biblioref">Wikipedia:
Expected value 2022</a>)</span>, <span class="citation"
data-cites="galvin-no-date">(<a href="#ref-galvin-no-date"
role="doc-biblioref">Galvin n.d.</a>)</span>, <span class="citation"
data-cites="wikipedia-contributors-2022K">(<a
href="#ref-wikipedia-contributors-2022K" role="doc-biblioref">Wikipedia:
Probability density function 2022</a>)</span>, <span class="citation"
data-cites="wikipedia-contributors-2022L">(<a
href="#ref-wikipedia-contributors-2022L" role="doc-biblioref">Wikipedia:
Estimador 2022</a>)</span>, <span class="citation"
data-cites="wikipedia-contributors-2022M">(<a
href="#ref-wikipedia-contributors-2022M" role="doc-biblioref">Wikipedia:
Método de la transformada inversa 2022</a>)</span>, <span
class="citation" data-cites="wikipedia-contributors-2022N">(<a
href="#ref-wikipedia-contributors-2022N" role="doc-biblioref">Wikipedia:
Rejection sampling 2022</a>)</span>, <span class="citation"
data-cites="ShirleyRRT">(<a href="#ref-ShirleyRRT"
role="doc-biblioref">Shirley and Morley 2003</a>)</span>, <span
class="citation" data-cites="PBRT3e">(<a href="#ref-PBRT3e"
role="doc-biblioref">Pharr, Jakob, and Humphreys 2016</a>)</span>, <span
class="citation" data-cites="mcbook">(<a href="#ref-mcbook"
role="doc-biblioref">Owen 2013</a>)</span>, <span class="citation"
data-cites="berkeley-cs184">(<a href="#ref-berkeley-cs184"
role="doc-biblioref">Berkeley cs184 2022</a>, Monte Carlo
Integration)</span></p>
<ul>
<li><em>(berkeley-cs184)</em>
https://cs184.eecs.berkeley.edu/public/sp22/lectures/lec-12-monte-carlo-integration/lec-12-monte-carlo-integration.pdf</li>
<li>Gems I, p.284.</li>
</ul>
<h1 id="transporte-de-luz">Transporte de luz</h1>
<p>En este capítulo estudiaremos las bases de la radiometría. Esta área
de la óptica nos proporcionará una serie de herramientas con las cuales
podremos responder a la pregunta <em>cuánta luz existe en un
punto</em>.</p>
<h2 id="unidades-radiométricas-básicas">Unidades radiométricas
básicas</h2>
<blockquote>
<p><strong>Nota</strong>: cuando usemos un paréntesis tras una ecuación,
dentro denotaremos sus unidades de medida.</p>
</blockquote>
<p>Antes de comenzar a trabajar, necesitamos conocer <em>qué
entendemos</em> por luz. Aunque hay muchas formas de trabajar con ella
(a fin de cuentas, todavía seguimos discutiendo sobre <em>qué es</em>
exactamente la luz <a href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a>), nosotros nos quedaremos con
algunas pinceladas de la cuántica. Nos será suficiente quedarnos con la
concepción de fotón. Una fuente de iluminación emite una serie de
fotones. Estos fotones tienen<sup><span class="citation"
data-cites="ShirleyRRT">(<a href="#ref-ShirleyRRT"
role="doc-biblioref">Shirley and Morley 2003</a>)</span></sup> una
posición, una dirección de propagación y una longitud de onda <span
class="math inline">\(\lambda\)</span>. Un fotón también tiene asociado
una velocidad <span class="math inline">\(c\)</span> que depende del
índice de refracción del medio, <span
class="math inline">\(n\)</span>.</p>
<p>La unidad de medida de <span class="math inline">\(\lambda\)</span>
es el nanómetro (<span class="math inline">\(\text{nm}\)</span>).
También nos vendrá bien definir una frecuencia, <span
class="math inline">\(f\)</span>. Su utilidad viene del hecho de que,
cuando la luz cambia de medio al propagarse, la frecuencia se mantiene
constante.</p>
<p><span class="math display">\[
f = \frac{c}{\lambda}
\]</span></p>
<p>Un fotón tiene asociada una carga de energía, denotada por <span
class="math inline">\(Q\)</span>:</p>
<p><span class="math display">\[
Q = hf = \frac{hc}{\lambda} (\text{J})
\]</span></p>
<p>donde <span class="math inline">\(h = 6.62607004 \times 10^{-34}
\text{J} \cdot \text{s}\)</span> es la constante de Plank y <span
class="math inline">\(c = 299 792 458 \text{m/s}\)</span> la velocidad
de la luz.</p>
<p>En realidad, <strong>todas estas cantidades deberían tener un
subíndice <span class="math inline">\(\lambda\)</span></strong>, puesto
que dependen de la longitud de onda. La energía de un fotón <span
class="math inline">\(Q\)</span>, por ejemplo, debería denotarse <span
class="math inline">\(Q_\lambda\)</span>. Sin embargo, en la literatura
de informática gráfica, <strong>se ha optado por omitirla</strong>.
¡Tenlo en cuenta a partir de aquí!</p>
<h3 id="potencia">Potencia</h3>
<p>A partir de la energía anterior, podemos estimar <em>la tasa de
producción de energía</em>. A esta tasa la llamaremos<sup><span
class="citation" data-cites="PBRT3e">(<a href="#ref-PBRT3e"
role="doc-biblioref">Pharr, Jakob, and Humphreys 2016</a>)</span></sup>
<strong>potencia</strong>, o <strong>flujo radiante</strong> <span
class="math inline">\(\Phi\)</span>. Esta medida nos resultará más útil
que la energía total, puesto que nos permite estimar la energía en un
instante:</p>
<p><span class="math display">\[
\Phi = \lim_{\Delta t \to 0}{\frac{\Delta Q}{\Delta t}} = \frac{dQ}{dt}
(J/s)
\]</span></p>
<p>Su unidad es julios por segundo, comúnmente denotado vatio
(<em>watts</em>, <span class="math inline">\(\text{W}\)</span>). También
se utiliza el lumen. Podemos encontrar la energía total en un periodo de
tiempo <span class="math inline">\([t_0, t_1]\)</span> integrando el
flujo radiante:</p>
<p><span class="math display">\[
Q = \int_{t_0}^{t_1}{\Phi(t)dt}
\]</span></p>
<h3 id="irradiancia">Irradiancia</h3>
<p>La <strong>irradiancia</strong> o <strong>radiancia emitida</strong>
es el flujo radiante que recibe una superficie. Dada un área <span
class="math inline">\(A\)</span>, se define como</p>
<p><span class="math display">\[
E = \frac{\Phi}{A} (\text{W/m}^2)
\]</span></p>
<figure>
<img src="./img/03/Irradiancia.png"
alt="La irradiancia es la potencia por metro cuadrado incidente en una superficie. Es proporcional al coseno del ángulo entre la dirección de la luz y la normal a la superficie." />
<figcaption aria-hidden="true">La irradiancia es la potencia por metro
cuadrado incidente en una superficie. Es proporcional al coseno del
ángulo entre la dirección de la luz y la normal a la
superficie.</figcaption>
</figure>
<p>Ahora que tenemos la potencia emitida en una cierta área, nos surge
una pregunta: <em>¿y en un cierto punto <span
class="math inline">\(p\)</span>?</em>. Tomando límites en la expresión
anterior, encontramos la respuesta:</p>
<p><span class="math display">\[
E(p) = \lim_{\Delta A \to 0}{\frac{\Delta \Phi}{\Delta A}} =
\frac{d\Phi}{dA} (\text{W/m}^2)
\]</span></p>
<p>De la misma manera que con la potencia, integrando <span
class="math inline">\(E(p)\)</span> podemos obtener el flujo
radiante:</p>
<p><span class="math display">\[
\Phi = \int_{A}{E(p)dp}
\]</span></p>
<p>El principal problema de la irradiancia es que <em>no nos dice nada
sobre las direcciones</em> desde las que ha llegado la luz.</p>
<h3 id="ángulos-sólidos">Ángulos sólidos</h3>
<p>Con estas tres unidades básicas, nos surge una pregunta muy natural:
<em>¿cómo mido cuánta luz llega a una superficie?</em></p>
<p>Para responder a esta pregunta, necesitaremos los <strong>ángulos
sólidos</strong>. Son la extensión de los <strong>ángulos
planares</strong>, en dos dimensiones.</p>
<p>Ilustremos el sentido de estos ángulos: imaginemos que tenemos un
cierto objeto en dos dimensiones delante de nosotros, a una distancia
desconocida. ¿Sabríamos cuál es su tamaño, solo con esta información? Es
más, si entrara otro objeto en la escena, ¿podríamos distinguir cuál de
ellos es más grande?</p>
<p>Parece difícil responder a estas preguntas. Sin embargo, sí que
podemos determinar <em>cómo de grandes nos parecen</em> desde nuestro
punto de vista. Para ello, describimos una circunferencia de radio <span
class="math inline">\(r\)</span> alrededor nuestra. Si trazamos un par
de líneas desde nuestra posición a las partes más alejadas de este
objeto, y las cortamos con nuestra circunferencia, obtendremos un par de
puntos inscritos en ella. Pues bien, al arco que encapsulan dichos
puntos le vamos a hacer corresponder un cierto ángulo: el ángulo
planar.</p>
<figure>
<img src="./img/03/Ángulo%20planar.png"
alt="La idea intuitiva de un ángulo planar" />
<figcaption aria-hidden="true">La idea intuitiva de un ángulo
planar</figcaption>
</figure>
<p>Llevando esta idea a las tres dimensiones es como conseguimos el
concepto de <strong>ángulo sólido</strong>. Si en dos dimensiones
teníamos una circunferencia, aquí tendremos una esfera. Cuando generemos
las rectas proyectantes hacia el volumen, a diferencia de los ángulos
planares, se inscribirá un área en la esfera. La razón entre dicha área
<span class="math inline">\(A\)</span> y el cuadrado del radio <span
class="math inline">\(r\)</span> nos dará un ángulo sólido:</p>
<p><span class="math display">\[
\omega = \frac{A}{r^2} \text{(sr)}
\]</span></p>
<figure>
<img src="./img/03/Ángulo%20sólido.png"
alt="Un ángulo sólido es la razón entre el área proyectada y el cuadrado del radio" />
<figcaption aria-hidden="true">Un ángulo sólido es la razón entre el
área proyectada y el cuadrado del radio</figcaption>
</figure>
<p>Los denotaremos por <span class="math inline">\(\omega\)</span>. En
física se suele usar <span class="math inline">\(\Omega\)</span>, pero
aquí optaremos por la minúscula. Su unidad de medida es el
estereorradián (<span class="math inline">\(\text{sr}\)</span>). Se
tiene que <span class="math inline">\(\omega \in [0, 4\pi]\)</span>. Si
<span class="math inline">\(2 \pi\)</span> radianes corresponden a la
circunferencia completa, para la esfera se tiene que <span
class="math inline">\(4 \pi\)</span> esteorradianes cubren toda la
superficie de esta. Se tiene también que <span
class="math inline">\(2\pi \text{sr}\)</span> cubren un hemisferio.
Además, un esteorradián corresponde a una superficie con área <span
class="math inline">\(r^2\)</span>: <span class="math inline">\(1
\text{sr} = \frac{r^2}{r^2}\)</span>.</p>
<p>De vez en cuando, usaremos <span
class="math inline">\(\omega\)</span> <strong>un vector dirección
unitario en la esfera</strong>.</p>
<figure>
<img src="./img/03/xkcd_1276.png"
alt="Como de costumbre, hay un xkcd relevante. (Fuente)" />
<figcaption aria-hidden="true">Como de costumbre, hay un xkcd relevante.
<a href="https://xkcd.com/1276/">(Fuente)</a></figcaption>
</figure>
<p>Usualmente emplearemos coordenadas esféricas cuando trabajemos con
ellos, dado que resulta más cómodo.</p>
<p><span class="math display">\[
\begin{aligned}
    \begin{cases}
        x = \sin\theta\cos\theta \\
        y = \sin\theta\sin\theta \\
        z = \cos\theta
    \end{cases}
\end{aligned}
\]</span></p>
<p>A <span class="math inline">\(\theta\)</span> se le denomina ángulo
polar, mientras que a <span class="math inline">\(\phi\)</span> se le
llama acimut. Imaginémonos un punto en la esfera de radio <span
class="math inline">\(r\)</span> ubicado en una posición <span
class="math inline">\((r, \theta, \phi)\)</span>. Queremos calcular un
área chiquitita <span class="math inline">\(dA_h\)</span>, de forma que
el ángulo sólido asociado a dicha área debe ser <span
class="math inline">\(d\omega\)</span>. Así, <span
class="math inline">\(d\omega = \frac{dA_h}{r^2}\)</span>. Si
proyectamos el área, obtenemos <span
class="math inline">\(d\theta\)</span> y <span
class="math inline">\(d\phi\)</span>: pequeños cambios en los ángulos
que nos generan nuestra pequeña área.</p>
<p><span class="math inline">\(dA_h\)</span> debe tener dos lados <span
class="math inline">\(lado_1\)</span> y <span
class="math inline">\(lado_2\)</span>. Podemos hallar <span
class="math inline">\(lado_1\)</span> si lo trasladamos al eje <span
class="math inline">\(z\)</span> de nuevo. Así, <span
class="math inline">\(lado_1 = r \sin d\theta\)</span>. De la misma
manera, <span class="math inline">\(lado_2 = r d\theta\)</span>.</p>
<blockquote>
<p>TODO: foto que explique todo esto, porque si no, no hay quien se
entere. Quizás me sirva la de
https://cs184.eecs.berkeley.edu/public/sp22/lectures/lec-11-radiometry-and-photometry/lec-11-radiometry-and-photometry.pdf,
p.16 siempre que adapte <span class="math inline">\(\phi\)</span>.</p>
</blockquote>
<p>Poniendo estos valores en <span
class="math inline">\(d\omega\)</span>:</p>
<p><span id="eq:d_omega" class="eqnos"><span class="math display">\[
\begin{aligned}
d\omega &amp; = \frac{dA_h}{r^2} = \frac{lado_1 lado_2}{r^2} = \\
        &amp; = \frac{r \sin\theta\ d\phi\ r\ d\theta}{r^2} = \\
        &amp; = \sin\theta\ d\theta\ d\phi
\end{aligned}
\]</span><span class="eqnos-number">(4)</span></span></p>
<p>¡Genial! Acabamos de añadir un recurso muy potente a nuestro
inventario. Esta expresión nos permitirá convertir integrales sobre
ángulos sólidos en integrales sobre ángulos esféricos.</p>
<h3 id="intensidad-radiante">Intensidad radiante</h3>
<p>Los ángulos sólidos nos proporcionan una variedad de herramientas
nuevas considerable. Gracias a ellos, podemos desarrollar algunos
conceptos nuevos. Uno de ellos es la <strong>intensidad
radiante</strong>.</p>
<p>Imaginémonos un pequeñito punto de luz encerrado en una esfera, el
cual emite fotones en todas direcciones. Nos gustaría medir cuánta
energía pasa por la esfera. Podríamos entonces definir</p>
<p><span class="math display">\[
I = \frac{\Phi}{4\pi} \text{(W/sr)}
\]</span></p>
<p>Otra unidad de medida es el lumen por esterorradián, <span
class="math inline">\(\text{(lm/sr)}\)</span>. La anterior definición
mide cuántos fotones pasan por toda la esfera. ¿Qué ocurre si
<em>cerramos</em> el ángulo, restringiéndonos así a un área muy pequeña
de la esfera?</p>
<p><span class="math display">\[
I = \lim_{\Delta\omega \to 0}{\frac{\Delta\Phi}{\Delta\omega}} =
\frac{d\Phi}{d\omega}
\]</span></p>
<p>De la misma manera que con los conceptos anteriores, podemos volver a
la potencia integrando sobre un conjunto de direcciones:</p>
<p><span class="math display">\[
\Phi = \int_{\Omega}{I(\omega)d\omega}
\]</span></p>
<h3 id="radiancia">Radiancia</h3>
<p>Finalmente, llegamos al concepto más importante. La <strong>radiancia
espectral</strong> (o radiancia a secas<a href="#fn3"
class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>) es
una extensión de la radiancia emitida teniendo en cuenta la
dirección:</p>
<p><span class="math display">\[
L(p, \omega) = \lim_{\Delta\omega \to 0}{\frac{\Delta
E_\omega(p)}{\Delta\omega}} = \frac{dE_\omega(p)}{d\omega}
\]</span></p>
<p>siendo <span class="math inline">\(E_\omega(p)\)</span> la radiancia
emitida a la superficie perpendicular a <span
class="math inline">\(\omega\)</span>.</p>
<blockquote>
<p>TODO: foto como la de
https://cs184.eecs.berkeley.edu/public/sp22/lectures/lec-11-radiometry-and-photometry/lec-11-radiometry-and-photometry.pdf,
página 10.</p>
</blockquote>
<p>Podemos dar otra expresión de la radiancia en términos del flujo:</p>
<p><span id="eq:radiancia_flujo" class="eqnos"><span
class="math display">\[
L(p, \omega) = \frac{d^2\Phi(p, \omega)}{d\omega\ dA^\bot} =
\frac{d^2\Phi(p, \omega)}{d\omega\ dA\ \cos\theta}
\]</span><span class="eqnos-number">(5)</span></span></p>
<p>donde <span class="math inline">\(dA^\bot\)</span> es el área
proyectada por <span class="math inline">\(dA\)</span> en una hipotética
superficie perpendicular a <span
class="math inline">\(\omega\)</span>:</p>
<blockquote>
<p>TODO: figura similar a pbr figura 5.10
https://www.pbr-book.org/3ed-2018/Color_and_Radiometry/Radiometry</p>
</blockquote>
<p>Cuando un rayo impacta en una superficie, <span
class="math inline">\(L\)</span> puede tomar valores muy diferentes en
un lado y otro de dicha superficie. Por ejemplo, si nos imaginamos un
espejo, el valor un poco por encima y un poco por debajo de un punto del
espejo es muy diferente. Para solucionarlo, podemos tomar límites para
distinguir a ambos lados:</p>
<p><span id="eq:L_limit" class="eqnos"><span class="math display">\[
\begin{aligned}
L^+(p, \omega) = \lim_{t \to 0^+}{L(p + t\mathbf{n_p}, \omega)} \\
L^-(p, \omega) = \lim_{t \to 0^-}{L(p + t\mathbf{n_p}, \omega)}
\end{aligned}
\]</span><span class="eqnos-number">(6)</span></span></p>
<p>donde <span class="math inline">\(\mathbf{n_p}\)</span> es la normal
en el punto <span class="math inline">\(p\)</span>.</p>
<p>Otra forma de solucionarlo (y preferible, puesto que simplifica
entender lo que ocurre) es distinguir entre la radiancia que llega a un
punto –la incidente–, y la saliente.</p>
<p>La primera se llamará <span class="math inline">\(L_i(p,
\omega)\)</span>, mientras que la segunda será <span
class="math inline">\(L_o(p, \omega)\)</span>. Es importante destacar
que <span class="math inline">\(\omega\)</span> apunta <em>hacia
fuera</em> de la superficie. Quizás es contraintuitivo en <span
class="math inline">\(L_i\)</span>, puesto que <span
class="math inline">\(-\omega\)</span> apunta <em>hacia</em> la
superficie. Depende del autor se utiliza una concepción u otra.</p>
<blockquote>
<p><strong>Nota</strong>(ción): a <span
class="math inline">\(L_o\)</span> también se le conoce como la
radiancia reflejada. Por eso, algunas veces aparece como <span
class="math inline">\(L_r\)</span> en algunas fuentes.</p>
</blockquote>
<p>Utilizando esta notación y usando [<a href="#eq:L_limit">6</a>],
podemos escribir <span class="math inline">\(L_i\)</span> y <span
class="math inline">\(L_o\)</span> como</p>
<p><span class="math display">\[
\begin{aligned}
    L_i(p, \omega) &amp; =
        \begin{cases}
            L^+(p, -\omega) &amp; \text{si } \omega \cdot \mathbf{n_p}
&gt; 0 \\
            L^-(p, -\omega) &amp; \text{si } \omega \cdot \mathbf{n_p}
&lt; 0
        \end{cases} \\
    L_o(p, \omega) &amp; =
        \begin{cases}
            L^+(p, \omega) &amp; \text{si } \omega \cdot \mathbf{n_p}
&gt; 0 \\
            L^-(p, \omega) &amp; \text{si } \omega \cdot \mathbf{n_p}
&lt; 0
        \end{cases}
\end{aligned}
\]</span></p>
<p>Hacemos esta distinción porque, a fin de cuentas, necesitamos
distinguir entre los fotones que llegan a la superficie y los que
salen.</p>
<blockquote>
<p>TODO:
https://cs184.eecs.berkeley.edu/public/sp22/lectures/lec-11-radiometry-and-photometry/lec-11-radiometry-and-photometry.pdf,
p.36</p>
</blockquote>
<p>Una propiedad a tener en cuenta es que, si cogemos un punto <span
class="math inline">\(p\)</span> del espacio donde no existe ninguna
superifcie, <span class="math inline">\(L_o(p, \omega) = L_i(p, -\omega)
= L(p, \omega)\)</span></p>
<p>La importancia de la radiancia se debe a un par de propiedades:</p>
<p>La primera de ellas es que, dado <span
class="math inline">\(L\)</span>, podemos calcular cualquier otra unidad
básica mediante integración. Además, <strong>su valor se mantiene
constante en rayos que viajan en el vacío en línea recta</strong> <span
class="citation" data-cites="Pellacini-Marschner-2017">(<a
href="#ref-Pellacini-Marschner-2017" role="doc-biblioref">Fabio
Pellacini 2017</a>)</span>. Esto último hace que resulte muy natural
usarla en un ray tracer.</p>
<p>Veamos por qué ocurre esto:</p>
<blockquote>
<p>TODO:
https://pellacini.di.uniroma1.it/teaching/graphics17b/lectures/12_pathtracing.pdf,
página 18.</p>
</blockquote>
<p>Consideremos dos superficies ortogonales entre sí, <span
class="math inline">\(S_1\)</span> y <span
class="math inline">\(S_2\)</span> separadas una distancia <span
class="math inline">\(r\)</span>. Debido a la conservación de la
energía, cualquier fotón que salga de una superficie y se encuentre bajo
el ángulo sólido de la otra debe llegar impactar en dicha superficie
opuesta.</p>
<p>Por tanto:</p>
<p><span class="math display">\[
d^2\Phi_1 = d^2\Phi_2
\]</span></p>
<p>Sustituyendo en la expresión de la radiancia [<a
href="#eq:radiancia_flujo">5</a>], y teniendo en cuenta que son
ortogonales (lo que nos dice que <span class="math inline">\(\cos\theta
= 1\)</span>):</p>
<p><span class="math display">\[
L_1 d\omega_1 dA_1 = L_2 d\omega_2 dA_2
\]</span></p>
<p>Por construcción, podemos cambiar los ángulos sólidos:</p>
<p><span class="math display">\[
L_1 \frac{dA_2}{r^2} dA_1 = L_2 \frac{dA_1}{r^2} dA_2
\]</span></p>
<p>Lo que finalmente nos dice que <span class="math inline">\(L_1 =
L_2\)</span>, como queríamos ver.</p>
<h2 id="integrales-radiométricas">Integrales radiométricas</h2>
<p>En esta sección, vamos a explorar las nuevas herramientas que nos
proporciona la radiancia. Veremos también cómo integrar ángulos sólidos,
y cómo simplificar dichas integrales.</p>
<h3 id="una-nueva-expresión-de-la-irradiancia-y-el-flujo">Una nueva
expresión de la irradiancia y el flujo</h3>
<p>Como dijimos al final de <a href="#irradiancia">la sección de la
irradiancia</a>, esta medida no tiene en cuenta las direcciones desde
las que llegaba la luz. A diferencia de esta, la radiancia sí que las
utiliza. Dado que una de las ventajas de la radiancia es que nos permite
obtener el resto de medidas radiométricas, ¿por qué no desarrollamos una
nueva expresión de la irradiancia?</p>
<p>Para obtener cuánta luz llega a un punto, debemos acumular la
radiancia incidente que nos llega desde cualquier dirección.</p>
<blockquote>
<p>TODO: dibujo como el de la libreta roja. Me lo mandé por Telegram,
por si no lo encuentro</p>
</blockquote>
<p>Dado un punto <span class="math inline">\(p\)</span> que se encuentra
en una superficie con normal <span
class="math inline">\(\mathbf{n}\)</span> en dicho punto, la irradiancia
se puede expresar como</p>
<p><span id="eq:E_abs_cos" class="eqnos"><span class="math display">\[
E(p, \mathbf{n}) = \int_{\Omega}{L_i(p, \omega) \lvert cos\theta \rvert
d\omega}
\]</span><span class="eqnos-number">(7)</span></span></p>
<p>El término <span class="math inline">\(\cos\theta\)</span> aparece en
la integral debido a la derivada del área proyectada, <span
class="math inline">\(dA^\bot\)</span>. <span
class="math inline">\(\theta\)</span> es el ángulo entre la dirección
<span class="math inline">\(\omega\)</span> y la normal <span
class="math inline">\(\mathbf{n}\)</span>.</p>
<p>Generalmente, la irradiancia se calcula únicamente en el hemisferio
de direcciones asociado a la normal en el punto, <span
class="math inline">\(H^2(\mathbf{n})\)</span>.</p>
<p>Podemos eliminar el <span class="math inline">\(\cos\theta\)</span>
de la integral mediante una pequeña transformación: proyectando el
ángulo sólido sobre el disco alrededor del punto <span
class="math inline">\(p\)</span> con normal <span
class="math inline">\(\mathbf{n}\)</span>, obtenemos una expresión más
sencilla: como <span class="math inline">\(d\omega^\bot = \lvert
\cos\theta \rvert d\omega\)</span>, entonces</p>
<p><span class="math display">\[
\begin{aligned}
    E(p, \mathbf{n}) = \int_{H^2(\mathbf{n})}{L_i(p, \omega)
d\omega^\bot}
\end{aligned}
\]</span></p>
<p>Usando lo que aprendimos sobre la derivada de los ángulos sólidos [<a
href="#eq:d_omega">4</a>], se puede reescribir la ecuación anterior
como</p>
<p><span class="math display">\[
E(p, \mathbf{n}) = \int_{0}^{2\pi}\int_{0}^{\pi/2}{L_i(p, \theta, \phi)
\cos\theta\ \sin\theta\ d\theta\ d\phi}
\]</span></p>
<p>Haciendo el mismo juego con el flujo emitido de un cierto objeto al
hemisferio que encapsula la normal, conseguimos:</p>
<p><span class="math display">\[
\begin{aligned}
    \Phi &amp; = \int_{A}\int_{H^2(\mathbf{n})}{L_o(p, \omega)
\cos\theta\ d\omega dA} = \\
         &amp; = \int_{A}\int_{H^2(\mathbf{n})}{L_o(p, \omega)
d\omega^\bot dA}
\end{aligned}
\]</span></p>
<blockquote>
<p>TODO: a lo mejor merece la pena hacer un ejemplo sobre los diferentes
tipos de luz, como en
https://cs184.eecs.berkeley.edu/public/sp22/lectures/lec-11-radiometry-and-photometry/lec-11-radiometry-and-photometry.pdf
p.41? O a lo mejor un capítulo para hablar de luces en general.</p>
</blockquote>
<h3 id="integrando-sobre-área">Integrando sobre área</h3>
<p>Una herramienta más que nos vendrá bien será la capacidad de
convertir integrales sobre direcciones en integrales sobre área. Hemos
hecho algo similar en las secciones anteriores, así que no perdemos nada
por generalizarlo.</p>
<p>Considera un punto <span class="math inline">\(p\)</span> sobre una
superficie con normal en dicho punto <span
class="math inline">\(\mathbf{n}\)</span>. Supongamos que tenemos una
pequeña área <span class="math inline">\(dA\)</span> con normal <span
class="math inline">\(\mathbf{n_{dA}}\)</span>. Sea <span
class="math inline">\(\theta\)</span> el ángulo entre <span
class="math inline">\(\mathbf{n}\)</span> y <span
class="math inline">\(\mathbf{n_{dA}}\)</span>, y <span
class="math inline">\(r\)</span> la distancia entre <span
class="math inline">\(p\)</span> y <span
class="math inline">\(dA\)</span>.</p>
<p>Entonces, la relación entre la diferencial de un ángulo sólido y la
de un área es</p>
<p><span class="math display">\[
d\omega = \frac{dA\cos\theta}{r^2}
\]</span></p>
<blockquote>
<p>TODO: figura como la de pbr book 5.16.</p>
</blockquote>
<p>Esto nos permite, por ejemplo, expandir algunas expresiones como la
de la irradiancia [<a href="#eq:E_abs_cos">7</a>] si partimos de un
cuadrilátero <span class="math inline">\(dA\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
    E(p, \mathbf{n}) &amp; = \int_{\Omega}{L_i(p, \omega) \lvert
\cos\theta \rvert d\omega} = \\
                     &amp; = \int_{A}{L\cos\theta\
\frac{\cos\theta_o}{r^2}dA}
\end{aligned}
\]</span></p>
<p>siendo <span class="math inline">\(\theta_o\)</span> el ángulo de la
radiancia de salida de la superficie del cuadrilátero.</p>
<h2
id="dispersión-de-luz-las-familias-de-funciones-de-distribución-bidireccionales">Dispersión
de luz: las familias de funciones de distribución bidireccionales</h2>
<p>Cuando una fuente de luz emite fotones hacia una superficie
impactando en ella, ocurren un par de sucesos: parte de la luz se
refleja en ella, saliendo disparada hacia alguna dirección; mientras que
otra parte se absorbe.</p>
<p>En informática gráfica se consideran tres tipos principales de
dispersión de luz: <strong>dispersión en superficie</strong>
(<em>surface scattering</em>), <strong>dispersión volumétrica</strong>
(<em>volumetric scattering</em>) y <strong>dispersión bajo
superficie</strong> (<em>subsurface scattering</em>)</p>
<p>En este capítulo vamos a modelar la primera. Estudiaremos qué es lo
que ocurre cuando los fotones alcanzan una superficie, en qué dirección
se reflejan, y cómo cambia el comportamiento dependiendo de las
propiedades del material.</p>
<h3
id="la-función-de-distribución-de-reflectancia-bidireccional-brdf">La
función de distribución de reflectancia bidireccional (BRDF)</h3>
<p>La <strong>función de distribución de reflectancia
bidireccional</strong> (en inglés, <em>bidirectional reflectance
distribution function</em>, BRDF) describe cómo la luz se refleja en una
superficie opaca. Se encarga de informarnos sobre cuánta radiancia sale
en dirección <span class="math inline">\(\omega_o\)</span> debido a la
radiancia incidente desde la dirección <span
class="math inline">\(\omega_i\)</span>, partiendo de un punto <span
class="math inline">\(p\)</span> en una superficie con normal <span
class="math inline">\(\mathbf{n}\)</span>. Depende de la longitud de
onda <span class="math inline">\(\lambda\)</span>, pero, como de
costumbre, la omitiremos.</p>
<blockquote>
<p><strong>Intuición</strong>: <em>¿cuál es la probabilidad de que,
habiéndome llegado un fotón desde <span
class="math inline">\(\omega_i\)</span>, me salga disparado hacia <span
class="math inline">\(\omega_o\)</span>?</em></p>
</blockquote>
<blockquote>
<p>TODO: esquema como el de pbr fig. 5.18, o como
https://pellacini.di.uniroma1.it/teaching/graphics17b/lectures/12_pathtracing.pdf
p.20</p>
</blockquote>
<p>Si consideramos <span class="math inline">\(\omega_i\)</span> como un
cono diferencial de direcciones, la irradiancia diferencial en <span
class="math inline">\(p\)</span> viene dada por</p>
<p><span class="math display">\[
dE(p, \omega_i) = L_i(p, \omega_i) \cos\theta_i\ d\omega_i
\]</span></p>
<p>Debido a esta irradiancia, una pequeña parte de radiancia saldrá en
dirección <span class="math inline">\(\omega_o\)</span>, proporcional a
la irradiancia:</p>
<p><span class="math display">\[
dL_o(p, \omega_o) \propto dE(p, \omega_i)
\]</span></p>
<p>Si lo ponemos en forma de cociente, sabremos exactamente cuál es la
proporción de luz. A este cociente lo llamaremos <span
class="math inline">\(f_r(p, \omega_o \leftarrow \omega_i)\)</span>; la
función de distribución de reflectancia bidireccional:</p>
<p><span class="math display">\[
f_r(p, \omega_o \leftarrow \omega_i) = \frac{dL_o(p, \omega_o)}{dE(p,
\omega_i)} = \frac{dL_o(p, \omega_o)}{L_i(p, \omega_i) \cos\theta_i\
d\omega_i} \text{(1/sr)}
\]</span></p>
<blockquote>
<p><strong>Nota</strong>(ción): dependiendo de la fuente que estés
leyendo, es posible que te encuentres una integral algo diferente. Por
ejemplo, en tanto en Wikipedia como en <span class="citation"
data-cites="ShirleyRRT">(<a href="#ref-ShirleyRRT"
role="doc-biblioref">Shirley and Morley 2003</a>)</span> se integra con
respecto a los ángulos de salida <span
class="math inline">\(\omega_o\)</span>, en vez de los incidentes.</p>
<p>Aquí, usaremos la notación de integrar con respecto a los incidentes,
como se hace en <span class="citation" data-cites="PBRT3e">(<a
href="#ref-PBRT3e" role="doc-biblioref">Pharr, Jakob, and Humphreys
2016</a>)</span>.</p>
</blockquote>
<p>Las BRDF físicamente realistas tienen un par de propiedades
importantes:</p>
<ol type="1">
<li><strong>Reciprocidad</strong>: para cualquier par de direcciones
<span class="math inline">\(\omega_i\)</span>, <span
class="math inline">\(\omega_o\)</span>, se tiene que <span
class="math inline">\(f_r(p, \omega_i, \omega_o)=\ \)</span> <span
class="math inline">\(f_r(p, \omega_o \leftarrow
\omega_i)\)</span>.</li>
<li><strong>Conservación de la energía</strong>: La energía reflejada
tiene que ser menor o igual que la incidente:</li>
</ol>
<p><span class="math display">\[
\int_{H^2(\mathbf{n})}{f_r(p, \omega_o \leftarrow \omega_i)
\cos\theta_i\ d\omega_i} \leq 1
\]</span></p>
<h3
id="la-función-de-distribución-de-transmitancia-bidireccional-btdf">La
función de distribución de transmitancia bidireccional (BTDF)</h3>
<p>Si la BRDF describe cómo se refleja la luz, la <em>bidirectional
transmittance distribution function</em> (abreviada BTDF) nos informará
sobre la transmitancia; es decir, cómo se comporta la luz cuando
<em>entra</em> en un medio. Generalmente serán dos caras de la misma
moneda: cuando la luz impacta en una superficie, parte de ella, se
reflejará, y otra parte se transmitirá.</p>
<p>Puedes imaginarte la BTDF como una función de reflectancia del
hemisferio opuesto a donde se encuentra la normal de la superficie.</p>
<p>Denotaremos a la BTDF por</p>
<p><span class="math display">\[
f_t(p, \omega_o \leftarrow \omega_i)
\]</span></p>
<p>Al contrario que en la BRDF, <span
class="math inline">\(\omega_o\)</span> y <span
class="math inline">\(\omega_i\)</span> se encuentran en hemisferios
diferentes.</p>
<h3
id="juntando-la-brdf-y-la-btdf-en-la-función-de-distribución-de-dispersión-bidireccional">Juntando
la BRDF y la BTDF en La función de distribución de dispersión
bidireccional</h3>
<p>Convenientemente, podemos unir la BRDF y la BTDF en una sola
expresión, llamada <strong>la función de distribución de dispersión
bidireccional</strong> (<em>bidirectional scattering distribution
function</em>, BSDF). A la BSDF la denotaremos por</p>
<p><span class="math display">\[
f(p, \omega_o \leftarrow \omega_i)
\]</span></p>
<blockquote>
<p><strong>Intuición:</strong> <em>la BSDF son todas las posibles
direcciones en las que puede salir disparada la luz.</em></p>
</blockquote>
<p>Usando esta definición, podemos obtener</p>
<p><span class="math display">\[
dL_o(p, \omega_o) = f(p, \omega_o \leftarrow \omega_i) L_i(p, \omega_i)
\lvert \cos\theta_i \rvert d\omega_i
\]</span></p>
<p>Esto nos deja a punto de caramelo una nueva expresión de la
randiancia en términos de la randiancia incidente en un punto <span
class="math inline">\(p\)</span>. Integrando la expresión anterior,
obtenemos</p>
<p><span id="eq:scattering_equation" class="eqnos"><span
class="math display">\[
L_o(p, \omega_o) = \int_{\mathbb{S}^2}{f(p, \omega_o \leftarrow
\omega_i)L_i(p, \omega_i)\lvert \cos\theta_i \rvert d\omega_i}
\]</span><span class="eqnos-number">(8)</span></span></p>
<p>siendo <span class="math inline">\(\mathbb{S}^2\)</span> la
esfera.</p>
<p>Esta forma de expresar la radiancia es muy importante. Generalmente
se le suele llamar la <em>ecuación de dispersión</em> (<em>scattering
equation</em>, en inglés). Dado que es una integral muy importante,
seguramente tengamos que evaluarla repetidamente. ¡Los métodos de Monte
Carlo nos vendrán de perlas! Más adelante hablaremos de ella.</p>
<p>Las BSDFs tienen unas propiedades interesantes:</p>
<ul>
<li><strong>Positividad</strong>: como los fotones no se pueden reflejar
“negativamente”, <span class="math inline">\(f(p, \omega_o \leftarrow
\omega_i) \ge 0\)</span>.</li>
<li><strong>Reciprocidad de Helmotz:</strong> se puede invertir un rayo
de luz: <span class="math inline">\(f(p, \omega_o \leftarrow \omega_i) =
f(p, \omega_i \leftarrow \omega_o)\)</span>.</li>
<li><strong>Conservación de la energía</strong>: todos los fotones que
llegan a la superficie deben ser reflejados o absorbidos. Es decir, no
se emite ningún fotón nuevo:</li>
</ul>
<p><span class="math display">\[
\int_{H^2(\mathbf{n})}{f(p, \omega_o \leftarrow \omega_i) \cos\theta_i\
d\omega_i} \le 1\ \forall \omega_o
\]</span></p>
<h3 id="reflectancia-hemisférica">Reflectancia hemisférica</h3>
<p>Puede ser útil tomar el comportamiento agregado de las BRDFs y las
BTDFs y reducirlo un cierto valor que describa su comportamiento general
de dispersión. Sería Algo así como un resumen de su distribución. Para
conseguirlo, vamos a introducir dos nuevas funciones:</p>
<p>La <strong>reflectancia hemisférica-direccional</strong>
(<em>hemispherical-directional reflectance</em>) describe la reflexión
total sobre un hemisferio debida a una fuente de luz que proviene desde
la dirección <span class="math inline">\(\omega_o\)</span>:</p>
<p><span class="math display">\[
\rho_{hd}(\omega_o) = \int_{H^2(n)}{f_r(p, \omega_o \leftarrow \omega_i)
\lvert \cos\theta_i \rvert\ d\omega_i}
\]</span></p>
<p>Por otra parte, la <strong>reflectancia
hemisférica-hemisférica</strong> (<em>hemispherical-hemispherical
reflectance</em>) es un valor espectral que nos proporciona el ratio de
luz incidente reflejada por una superficie, suponiendo que llega la
misma luz desde todas direcciones:</p>
<p><span class="math display">\[
\rho_{hh} = \frac{1}{\pi} \int_{H^2(n)} \int_{H^2(n)}{f_r(p, \omega_o
\leftarrow \omega_i) \lvert \cos\theta_o\ \cos\theta_i \rvert\
d\omega_o\ d\omega_i}
\]</span></p>
<h3 id="reflejos">Reflejos</h3>
<p>Una vez hemos definido las funciones de distribución bidireccionales,
debemos encargarnos de modelar el comportamiento explícitamente. Para
ello, veamos cómo los materiales modifican las distribuciones.</p>
<p>En esencia, los reflejos se pueden clasificar en cuatro grandes
tipos:</p>
<ul>
<li><strong>Difusos</strong> (<em>Diffuse</em>): esparcen la luz en
todas direcciones casi equiprobablemente. Por ejemplo, la tela y el
papel son materiales difusos.</li>
<li><strong>Especulares brillantes</strong> (<em>Glossy specular</em>):
la distribución de luz se asemeja a un cono. La chapa de un coche es un
material especular brillante.</li>
<li><strong>Especulares perfectos</strong> (<em>Perfect specular</em>):
en esencia, son espejos. El ángulo de salida de la luz es muy pequeño,
por lo que reflejan casi a la perfección lo que les llega.</li>
<li><strong>Retrorreflectores</strong> (<em>Retro reflective</em>): la
luz se refleja en dirección contraria a la de llegada. Esto es lo que
sucede a la luna.</li>
</ul>
<p>Ten en cuenta que es muy difícil encontrar objetos físicos que imiten
a la perfección un cierto modelo. Suelen recaer en un híbrido entre dos
o más modelos.</p>
<p>Fijado un cierto modelo, la función de distribución de reflectancia,
BRDF, puede ser <strong>isotrópica</strong> o
<strong>anisotrópica</strong>. Los materiales isotrópicos mantienen las
propiedades de reflectancia invariantes ante rotaciones; es decir, la
distribución de luz es la misma en todas direcciones. Por el contrario,
los anisotrópicos reflejan diferentes cantidades de luz dependiendo
desde dónde los miremos. Los ejemplos más habituales de materiales
anisotrópicos son las rocas y la madera.</p>
<h2 id="la-rendering-equation"><strong>La rendering
equation</strong></h2>
<p>Y, finalmente, tras esta introducción de los principales conceptos
radiométricos, llegamos a la ecuación más importante de todo este
trabajo: la <strong>rendering equation</strong>; también llamada la
<strong>ecuación del transporte de luz</strong>.</p>
<blockquote>
<p><strong>Nota</strong>(ción): esta vez no traduciré el concepto. Es
cierto que afea un poco la escritura teniendo en cuenta que esto es un
texto en castellano. Sin embargo, la otra opción es inventarme una
traducción que nadie usa.</p>
</blockquote>
<p>Antes de comenzar, volvamos a plantear de nuevo la situación: nos
encontramos observando desde nuestra pantalla una escena virtual
mediante la cámara. Queremos saber qué color tomará un pixel específico.
Para conseguirlo, dispararemos rayos desde nuestro punto de vista hacia
el entorno, haciendo que reboten en los objetos. Cuando un rayo impacte
en una superficie, adquirirá parte de las propiedades del material del
objeto. Además, de este rayo surgirán otros nuevos (un rayo dispersado y
otro refractado), que a su vez repetirán el proceso. La información que
se obtiene a partir de estos caminos de rayos nos permitirá darle color
al píxel.</p>
<p>La <em>rendering equation</em> se va a encargar de describir
analíticamente cómo ocurre esto.</p>
<p>Un último concepto más: denotemos por <span
class="math inline">\(L_e(p, \omega_o)\)</span> a <strong>la radiancia
producida por los materiales emisivos</strong>. Por ejemplo, una luz
emite radiancia por sí misma.</p>
<p>Bien, partamos de la ecuación de para la radiancia reflejada:</p>
<p><span class="math display">\[
L_o(p, \omega_o) = \int_{H^2(\mathbf{n})}{f(p, \omega_o \leftarrow
\omega_i) L_i(p, \omega_i) \cos\theta_i\ d\omega_i}
\]</span></p>
<p>Vamos a buscar expresar la radiancia incidente en términos de la
radiancia reflejada. Para ello, usamos la propiedad de que la radiancia
a lo largo de un rayo no cambia.</p>
<p>Si a una superficie le llega un fotón desde alguna parte, debe ser
porque <em>“alguien”</em> ha tenido que emitirlo. El fotón
necesariamente ha llegado a partir de un rayo. La propiedad nos dice que
la radiancia no ha podido cambiar en el camino.</p>
<p>Pues bien, consideremos una función <span class="math inline">\(r:
\mathbb{R}^3 \times \Omega \to \mathbb{R}^3\)</span> tal que, dado un
punto <span class="math inline">\(p\)</span> y una dirección <span
class="math inline">\(\omega\)</span>, devuelve el siguiente punto de
impacto en una superficie. En esencia, es una función de <em>ray
casting</em>.</p>
<blockquote>
<p>TODO: foto como la de
https://pellacini.di.uniroma1.it/teaching/graphics17b/lectures/12_pathtracing.pdf,
p.29</p>
</blockquote>
<p>Esta función nos permite expresar el punto anterior de la siguiente
forma:</p>
<p><span class="math display">\[
L_i(p, \omega) = L_o(r(p, \omega), -\omega)
\]</span></p>
<p>Esto nos permite cambiar la expresión de <span
class="math inline">\(L_i\)</span> en la integral anterior:</p>
<p><span class="math display">\[
L_o(p, \omega_o) = \int_{H^2(\mathbf{n})}{f(p, \omega_o \leftarrow
\omega_i) L_o(r(p, \omega_i), -\omega_i) \cos\theta_i\ d\omega_i}
\]</span></p>
<p>Finalmente, la radiancia total vendrá dada por la suma de la
radiancia emitida y la reflejada:</p>
<p><span id="eq:rendering_equation" class="eqnos"><span
class="math display">\[
L(p, \omega_o) = L_e(p, \omega_o) + \int_{H^2(\mathbf{n})}{f(p, \omega_o
\leftarrow \omega_i) L_o(r(p, \omega_i), -\omega_i) \cos\theta_i\
d\omega_i}
\]</span><span class="eqnos-number">(9)</span></span></p>
<p>Y con esto, ¡hemos obtenido la <em>rendering equation</em>!</p>
<p>Si quieres ver gráficamente cómo funciona, te recomiendo pasarte por
<span class="citation" data-cites="arneback-2019">(<a
href="#ref-arneback-2019" role="doc-biblioref">Arnebäck
2019</a>)</span>. Es un vídeo muy intuitivo.</p>
<iframe width="784" height="441" src="https://www.youtube-nocookie.com/embed/eo_MTI-d28s" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>Si nos paramos a pensar, la ecuación de reflexión es muy similar a la
de renderizado. Sin embargo, hay un par de matices que las hacen muy
diferentes:</p>
<ul>
<li>La ecuación de reflexión describe cómo se comporta la luz reflejada
en un cierto punto. Es decir, tiene un ámbito local. Además, para
calcular la radiancia reflejada, se necesita conocer la radiancia
incidente.</li>
<li>La <em>rendering equation</em> calcula las condiciones globales de
la luz. Además, no se conocen las radiancias de salida.</li>
</ul>
<p>Este último matiz es importante. Para renderizar una imagen, se
necesita calcular la radiancia de salida para aquellos puntos visibles
desde nuestra cámara.</p>
<hr>
<h2 class="unlisted unnumbered" id="referencias-3">Referencias</h2>
<p><span class="citation" data-cites="PBRT3e">(<a href="#ref-PBRT3e"
role="doc-biblioref">Pharr, Jakob, and Humphreys 2016</a>)</span>, <span
class="citation" data-cites="wikipedia-contributors-2021D">(<a
href="#ref-wikipedia-contributors-2021D" role="doc-biblioref">Wikipedia:
Radiometry 2021</a>)</span>, <span class="citation"
data-cites="studysession-2021">(<a href="#ref-studysession-2021"
role="doc-biblioref">StudySession 2021</a>)</span>, <span
class="citation" data-cites="berkeley-cs184">(<a
href="#ref-berkeley-cs184" role="doc-biblioref">Berkeley cs184 2022</a>,
Radiometry &amp; Photometry)</span>, <span class="citation"
data-cites="wikipedia-funcion-de-distribucion-de-reflectancia-bidireccional-2022">(<a
href="#ref-wikipedia-funcion-de-distribucion-de-reflectancia-bidireccional-2022"
role="doc-biblioref">Wikipedia: Función de distribución de reflectancia
bidireccional 2022</a>)</span>, <span class="citation"
data-cites="wikipedia-transmittance-2021">(<a
href="#ref-wikipedia-transmittance-2021" role="doc-biblioref">Wikipedia:
Transmittance 2021</a>)</span></p>
<ul>
<li>https://matmatch.com/learn/property/isotropy-anisotropy</li>
<li>https://pellacini.di.uniroma1.it/teaching/graphics17b/lectures/12_pathtracing.pdf</li>
</ul>
<h1 id="construyamos-un-path-tracer">¡Construyamos un path tracer!</h1>
<p>Ahora que hemos introducido toda la teoría necesaria, es hora de
ponernos manos a la obra. En este capítulo, vamos a escoger una serie de
herramientas y haremos una pequeña implementación de un motor de path
tracing en tiempo real.</p>
<p>La implementación estará basada en Vulkan, junto al pequeño framework
de nvpro-samples. El motor mantendrá el mismo espíritu que la serie de
<span class="citation" data-cites="Shirley2020RTW1">(<a
href="#ref-Shirley2020RTW1" role="doc-biblioref">Shirley
2020a</a>)</span>, Ray Tracing In One Weekend.</p>
<p>Le pondremos especial atención a los conceptos claves. Vulkan tiende
a crear código muy verboso, por lo que se documentarán únicamente las
partes más importantes.</p>
<h2 id="requisitos-de-real-time-ray-tracing">Requisitos de <em>real time
ray tracing</em></h2>
<p>Como es natural, el tiempo es una limitación enorme para cualquier
programa en tiempo real. Mientras que en un <em>offline renderer</em>
disponemos de un tiempo muy considerable por frame (hablamos de varios
segundos), en un programa en tiempo real necesitamos que un frame salga
en 16 milisegundos o menos. Este concepto se suele denominar <em>frame
budget</em>: la cantidad de tiempo que disponemos para un frame.</p>
<blockquote>
<p><strong>Nota</strong>: cuando hablamos del tiempo disponible para un
frame, solemos hablar en milisegundos (ms) o frames por segundo (FPS).
Para que un motor vaya suficientemente fluido, necesitaremos que el
motor corra a un mínimo de 30 FPS (que equivalen a 33 ms por frame). Hoy
en día, debido al avance del área en campos como los videosjuegos, el
estándar se está convirtiendo en 60 FPS (16 ms/frame).</p>
</blockquote>
<p>Las nociones anteriores no distinguen entre un motor en tiempo real y
<em>offline</em>. Como es natural, necesitaremos introducir unos pocos
conceptos más para llevarlo a tiempo real. Además, existe una serie de
requisitos hardware que debemos cumplir para que un motor en tiempo real
con ray tracing funcione.</p>
<h3 id="arquitecturas-de-gráficas">Arquitecturas de gráficas</h3>
<blockquote>
<p>NOTE: sería interesante enlazarlo con la sección de rendimiento.</p>
</blockquote>
<p>El requisito más importante de todos es la gráfica. Para ser capaces
de realizar cálculos de ray tracing en tiempo real, necesitaremos una
arquitectura moderna con núcleos dedicados a este tipo de cáclulos <a
href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a>.</p>
<p>A día 17 de abril de 2022, para correr ray tracing en tiempo real, se
necesita alguna de las siguientes tarjetas gráficas:</p>
<table>
<colgroup>
<col style="width: 20%" />
<col style="width: 10%" />
<col style="width: 68%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Arquitectura</strong></th>
<th><strong>Fabricante</strong></th>
<th><strong>Modelos de gráficas</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Turing</strong></td>
<td>Nvidia</td>
<td>RTX 2060, RTX 2060 Super, RTX 2070, RTX 2070 Super, RTX 2080, RTX
2080 Super, RTX 2080 Ti, RTX Titan</td>
</tr>
<tr class="even">
<td><strong>Ampere</strong></td>
<td>Nvidia</td>
<td>RTX 3050, RTX 3060, RTX 3060 Ti, RTX 3070, RTX 3070 Ti, RTX 3080,
RTX 3080 Ti, RTX 3090, RTX 3090 Ti</td>
</tr>
<tr class="odd">
<td><strong>RDNA2</strong> (Navi 2X, Big Navi)</td>
<td>AMD</td>
<td>RX 6400, RX 6500 XT, RX 6600, RX 6600 XT, RX 6700 XT, RX 6800, RX
6800 XT, RX 6900 XT</td>
</tr>
<tr class="even">
<td><strong>Arc Alchemist</strong></td>
<td>Intel</td>
<td><em>No reveleado aún</em></td>
</tr>
</tbody>
</table>
<p>Solo se han incluido las gráficas de escritorio de consumidor.</p>
<p>Para este trabajo se ha utilizado una <strong>RTX 2070
Super</strong>. En el capítulo de análisis del rendimiento se hablará
con mayor profundidad de este apartado.</p>
<h3 id="frameworks-y-api-de-ray-tracing-en-tiempo-real">Frameworks y API
de ray tracing en tiempo real</h3>
<p>Una vez hemos cumplido los requisitos de hardware, es hora de escoger
los frameworks de trabajo.</p>
<p>Las API de gráficos están empezando a adaptarse a los requisitos del
tiempo real, por lo que cambian frecuentemente. La mayoría adquirieron
las directivas necesarias muy recientemente. Aun así, son lo
suficientemente sólidas para que se pueda usar en aplicaciones
empresariales de gran embergadura.</p>
<p>Esta es una lista de las API disponibles con capacidades de Ray
Tracing disponibles para, al menos, la arquitectura Turing:</p>
<ul>
<li>Vulkan (los bindings de ray tracing se denominan KHR).</li>
<li>Microsoft DirectX Ray Tracing (DXR), una extensión de DirectX
12.</li>
<li>Nvidia OptiX.</li>
</ul>
<p>De momento, no hay mucho donde elegir.</p>
<p>OptiX es la API más vieja de todas. Su primera versión salió en 2009,
mientras que la última estable es de 2021. Tradicionalmente se ha usado
para offline renderers, y no tiene un especial interés para este trabajo
estando las otras dos disponibles.</p>
<p>Tanto DXR como Vulkan son los candidatos más sólidos. DXR salió en
2018, con la llegada de Turing. Es un par de años más reciente que
Vulkan KHR. Cualquiera de las dos cumpliría su cometido de forma
exitosa. Sin embargo, para este trabajo, <strong>hemos escogido
Vulkan</strong> por los siguientes motivos:</p>
<ul>
<li>DirectX 12 está destinado principalmente a plataformas de Microsoft.
Es decir, está pensado para sistemas operativos Windows 10 o mayor <a
href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a>.</li>
<li>Vulkan está apoyado principalmente por AMD. Esto sigue las línas de
la su política de empresa de apoyar el código abierto. Además, resulta
más sencillo exportarlo a otros sistemas operativos.</li>
</ul>
<p>Ambas API se comportan de manera muy similar, y no existe una gran
diferencia entre ellas; tanto en rendimiento como en complejidad de
desarrollo. Actualmente el proyecto solo compila en Windows 10 o mayor,
por lo que estos dos puntos no resultan especialmente relevantes para el
trabajo.</p>
<h2 id="setup-del-proyecto">Setup del proyecto</h2>
<p>Un proyecto de Vulkan necesita una cantidad de código inicial
considerable. Para acelerar este trámite y partir de una base más
sólida, se ha decidido usar un pequeño framework de trabajo de Nvidia
llamado <a
href="https://github.com/nvpro-samples">nvpro-samples</a>.</p>
<p>Esta serie de repositorios contienen proyectos de ray tracing de
Nvidia con fines didácticos. Nosotros usaremos <a
href="https://github.com/nvpro-samples/vk_raytracing_tutorial_KHR">vk_raytracing_tutorial_KHR</a>,
pues ejemplifica cómo añadir ray tracing en tiempo real a un proyecto de
Vulkan.</p>
<p>Nuestro repositorio utiliza los citados anteriormente para compilar
su proyecto. El Makefile es una modificación del que se usa para
ejecutar los ejemplos de Nvidia. Por defecto, ejecuta una aplicación muy
simple que muestra un cubo mediante rasterización.</p>
<h2 id="compilación">Compilación</h2>
<p>Las dependencias necesarias para compilarlo son:</p>
<ol type="1">
<li>CMake.</li>
<li>Un driver de Nvidia compatible con la extensión
<code>VK_KHR_ray_tracing_pipeline</code>.</li>
<li>El SDK de Vulkan, versión 1.2.161 o mayor.</li>
</ol>
<p>La parte inicial del desarrollo consiste en adaptar Vulkan para usar
la extensión de ray tracing, extrayendo la información de la gráfica y
cargando correspondientemente el dispositivo.</p>
<p>Para compilarlo, ejecuta los siguientes comandos:</p>
<pre class="sh"><code>git clone git@github.com:Asmilex/Raytracing.git
cd .\application\vulkan_ray_tracing\
mkdir build
cd build
cmake ..</code></pre>
<p>Si todo funciona correctamente, debería generarse un binario en
<code>./application/bin_x64/Debug</code> llamado
<code>asmiray.exe</code>.</p>
<h2 id="estructuras-de-aceleración">Estructuras de aceleración</h2>
<p>El principal coste de ray tracing es el cálculo de las intersecciones
con objetos; hasta un 95% del tiempo de ejecución total (<span
class="citation" data-cites="scratchapixel-2019">(<a
href="#ref-scratchapixel-2019" role="doc-biblioref">Scratchapixel
2019</a>)</span>). Reducir el número de test de intersección es
clave.</p>
<p>Las <strong>estructuras de aceleración</strong> son una forma de
representar la geometría de la escena. Aunque hay varios tipos
diferentes, en esencia, engloban a un objeto o varios en una estructura
con la que resulta más eficiente hacer test de intersección. Son
similares a los grafos de escena de un rasterizador.</p>
<p>Uno de los tipos más comunes es la <strong>Bounding Volume Hierarchy
(BVH)</strong>. Fue una técnica desarrollada por Kay y Kajiya en 1986.
En esencia, este método encierra un objeto en una caja (lo que se
denomina una <strong>bounding box</strong>), de forma que el test de
intersección principal se hace con la caja y no con la geometría. Si un
rayo impacta en la <em>bounding box</em>, entonces se pasa a testear la
geometría.</p>
<p>Se puede repetir esta idea repetidamente, de forma que agrupemos
varias <em>bounding boxes</em>. Así, creamos una jerarquía de objetos
–como si nodos de un árbol se trataran–. A esta jerarquía es a la que
llamamos BVH.</p>
<p>Es importante crear buenas divisiones de los objetos en la BVH.
Cuanto más compacta sea una BVH, más eficiente será el test de
intersección.</p>
<p>Una forma habitual de crear la BVH es mediante la división del
espacio en una rejilla. Esta técnica se llama <strong>Axis-Aligned
Bounding Box (AABB)</strong>. Usualmente se usa el método del
<em>slab</em> (también introducido por Kay y Kajilla). Se divide el
espacio en una caja n-dimensional alineada con los ejes, de forma que
podemos verla como <span class="math inline">\([x_0, x_1]
\times\)</span> <span class="math inline">\([y_0, y_1] \times\)</span>
<span class="math inline">\([z_0, z_1] \times \dots\)</span> De esta
forma, comprobar si un rayo impacta en una bounding box es tan sencillo
como comprobar que está dentro del intervalo. Este es el método que se
ha usado en Ray Tracing in One Weekend.</p>
<h3 id="botom-level-acceleration-structure-blas">Botom-Level
Acceleration Structure (BLAS)</h3>
<h3 id="top-level-acceleration-structure-tlas">Top-Level Acceleration
Structure (TLAS)</h3>
<h2 id="ray-tracing-pipeline">Ray tracing pipeline</h2>
<h2 id="shaders">Shaders</h2>
<h3 id="shader-binding-table">Shader binding table</h3>
<h3 id="tipos-de-shaders">Tipos de shaders</h3>
<h4 id="ray-generation-shader">Ray generation shader</h4>
<h4 id="closest-hit-shader">Closest hit shader</h4>
<h4 id="miss-shader">Miss shader</h4>
<h4 id="anyhit-shader">Anyhit shader</h4>
<h2 id="asmiray">Asmiray</h2>
<h2 id="transporte-de-luz-1">Transporte de luz</h2>
<blockquote>
<p>TODO: creo… que esto no debería ir aquí. Pero no quiero tampoco que
el capítulo de radiometría sea un tocho impresionante.</p>
</blockquote>
<p>Hemos llegado a una de las partes más importantes de este trabajo. Es
el momento de poner en concordancia todo lo que hemos visto a lo largo
de los capítulos anteriores.</p>
<p>Empecemos por la dispersión. ¿Recuerdas la ecuación de dispersión [<a
href="#eq:scattering_equation">8</a>]? Podemos estimarla utilizando
Monte Carlo:</p>
<p><span class="math display">\[
\begin{aligned}
L_o(p, \omega_o) &amp; = \int_{\mathbb{S}^2}{f(p, \omega_o \leftarrow
\omega_i)L_i(p, \omega_i)\lvert \cos\theta_i \rvert d\omega_i} \\
                 &amp; \approx \frac{1}{N} \sum_{j = 1}^{N}{\frac{f(p,
\omega_o \leftarrow \omega_j) L_i(p, \omega_j) \lvert \cos\theta_j
\rvert}{p(\omega_j)}}
\end{aligned}
\]</span></p>
<h3 id="materiales-y-objetos">Materiales y objetos</h3>
<blockquote>
<p>NOTE: esto son notas para el Andrés del futuro. Sí, lo sé, está
bastante claro solo con leerlo (⊙_⊙;)</p>
</blockquote>
<p>Si quiero meter las BxDFs en los materiales tal y como tenía pensado
(es decir, unas cuantas flags que me indiquen la BxDF que tengo que
usar), tengo que…</p>
<ol type="1">
<li>Modificar <code>common/obj_loader.h/MaterialObj</code> para meterle
las flags necesarias.</li>
<li>Modificar acordemente
<code>shaders/host_device.h/WaveFronMaterial</code>.</li>
<li>Secuestrar <code>ObjLoader::loadModel()</code> para indicarle los
parámetros nuevos.</li>
<li>(<em>Creo que no hace falta tocar <code>HelloVk::loadModel()</code>
de esta manera</em>)</li>
<li>Toquetear los shaders para que me saque las flags.</li>
</ol>
<p>CREO que de esta manera no me va a hacer falta tocar framebuffers.
Simplemente, todo dependerá de mi material y ya.</p>
<p><em>Creo</em>.</p>
<h2 id="fuentes-de-luz">Fuentes de luz</h2>
<blockquote>
<p>TODO: point lights, area lights, ambient lights…</p>
<p>TODO: estas son notas muy puntuales (<em>como las luces, jeje</em>).
Ya las revisaré más adelante.</p>
</blockquote>
<p>La interfaz se encuentra en <code>host_device.h</code>. Describe cómo
comunicarse con la GPU.</p>
<p>Ahora mismo, tenemos 3 constantes: tipo de luz:</p>
<pre><code class="language-glsl">vec3  lightPosition;    // (x, y, z)
float lightIntensity;   // (Intensidad)
int   lightType;        // (0 =&gt; point light, 1 =&gt; area light)</code></pre>
<p>Sería interesante añadir algunas constantes para controlar el tamaño
(radio, posición, normal para las de área…)</p>
<h3 id="point-lights-spotlights">Point lights + spotlights</h3>
<blockquote>
<p>pbr-book, point lights: <em>“Strictly speaking, it is incorrect to
describe the light arriving at a point due to a point light source using
units of radiance. Radiant intensity is instead the proper unit for
describing emission from a point light source, as explained in Section
5.4. In the light source interfaces here, however, we will abuse
terminology and use Sample_Li() methods to report the illumination
arriving at a point for all types of light sources, dividing radiant
intensity by the squared distance to the point p to convert units.
Section 14.2 revisits the details of this issue in its discussion of how
delta distributions affect evaluation of the integral in the scattering
equation. In the end, the correctness of the computation does not suffer
from this fudge, and it makes the implementation of light transport
algorithms more straightforward by not requiring them to use different
interfaces for different types of lights.”</em></p>
</blockquote>
<pre><code class="language-cpp">// https://github.com/mmp/pbrt-v3/blob/master/src/lights/point.h
// https://github.com/mmp/pbrt-v3/blob/master/src/lights/point.cpp

Spectrum sample_light(interaccion, vec2 u, vec3 wi, float pdf, visibility_tester) {
    wi = normalize(posicion_luz - interraccion.p);
    pdf = 1.f;
    // testeo de visibilidad. Opcional, I guess.

    return intensidad / distancia_al_cuadrado(posicion_luz, interraccion.p);
}</code></pre>
<p>La potencia total emitida por la luz puede calcularse integrando la
intensidad desprendida en toda su superficie. Asumiendo la intensidad
constante:</p>
<p><span class="math display">\[
\Phi = \int_{\mathbb{S}^2}{I d\omega} = I \int_{\mathbb{S}^2}{d\omega} =
4 \pi I
\]</span></p>
<p>Las spotlights son variaciones de las point lights iluminando en un
cono.</p>
<h3 id="fuentes-de-área">Fuentes de área</h3>
<p>Para simplificar la implementación, podemos asumir que son
rectangulares.</p>
<p>Nos van a hacer falta técnicas de Monte Carlo para solucionar el
problema de calcular integrales a lo largo de su superficie.</p>
<p>Primero, lo mejor es asumir un cuadrado, y después, extender la
interfaz para meter otras formas (es decir, rectángulos. Porque lo otro
sería mucha parafernalia innecesaria).</p>
<p><a
href="https://github.com/mmp/pbrt-v3/blob/aaa552a4b9cbf9dccb71450f47b268e0ed6370e2/src/core/light.h">Código
fuente</a></p>
<hr>
<h2 class="unlisted unnumbered" id="referencias-4">Referencias</h2>
<ul>
<li>https://github.com/dannyfritz/awesome-ray-tracing</li>
<li>https://www.wikiwand.com/en/Radeon</li>
<li>https://www.wikiwand.com/en/List_of_Nvidia_graphics_processing_units#/GeForce_30_series</li>
<li>https://www.eurogamer.net/digitalfoundry-2021-the-big-intel-interview-how-intel-alchemist-gpus-and-xess-upscaling-will-change-the-market</li>
<li>https://www.intel.com/content/www/us/en/products/docs/arc-discrete-graphics/overview.html</li>
<li>https://www.khronos.org/registry/vulkan/specs/1.2-khr-extensions/html/chap1.html</li>
<li>https://www.wikiwand.com/en/OptiX</li>
<li>https://www.wikiwand.com/en/DirectX_Raytracing</li>
<li>https://www.wikiwand.com/es/Valve_Corporation</li>
<li>https://www.phoronix.com/scan.php?page=news_item&amp;px=VKD3D-Proton-2.5</li>
<li>https://github.com/ValveSoftware/Proton</li>
<li>https://nvpro-samples.github.io/vk_raytracing_tutorial_KHR/</li>
<li>https://www.scratchapixel.com/lessons/3d-basic-rendering/introduction-acceleration-structure</li>
<li>https://www.khronos.org/blog/vulkan-ray-tracing-best-practices-for-hybrid-rendering</li>
<li>https://raytracing.github.io/books/RayTracingTheNextWeek.html#boundingvolumehierarchies</li>
</ul>
<h1 id="análisis-de-rendimiento">Análisis de rendimiento</h1>
<blockquote>
<p>TODO: para completar esta parte, necesitamos ambas implementaciones
(en CPU y GPU) listas. Hasta entonces, esto se queda vacío. NOTE: Podría
preguntarle a Kako que tire benchmark en su 2060, y a Manu con su 3060
(¿ti?)</p>
</blockquote>
<hr>
<h2 class="unlisted unnumbered" id="referencias-5">Referencias</h2>
<h1 id="el-futuro-de-ray-tracing">El futuro de Ray Tracing</h1>
<blockquote>
<p>TODO: Ideas para este capítulo:</p>
<ul>
<li>Hablar de los offline renderers disponibles</li>
<li>Real time ray tracing en la industria: Minecraft RTX, Queake II,
Cyberpunk, Metro Exodus, Control</li>
<li>Arquitecturas modernas de consolas, y cómo el desarrollo en consola
se ha transformado. Hablar de Insomniac Games</li>
</ul>
</blockquote>
<hr>
<h2 class="unlisted unnumbered" id="referencias-6">Referencias</h2>

<h1 id="metodología-de-trabajo">Metodología de trabajo</h1>
<p>Cualquier proyecto de una envergadura considerable necesita ser
planificado con antelación. En este capítulo vamos a hablar de cómo se
ha realizado este trabajo: mostraremos las herramientas usadas, los
ciclos de desarrollo, integración entre documentación y path tracer, y
otras influencias que han afectado al producto final.</p>
<h2 id="influencias">Influencias</h2>
<p>Antes de comenzar con la labor, primero uno se debe hacer una simple
pregunta:</p>
<blockquote>
<p><em>“Y esto, ¿por qué me importa?”</em></p>
</blockquote>
<p>Dar una respuesta contundente a este tipo de cuestiones nunca es
fácil. Sin embargo, sí que puedo proporcionar motivos por los que he
querido escribir sobre ray tracing.</p>
<p>Una de las principales influencias ha sido <a
href="https://www.youtube.com/user/DigitalFoundry">Digital Foundry</a>.
Este grupo de divulgación se dedica al estudio de las técnicas
utilizadas en el mundo de los videojuegos. El inicio de la era del ray
tracing en tiempo real les llevó a dedicar una serie de vídeos y
artículos a esta tecnología, y a las diferentes maneras en las que se ha
implementado. Se puede ver un ejemplo en <span class="citation"
data-cites="digital-foundry-2020">(<a href="#ref-digital-foundry-2020"
role="doc-biblioref">Digital Foundry 2020</a>)</span>.</p>
<p>Dado que esta área combina tanto informática, matemáticas y una
visión artística, ¿por qué no explorarlo a fondo?</p>
<p>Ahora que se ha decidido el tema, es hora de ver cómo atacarlo.</p>
<p>Soy un fiel creyente del aprendizaje mediante el juego. Páginas como
<a href="https://explorabl.es/">Explorable Explanations</a>, el <a
href="https://ciechanow.ski/lights-and-shadows/">blog de Bartosz
Ciechanowski</a>, el proyecto <a
href="https://web.evanchen.cc/napkin.html"><em>The napkin</em></a> o el
divulgador <a href="https://www.3blue1brown.com/">3Blue1Brown</a>
repercuten inevitablemente en la manera en la que te planteas cómo
comunicar textos científicos. Por ello, aunque esto a fin de cuentas es
un trabajo de fin de grado de una carrera, quería ver hasta dónde era
capaz de llevarlo.</p>
<p>Otro punto importante es la <em>manera</em> de escribir. No me gusta
especialmente la escritura formal. Prefiero ser distendido. Por suerte,
parece que el mundo científico se está volviendo más informal <span
class="citation" data-cites="nature-2016">(<a href="#ref-nature-2016"
role="doc-biblioref">Nature 2016</a>)</span>, así que no soy el único
que aprueba esta tendencia. Además, la estructura clásica de un escrito
matemático de “teorema, lema, demostración, corolario” no me agrada
especialmente. He intentado preservar su estructura, pero sin ser tan
explícito. Estos dos puntos, en conjunto, suponen un balance entre
formalidad y distensión difícil de mantener.</p>
<h2 id="ciclos-de-desarrollo">Ciclos de desarrollo</h2>
<p>Este proyecto está compuesto por 2 grandes pilares: documentación –lo
que estás leyendo, ya sea en PDF o en la web– y software.</p>
<p>La metodología que se ha seguido es, en esencia, una versión de Agile
muy laxa <span class="citation" data-cites="beck2001agile">(<a
href="#ref-beck2001agile" role="doc-biblioref">Beck et al.
2001</a>)</span>.</p>
<p>Para empezar, se implementaron los tres libros de Shirley de la
“serie In One Weekend”: In One Weekend <span class="citation"
data-cites="Shirley2020RTW1">(<a href="#ref-Shirley2020RTW1"
role="doc-biblioref">Shirley 2020a</a>)</span>, The Next Week <span
class="citation" data-cites="Shirley2020RTW2">(<a
href="#ref-Shirley2020RTW2" role="doc-biblioref">Shirley
2020b</a>)</span>, y The Rest of your Life <span class="citation"
data-cites="Shirley2020RTW3">(<a href="#ref-Shirley2020RTW3"
role="doc-biblioref">Shirley 2020c</a>)</span>.</p>
<p>Tras esto, comenzó a <a href="#setup-del-proyecto">desarrollarse</a>
el motor por GPU. Cuando se consiguió una base sólida (que se puede ver
en <a href="https://github.com/Asmilex/Raytracing/issues/25">este issue
del repositorio</a>), se empezó a alternar entre escritura de
documentación y desarrollo del software. A fin de cuentas, no tiene
sentido implementar algo que no se conoce.</p>
<p>Para apoyar el desarrollo, se ha utilizado <a
href="#github">Github</a>. Más adelante hablaremos de cómo esta
plataforma ha facilitado el trabajo.</p>
<h2 id="diseño">Diseño</h2>
<blockquote>
<p>TODO: hablar de paleta de colores, tipografía…</p>
</blockquote>
<p>El diseño juega un papel fundamental en este proyecto. Todos los
elementos visuales han sido escogidos con cuidado, de forma que se
preserve la estética.</p>
<p>Se ha creado <strong>un diseño que preserve el equilibrio entre la
profesionalidad y la distensión</strong>.</p>
<h3 id="bases-del-diseño">Bases del diseño</h3>
<p>Para la documentación en versión PDF, usamos como base la
<em>template</em> <a
href="https://github.com/Wandmalfarbe/pandoc-latex-template">Eisvogel</a>.
Esta es una elegante plantilla fácil de usar para LaTeX. Uno de sus
puntos fuertes es la personalización, la cual aprovecharemos para darle
un toque diferente.</p>
<p>La web utiliza como base el estilo generado por Pandoc, el
microframework de css <a
href="https://github.com/rilwis/bamboo">Bamboo</a> y unas modificaciones
personales.</p>
<h3 id="tipografías">Tipografías</h3>
<p>Un apartado al que se le debe prestar especial énfasis es a la
combinación de tipografías. A fin de cuentas, esto es un libro; así que
escoger un tipo de letra correcto facilitará al lector comprender los
conceptos. Puede parecer trivial a priori, pero es importante.</p>
<p>Para este trabajo, se han escogido las siguientes tipografías:</p>
<ul>
<li><a href="https://fonts.google.com/specimen/Crimson+Pro">Crimson
Pro</a>: una tipografía serif clara, legible y contemporánea. Funciona
muy bien en densidades más bajas, como 11pt. Es ideal para la versión en
PDF. Además, liga estupendamente con Source Sans Pro, utilizada para los
títulos en la plantilla Eisvogel.</li>
<li><a href="https://fonts.google.com/specimen/Fraunces">Fraunces</a>:
de lejos, la fuente más interesante de todo este proyecto. Es una
soft-serif <em>old style</em>, pensada para títulos y similares (lo que
se conoce como <em>display</em>). Es usada en los títulos de la web. Una
de sus propiedades más curiosas es que modifica activamente los glifos
dependiendo del valor del <em>optical size axis</em>, el peso y
similares. Recomiendo echarle un ojo a su <a
href="https://github.com/undercasetype/Fraunces">repositorio de
Github</a>.</li>
<li><a href="https://fonts.google.com/specimen/Rubik">Rubik</a>: La
elección de Rubik es peculiar. Por sí sola, no casa con el proyecto. Sin
embargo, combinada con Fraunces, proporcionan un punto de elegancia y
familiaridad a la web. Su principal fuerte es la facilidad para la
comprensión lectora en pantallas, algo que buscamos para la página
web.</li>
<li><a href="https://juliamono.netlify.app/">Julia Mono</a>:
monoespaciada, pensada para computación científica. Llevo usándola
bastante tiempo, y combia bien con Crimson Pro.</li>
<li><a href="https://www.jetbrains.com/es-es/lp/mono/">Jetbrains
Mono</a>: otra tipografía monoespaciada open source muy sólida,
producida por la compañía Jetbrains. Se utiliza en la web para los
bloques de código.</li>
</ul>
<p>Todas estas fuentes permiten un uso no comercial gratuito.</p>
<blockquote>
<p>TODO: Añadir imagen comparativa con las fuentes</p>
</blockquote>
<h3 id="paleta-de-colores">Paleta de colores</h3>
<p>A fin de mantener consistencia, se ha creado una paleta de colores
específica.</p>
<figure>
<img src="./img/07/Paleta%20de%20colores.png" width="400"
alt="La paleta de colores del proyecto" />
<figcaption aria-hidden="true">La paleta de colores del
proyecto</figcaption>
</figure>
<p>El principal objetivo es <strong>transmitir tranquilidad</strong>,
pero a la misma vez, <strong>profesionalidad</strong>. De nuevo,
buscamos la idea de profesionalidad distendida que ya hemos repetido un
par de veces.</p>
<p>Partiendo del rojo que traía Eisvogel (lo que para nosotros sería el
rojo primario), se han creado el resto. En principio, con 5 tonalidades
diferentes nos basta. Todas ellas vienen acompañadas de sus respectivas
variaciones oscuras, muy oscuras, claras y muy claras. Corresponderían a
los <code>color-100, color-300, color-500, color-700, color-900</code>
que estamos acostumbrados en diseño web. Para la escala de grises, se
han escogido 7 colores en vez de 9. Son más que suficientes para lo que
necesitamos. Puedes encontrar las definiciones en el <a
href="https://github.com/Asmilex/Raytracing/blob/main/docs/headers/style.css">fichero
de estilos</a>.</p>
<p>Todos los colores que puedes ver en este documento se han extraído de
la paleta. ¡La consistencia es clave!</p>
<h2 id="flujo-de-trabajo-y-herramientas">Flujo de trabajo y
herramientas</h2>
<p>Encontrar una herramienta que se adapte a un <em>workflow</em> es
complicado. Aunque hay muchos programas maravilosos, debemos hacerlos
funcionar en conjunto. En este apartado, vamos a describir cuáles son
las que hemos usado.</p>
<p>Principalmente destacan tres de ellas: <strong>Github</strong>,
<strong>Pandoc</strong> y <strong>Figma</strong>. La primera tendrá <a
href="#github">su propia sección</a>, así que hablaremos de las
otras.</p>
<blockquote>
<p>TODO: foto del workflow.</p>
</blockquote>
<h3 id="pandoc">Pandoc</h3>
<p><a href="https://pandoc.org/">Pandoc</a> es una estupendísima de
conversión de documentos. Se puede usar para convertir un tipo de
archivo a otro. En este caso, se usa para convertir una serie de
ficheros Markdown (los capítulos) a un fichero HTML (la web) y a PDF. Su
punto más fuerte es que permite escribir LaTeX de forma simplificada,
como si se tratara de <em>sugar syntax</em>. Combina la simplicidad de
Markdown y la correctitud de LaTeX.</p>
<p>Su funcionamiento en este proyecto es el siguiente: Primero, recoge
los capítulos que se encuentra en <code>docs/chapters</code>, usando una
serie de cabeceras en YAML que especifican ciertos parámetros (como
autor, fecha, título, etc.), así como scripts de Lua. Estas caceberas se
encuentran en <code>docs/headers</code>. En particular:</p>
<ol type="1">
<li><code>meta.md</code> recoge los parámetros base del trabajo.</li>
<li><code>pdf.md</code> y <code>web.md</code> contienen algunas
definiciones específicas de sus respectivos formatos. Por ejemplo, el
YAML del PDF asigna las variables disponibles de la plantilla Eisvogel;
mientras que para la web se incluyen las referencias a algunas
bibliotecas de Javascript necesarias o los estilos
(<code>docs/headers/style.css</code>, usando como base <a
href="https://github.com/rilwis/bamboo">Bamboo.css</a>).</li>
<li><code>math.md</code> contiene las definiciones de LaTeX.</li>
<li>Se utilizan algunos filtros específicos de Lua para simplificar la
escritura. En específico, <code>standard-code.lua</code> formatea
correctamente los bloques de código para la web.</li>
</ol>
<p>Un fichero Makefile (<code>docs/Makefile</code>) contiene varias
órdenes para generar ambos formatos. Tienen varios parámetros
adicionales de por sí, como puede ser la bibliografía
(<code>docs/chapters/bibliography.bib</code>).</p>
<h3 id="figma">Figma</h3>
<p><a href="https://www.figma.com/">Figma</a> es otro de esos programas
que te hace preguntarte por qué es gratis. Es una aplicación en la web
usada para diseño gráfico. Es muy potente, intuitiva, y genera unos
resultados muy buenos en poco tiempo. Todos los diseños de este trabajo
se han hecho con esta herramienta.</p>
<figure>
<img src="./img/07/Figma.png"
alt="Tablón principal del proyecto de Figma, a día 15 de abril de 2022" />
<figcaption aria-hidden="true">Tablón principal del proyecto de Figma, a
día 15 de abril de 2022</figcaption>
</figure>
<p>Una de las características más útiles es poder exportar rápidamente
la imagen. Esto permite hacer cambios rápidos y registrarlos en el
repositorio fácilmente. Además, permite instalar plugins. Uno de ellos
ha resultado especialmente útil: <a
href="https://www.figma.com/community/plugin/793023817364007801/LaTeX-Complete">Latex
Complete</a>. Esto nos permite incrustar código LaTeX en el documento en
forma de SVG.</p>
<h3 id="otros-programas">Otros programas</h3>
<p>Como es normal, hay muchos otros programas que han intervenido en el
desarrollo. Estos son algunos de ellos:</p>
<ul>
<li>El editor por excelencia <a
href="https://code.visualstudio.com/">VSCode</a>. Ha facilitado en gran
medida el desarrollo de la aplicación y la documentación. En particular,
se ha usado una extensión denominada <a
href="https://marketplace.visualstudio.com/items?itemName=Gruntfuggly.triggertaskonsave">Trigger
task on save</a> que compila la documentación HTML automáticamente al
guardar un fichero. ¡Muy útil y rápido!</li>
<li><a href="https://www.vectary.com/">Vectary</a> para hacer los
diseños en 3D fácilmente. Permite exportar una escena rápidamente a png
para editarla en Figma.</li>
<li>Como veremos más adelante, la documentación se compila en el
repositorio usando un contenedor de <a
href="https://www.docker.com/">Docker</a>.</li>
<li>Cualquier proyecto informático debería usar <code>git</code>. Este
no es una excepción.</li>
</ul>
<h2 id="github">Github</h2>
<p>La página <a href="https://github.com">Github</a> ha alojado
prácticamente todo el contenido del trabajo; desde el programa, hasta la
documentación online. El repositorio se puede consultar en <a
href="https://github.com/Asmilex/Raytracing">Github.com/Asmilex/Raytracing</a>.</p>
<p>Se ha escogido Github en vez de sus competidores por los siguientes
motivos:</p>
<ol type="1">
<li>Llevo usándola toda la carrera. Es mi página de hosting de
repositorios favorita.</li>
<li>Los repositorios de Nvidia se encontraban en Github, por lo que
resulta más fácil sincronizarlos.</li>
<li>La documentación se puede desplegar usando Github Pages.</li>
<li>Las Github Actions son particularmente cómodas y sencillas de
usar.</li>
</ol>
<p>Entremos en detalle en algunos de los puntos anteriores:</p>
<h3
id="integración-continua-con-github-actions-y-github-pages">Integración
continua con Github Actions y Github Pages</h3>
<p>Cuando hablamos de <strong>integración continua</strong>, nos
referimos a ciertos programas que corren en un repositorio y se encargan
de hacer ciertas transformaciones al código, de forma que este se
prepare para su presentación final. En esencia, automatizan algunas
tareas habituales de un desarrollo de software.</p>
<p>En este trabajo lo usaremos para compilar la documentación. De esta
forma, no necesitamos lidiar con “proyecto final”, “proyecto final
definitivo”, “proyecto final final v2”, etc. Simplemente, cuando
registremos un cambio en los ficheros Markdown (lo que se conoce en git
como un <code>commit</code>), y lo subamos a Github (acción de
<code>push</code>), se ejecutará un denominado <code>Action</code> que
operará sobre nuestros archivos.</p>
<p>Tendremos dos tipos de <code>Actions</code>: uno que se encarga de
compilar la web, y otro el PDF. En esencia, operan de la siguiente
manera:</p>
<ol type="1">
<li>Comprueba si se ha modificado algún fichero <code>.md</code> en el
último commit subido. Si no es el caso, para.</li>
<li>Si sí se ha modificado, accede a la carpeta del repositorio y
compila la documentación mediante <code>pandoc</code>.
<ol type="1">
<li>La web se genera en <code>docs/index.html</code>. Publica la web a
Github Pages.</li>
<li>El PDF se crea en <code>docs/TFG.pdf</code></li>
</ol></li>
<li>Commitea los archivos y termina.</li>
</ol>
<figure>
<img src="./img/07/Github%20Actions.png"
alt="La pestaña de Github Actions permite controlar con facilidad el resultado de un workflow y cuánto tarda en ejecutarse" />
<figcaption aria-hidden="true">La pestaña de Github Actions permite
controlar con facilidad el resultado de un workflow y cuánto tarda en
ejecutarse</figcaption>
</figure>
<p>El workflow de la web corre automáticamente, mientras que para
generar el PDF hace falta activación manual. Aunque no es <em>del
todo</em> correcto almacenar ficheros binarios en un repositorio de git,
no me resulta molesto personalmente. Así que, cuando considero que es el
momento oportuno, lo hago manualmente. Además, también se activa por
cada <em>release</em> que se crea.</p>
<p>Volviendo a la web, Github permite alojar páginas web para un
repositorio. Activando el parámetro correcto en las opciones del
repositorio, y configurándolo debidamente, conseguimos que lea el
archivo <code>index.html</code> generado por el Action y lo despliegue.
Esto es potentísimo: con solo editar una línea de código y subir los
cambios, conseguimos que la web se actualice al instante.</p>
<p>Para generar los archivos nos hace falta una distribución de LaTeX,
Pandoc, y todas las dependencias (como filtros). Como no encontré ningún
contenedor que sirviera mi propósito, decidí crear uno. Se encuentra en
el <a href="https://hub.docker.com/r/asmilex/raytracing">repositorio de
Dockerhub</a>. Esta imagen está basada en <a
href="https://hub.docker.com/r/dockershelf/latex">dockershelf/latex:full</a>.
Por desgracia, es <em>muy</em> pesada para ser un contenedor.
Desafortunadamente, una instalación de LaTeX ocupa una cantidad de
espacio considerable; y para compilar el PDF necesitamos una muy
completa, por lo que debemos lidiar con este <em>overhead</em>. Puedes
encontrar el Dockerfile <a
href="https://github.com/Asmilex/Raytracing/blob/main/Dockerfile">aquí</a>.</p>
<h3 id="issues-y-github-projects">Issues y Github Projects</h3>
<p>Las tareas pendientes se gestionan mediante issues. Cada vez que se
tenga un objetivo particular para el desarrollo, se anota un issue.
Cuando se genere un commit que avance dicha tarea, se etiqueta con el
número correspondiente al issue. De esta forma, todas las confirmaciones
relacionadas con la tarea quedan recogidas en la página web. Puedes ver
un ejemplo en el <a
href="https://github.com/Asmilex/Raytracing/issues/22">issue número
22</a>.</p>
<p>Esto permite una gestión muy eficiente de los principales problemas y
objetivos pendientes de la aplicación.</p>
<figure>
<img src="./img/07/Issues.png"
alt="Pestaña de issues, día 16 de abril de 2022" />
<figcaption aria-hidden="true">Pestaña de issues, día 16 de abril de
2022</figcaption>
</figure>
<p>Los issues se agrupan en <em>milestones</em>, o productos mínimamente
viables. Estos issues suelen estar relacionados con algún apartado
importante del desarrollo.</p>
<figure>
<img src="./img/07/Milestones.png"
alt="Los milestones agrupan una serie de issues relacionados con un punto clave del desarrollo" />
<figcaption aria-hidden="true">Los <em>milestones</em> agrupan una serie
de issues relacionados con un punto clave del desarrollo</figcaption>
</figure>
<p>De esta forma, podemos ver todo lo que queda pendiente para la fecha
de entrega.</p>
<p>Para añadir mayor granularidad a la gestión de tareas y proporcionar
una vista informativa, se utiliza Github Projects. En esencia, esta
aplicación es un acompañante del repositorio estilo Asana.</p>
<figure>
<img src="./img/07/Projects.png"
alt="Projects agrupa los issues y les asigna prioridades" />
<figcaption aria-hidden="true">Projects agrupa los issues y les asigna
prioridades</figcaption>
</figure>
<p>Una de las alternativas que se planteó al inicio fue <a
href="https://linear.app/">Linear</a>, una aplicación de gestión de
issues similar a Projects. Sin embargo, la conveniencia de tener
Projects integrado en Github supuso un punto a favor para este gestor.
De todas formas, el equipo de desarrollo se compone de una persona, así
que no hace falta complicar excesivamente el workflow.</p>
<p>El desarrollo general de la documentación no ha seguido este sistema
de issues, pues está sujeta a cambios constantes y cada commit está
marcado con <code>[:notebook:]</code>. No obstante, ciertos problemas
relacionados con ella, como puede ser el formato de entrega, sí que
quedan recogidos como un issue.</p>
<p>Finalmente, cuando se produce un cambio significativo en la
aplicación (como puede ser una refactorización, una implementación
considerablemente más compleja…) se genera una nueva rama. Cuando se ha
cumplido el objetivo, se <em>mergea</em> la rama con la principal
<code>main</code> mediante un <em>pull request</em>. Esto proporciona un
mecanismo de robustez ante cambios complejos.</p>
<h3 id="estilo-de-commits">Estilo de commits</h3>
<p>Una de los detalles que has podido apreciar si has entrado al
repositorio es un estilo de commit un tanto inusual. Aunque parece un
detalle de lo más insustancial, añadir emojis a los mensajes de commits
añade un toque particular al repositorio, y permite identificar
rápidamente el tipo de cambio.</p>
<p>Cada uno tiene un significado particular. En esta tabla se recogen
sus significados:</p>
<figure>
<img src="./img/07/Commits.png"
alt="Los emojis permiten reconocer el objetivo de cada commit. Esta tabla recoge el significado de cada uno" />
<figcaption aria-hidden="true">Los emojis permiten reconocer el objetivo
de cada commit. Esta tabla recoge el significado de cada
uno</figcaption>
</figure>
<hr>
<h2 class="unlisted unnumbered" id="referencias-7">Referencias</h2>
<p><span class="citation" data-cites="digital-foundry-2020">(<a
href="#ref-digital-foundry-2020" role="doc-biblioref">Digital Foundry
2020</a>)</span>, <span class="citation" data-cites="nature-2016">(<a
href="#ref-nature-2016" role="doc-biblioref">Nature 2016</a>)</span>,
<span class="citation" data-cites="beck2001agile">(<a
href="#ref-beck2001agile" role="doc-biblioref">Beck et al.
2001</a>)</span>, <span class="citation" data-cites="merelo-2021">(<a
href="#ref-merelo-2021" role="doc-biblioref">Merelo 2021</a>)</span></p>
<h1 id="glosario-de-términos">Glosario de términos</h1>
<blockquote>
<p><em>It’s dangerous to go alone, take this.</em></p>
</blockquote>
<p>Tener en mente <em>todos</em> los conceptos y sus expresiones que
aparecen en un libro como este es prácticamente imposible. Tampoco hay
necesidad de ello, realmente. ¡Vaya desperdicio de cabeza! Por eso, aquí
tienes recopilada una lista con todos los elementos importantes y un
enlace a sus secciones correspondientes.</p>
<h2 id="notación">Notación</h2>
<table>
<colgroup>
<col style="width: 28%" />
<col style="width: 71%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Concepto</strong></th>
<th style="text-align: left;"><strong>Notación</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Puntos</strong></td>
<td style="text-align: left;">Letras mayúsculas: <span
class="math inline">\(P, Q, \dots\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Escalares</strong></td>
<td style="text-align: left;">Letras minúsculas: <span
class="math inline">\(a, b, c, k, \dots\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Vectores</strong></td>
<td style="text-align: left;">Letras minúsculas en negrita: <span
class="math inline">\(\mathbf{v, w, n}, \dots\)</span>. Si están
normalizados, se les pone gorrito (por ejemplo, <span
class="math inline">\(\hat{\mathbf{n}}\)</span>)</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Matrices</strong></td>
<td style="text-align: left;">Letras mayúsculas en negrita: <span
class="math inline">\(\mathbf{M}\)</span>. Por columnas.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Producto escalar</strong></td>
<td style="text-align: left;"><span class="math inline">\(\mathbf{v}
\cdot \mathbf{w}\)</span>. Si es el producto escalar de un vector
consigo mismo, a veces pondremos <span
class="math inline">\(\mathbf{v}^2\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Producto vectorial</strong></td>
<td style="text-align: left;"><span class="math inline">\(\mathbf{v}
\times \mathbf{w}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
href="#repaso-de-probabilidad"><strong>Variables
aleatorias</strong></a></td>
<td style="text-align: left;"><span class="math inline">\(X, Y\)</span>.
<span class="math inline">\(\xi\)</span> representa una variable
aleatoria con distribución uniforme en <span class="math inline">\([0,
1)\)</span>.</td>
</tr>
</tbody>
</table>
<h2 id="radiometría"><a href="#radiometría">Radiometría</a></h2>
<table>
<colgroup>
<col style="width: 17%" />
<col style="width: 82%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Concepto</strong></th>
<th style="text-align: left;"><strong>Expresiones</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><a href="#ángulos-sólidos"><strong>Ángulo
sólido</strong></a>, derivada [<a href="#eq:d_omega">4</a>]</td>
<td style="text-align: left;"><span
class="math inline">\(\begin{aligned} &amp;\omega = \frac{A}{r^2} \\
&amp; d\omega = \sin\theta\ d\theta\ d\phi\end{aligned}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Hemisferio de direcciones
alrededor de un vector</strong></td>
<td style="text-align: left;"><span
class="math inline">\(H^2(\mathbf{n})\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a href="#unidades-básicas"><strong>Carga
de energía</strong></a></td>
<td style="text-align: left;"><span class="math inline">\(Q = hf =
\frac{hc}{\lambda}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong><a href="#potencia">Flujo
radiante, potencia</a></strong></td>
<td style="text-align: left;"><span
class="math inline">\(\begin{aligned}&amp; \Phi = \frac{dQ}{dt} \\ &amp;
\Phi = \int_{A}\int_{H^2(\mathbf{n})}{L_o(p, \omega) d\omega^\bot
dA}\end{aligned}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong><a
href="#irradiancia">Irradiancia, radiancia emitida</a></strong></td>
<td style="text-align: left;"><span
class="math inline">\(\begin{aligned} &amp; E = \frac{\Phi}{A} \\ &amp;
E(p) = \frac{d\Phi}{dA} \\ &amp; E(p, \mathbf{n}) = \int_{\Omega}{L_i(p,
\omega) \lvert cos\theta \rvert d\omega} \\ &amp; E(p, \mathbf{n}) =
\int_{0}^{2\pi}\int_{0}^{\pi/2}{L_i(p, \theta, \phi) \cos\theta\
\sin\theta\ d\theta\ d\phi} \\ &amp; E(p, \mathbf{n}) =
\int_{A}{L\cos\theta\ \frac{\cos\theta_o}{r^2}dA}
\end{aligned}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong><a
href="#intensidad_radiante">Intensidad radiante</a></strong></td>
<td style="text-align: left;"><span
class="math inline">\(\begin{aligned}I =
\frac{d\Phi}{d\omega}\end{aligned}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong><a
href="#radiancia">Radiancia</a></strong></td>
<td style="text-align: left;"><span
class="math inline">\(\begin{aligned} &amp; L(p, \omega) =
\frac{dE_\omega(p)}{d\omega} \\ &amp; L(p, \omega) = \frac{d^2\Phi(p,
\omega)}{d\omega\ dA^\bot} = \frac{d^2\Phi(p, \omega)}{d\omega\ dA\
\cos\theta} \\ &amp; L^+(p, \omega) = \lim_{t \to 0^+}{L(p +
t\mathbf{n_p}, \omega)} \\ &amp; L^-(p, \omega) = \lim_{t \to 0^-}{L(p +
t\mathbf{n_p}, \omega)} \end{aligned}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong><a href="#radiancia">Radiancia
incidente</a></strong></td>
<td style="text-align: left;"><span
class="math inline">\(\begin{aligned} L_i(p, \omega) = \begin{cases}
L^+(p, -\omega) &amp; \text{si } \omega \cdot \mathbf{n_p} &gt; 0 \\
L^-(p, -\omega) &amp; \text{si } \omega \cdot \mathbf{n_p} &lt; 0
\end{cases}\end{aligned}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong><a href="#radiancia">Radiancia
reflejada, radiancia de salida</a></strong></td>
<td style="text-align: left;"><span
class="math inline">\(\begin{aligned} &amp; L_o(p, \omega) =
\begin{cases} L^+(p, \omega) &amp; \text{si } \omega \cdot \mathbf{n_p}
&gt; 0 \\ L^-(p, \omega) &amp; \text{si } \omega \cdot \mathbf{n_p} &lt;
0 \end{cases} \end{aligned}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong><a href="">Ecuación de
dispersión</a></strong></td>
<td style="text-align: left;"><span
class="math inline">\(\begin{aligned}L_o(p, \omega_o) =
\int_{\mathbb{S}^2}{f(p, \omega_o \leftarrow \omega_i)L_i(p,
\omega_i)\lvert \cos\theta_i \rvert
d\omega_i}\end{aligned}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong><a
href="#la-función-de-distribución-de-reflectancia-bidireccional-brdf">BRDF</a></strong></td>
<td style="text-align: left;"><span
class="math inline">\(\begin{aligned}&amp; f_r(p, \omega_o \leftarrow
\omega_i) = \frac{dL_o(p, \omega_o)}{dE(p, \omega_i)} = \frac{dL_o(p,
\omega_o)}{L_i(p, \omega_i) \cos\theta_i\
d\omega_i}\end{aligned}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong><a
href="#la-función-de-distribución-de-transmitancia-bidireccional-btdf">BTDF</a></strong></td>
<td style="text-align: left;"><span class="math inline">\(f_t(p,
\omega_o \leftarrow \omega_i)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong><a
href="#juntando-la-brdf-y-la-btdf">BSDF</a></strong></td>
<td style="text-align: left;"><span class="math inline">\(f(p, \omega_o
\leftarrow \omega_i)\)</span></td>
</tr>
</tbody>
</table>
<h1 class="unnumbered" id="bibliografía">Bibliografía</h1>
<div id="refs" class="references csl-bib-body hanging-indent"
role="doc-bibliography">
<div id="ref-Sarabia" class="csl-entry" role="doc-biblioentry">
A. Romero Sarabia. 2021. <em>Apuntes de La Asignatura Curvas y
Superficies</em>.
</div>
<div id="ref-arneback-2019" class="csl-entry" role="doc-biblioentry">
Arnebäck. 2019. <span>“An Explanation of the Rendering Equation.”</span>
January 10, 2019. <a
href="https://www.youtube.com/watch?v=eo_MTI-d28s">https://www.youtube.com/watch?v=eo_MTI-d28s</a>.
</div>
<div id="ref-beck2001agile" class="csl-entry" role="doc-biblioentry">
Beck, Kent, Mike Beedle, Arie van Bennekum, Alistair Cockburn, Ward
Cunningham, Martin Fowler, James Grenning, et al. 2001. <span>“Manifesto
for Agile Software Development.”</span> <a
href="http://www.agilemanifesto.org/">http://www.agilemanifesto.org/</a>.
</div>
<div id="ref-berkeley-cs184" class="csl-entry" role="doc-biblioentry">
Berkeley cs184. 2022. <span>“Monte Carlo Integration Cs184/284a.”</span>
2022. <a
href="https://cs184.eecs.berkeley.edu/sp22">https://cs184.eecs.berkeley.edu/sp22</a>.
</div>
<div id="ref-caulfield-2020" class="csl-entry" role="doc-biblioentry">
Caulfield, Brian. 2020. <span>“What’s the Difference Between Ray
Tracing, Rasterization?”</span> May 22, 2020. <a
href="https://blogs.nvidia.com/blog/2018/03/19/whats-difference-between-ray-tracing-rasterization/">https://blogs.nvidia.com/blog/2018/03/19/whats-difference-between-ray-tracing-rasterization/</a>.
</div>
<div id="ref-crytek-2020" class="csl-entry" role="doc-biblioentry">
Crytek. 2020. <span>“Crysis Remastered Brings Ray Tracing to Current-Gen
Consoles.”</span> September 11, 2020. <a
href="https://www.cryengine.com/news/view/crysis-remastered-brings-ray-tracing-to-current-gen-consoles">https://www.cryengine.com/news/view/crysis-remastered-brings-ray-tracing-to-current-gen-consoles</a>.
</div>
<div id="ref-digital-foundry-2020" class="csl-entry"
role="doc-biblioentry">
Digital Foundry. 2020. <span>“Cyberpunk 2077 PC: What Does Ray Tracing
Deliver... And Is It Worth It?”</span> December 19, 2020. <a
href="https://www.youtube.com/watch?v=6bqA8F6B6NQ">https://www.youtube.com/watch?v=6bqA8F6B6NQ</a>.
</div>
<div id="ref-Pellacini-Marschner-2017" class="csl-entry"
role="doc-biblioentry">
Fabio Pellacini, Steve Marschner. 2017. <span>“Fundamentals of Computer
Graphics.”</span> 2017. <a
href="https://pellacini.di.uniroma1.it/teaching/graphics17b/">https://pellacini.di.uniroma1.it/teaching/graphics17b/</a>.
</div>
<div id="ref-galvin-no-date" class="csl-entry" role="doc-biblioentry">
Galvin. n.d. <span>“Random Variables.”</span> Accessed March 20, 2022.
<a
href="https://www3.nd.edu/~dgalvin1/10120/10120_S16/Topic17_8p4_Galvin_class.pdf">https://www3.nd.edu/~dgalvin1/10120/10120_S16/Topic17_8p4_Galvin_class.pdf</a>.
</div>
<div id="ref-Haines2019" class="csl-entry" role="doc-biblioentry">
Haines, Eric, and Tomas Akenine-Möller, eds. 2019. <span>“Ray Tracing
Gems.”</span> Apress. 2019. <a
href="http://raytracinggems.com">http://raytracinggems.com</a>.
</div>
<div id="ref-merelo-2021" class="csl-entry" role="doc-biblioentry">
Merelo. 2021. <span>“Infraestructura Virtual.”</span> 2021. <a
href="http://jj.github.io/IV/documentos/temas/Integracion_continua">http://jj.github.io/IV/documentos/temas/Integracion_continua</a>.
</div>
<div id="ref-nature-2016" class="csl-entry" role="doc-biblioentry">
Nature. 2016. <span>“Scientific Language Is Becoming More
Informal.”</span> November 8, 2016. <a
href="https://doi.org/10.1038/539140a">https://doi.org/10.1038/539140a</a>.
</div>
<div id="ref-mcbook" class="csl-entry" role="doc-biblioentry">
Owen, Art B. 2013. <em>Monte Carlo Theory, Methods and Examples</em>. <a
href="https://artowen.su.domains/mc/">https://artowen.su.domains/mc/</a>.
</div>
<div id="ref-PBRT3e" class="csl-entry" role="doc-biblioentry">
Pharr, Matt, Wenzel Jakob, and Greg Humphreys. 2016. <span>“Physically
Based Rendering: From Theory to Implementation (3rd Ed.).”</span> San
Francisco, CA, USA: Morgan Kaufmann Publishers Inc. November 2016. <a
href="https://www.pbr-book.org/3ed-2018/contents">https://www.pbr-book.org/3ed-2018/contents</a>.
</div>
<div id="ref-quantumfracture-2021" class="csl-entry"
role="doc-biblioentry">
QuantumFracture. 2021. <span>“Ya, En Serio, ¿Qué Es La Luz?”</span>
December 10, 2021. <a
href="https://www.youtube.com/watch?v=DkcEAz09Buo">https://www.youtube.com/watch?v=DkcEAz09Buo</a>.
</div>
<div id="ref-unknown-author-no-date" class="csl-entry"
role="doc-biblioentry">
<span>“Rendering.”</span> n.d. Accessed March 20, 2022. <a
href="https://sciencebehindpixar.org/pipeline/rendering#:%7E:text=They%20said%20it%20takes%20at,to%20render%20that%20many%20frames">https://sciencebehindpixar.org/pipeline/rendering#:%7E:text=They%20said%20it%20takes%20at,to%20render%20that%20many%20frames</a>.
</div>
<div id="ref-scratchapixel-2019" class="csl-entry"
role="doc-biblioentry">
Scratchapixel. 2019. <span>“Learn Computer Graphics from
Scratch!”</span> 2019. <a
href="https://www.scratchapixel.com/index.php?redirect">https://www.scratchapixel.com/index.php?redirect</a>.
</div>
<div id="ref-Shirley2020RTW1" class="csl-entry" role="doc-biblioentry">
Shirley, Peter. 2020a. <span>“Ray Tracing in One Weekend.”</span> 2020.
<a
href="https://raytracing.github.io/books/RayTracingInOneWeekend.html">https://raytracing.github.io/books/RayTracingInOneWeekend.html</a>.
</div>
<div id="ref-Shirley2020RTW2" class="csl-entry" role="doc-biblioentry">
———. 2020b. <span>“Ray Tracing: The Next Week.”</span> 2020. <a
href="https://raytracing.github.io/books/RayTracingTheNextWeek.html">https://raytracing.github.io/books/RayTracingTheNextWeek.html</a>.
</div>
<div id="ref-Shirley2020RTW3" class="csl-entry" role="doc-biblioentry">
———. 2020c. <span>“Ray Tracing: The Rest of Your Life.”</span> 2020. <a
href="https://raytracing.github.io/books/RayTracingTheRestOfYourLife.html">https://raytracing.github.io/books/RayTracingTheRestOfYourLife.html</a>.
</div>
<div id="ref-ShirleyRRT" class="csl-entry" role="doc-biblioentry">
Shirley, Peter, and R. Keith Morley. 2003. <em>Realistic Ray
Tracing</em>. 2nd ed. USA: A. K. Peters, Ltd. <a
href="https://www.taylorfrancis.com/books/mono/10.1201/9780429294891/realistic-ray-tracing-peter-shirley-keith-morley">https://www.taylorfrancis.com/books/mono/10.1201/9780429294891/realistic-ray-tracing-peter-shirley-keith-morley</a>.
</div>
<div id="ref-studysession-2021" class="csl-entry"
role="doc-biblioentry">
StudySession. 2021. <span>“Solid Angle Derivation &amp;
Intuition.”</span> March 4, 2021. <a
href="https://www.youtube.com/watch?v=WrKsgBElPWA">https://www.youtube.com/watch?v=WrKsgBElPWA</a>.
</div>
<div id="ref-the-khronos-vulkan-working-group-2022" class="csl-entry"
role="doc-biblioentry">
The Khronos® Vulkan Working Group. 2022. <span>“Vulkan® 1.2.210 - KHR
Extensions: 33. Ray Intersection.”</span> March 29, 2022. <a
href="https://www.khronos.org/registry/vulkan/specs/1.2-khr-extensions/html/chap33.html#ray-intersection-candidate-determination">https://www.khronos.org/registry/vulkan/specs/1.2-khr-extensions/html/chap33.html#ray-intersection-candidate-determination</a>.
</div>
<div id="ref-wikipedia-contributors-2022E" class="csl-entry"
role="doc-biblioentry">
tracing, Wikipedia: Ray. 2022. <span>“Ray Tracing (Graphics).”</span>
March 7, 2022. <a
href="https://en.wikipedia.org/wiki/Ray_tracing_(graphics)">https://en.wikipedia.org/wiki/Ray_tracing_(graphics)</a>.
</div>
<div id="ref-wikipedia-contributors-2022G" class="csl-entry"
role="doc-biblioentry">
Wikipedia: Barycentric coordinate system. 2022. <span>“Barycentric
Coordinate System.”</span> March 14, 2022. <a
href="https://en.wikipedia.org/wiki/Barycentric_coordinate_system">https://en.wikipedia.org/wiki/Barycentric_coordinate_system</a>.
</div>
<div id="ref-wikipedia-contributors-2022C" class="csl-entry"
role="doc-biblioentry">
Wikipedia: Computer. 2022. <span>“Computer.”</span> March 13, 2022. <a
href="https://en.wikipedia.org/wiki/Computer">https://en.wikipedia.org/wiki/Computer</a>.
</div>
<div id="ref-wikipedia-contributors-2022O" class="csl-entry"
role="doc-biblioentry">
Wikipedia: Differential geometry of surfaces. 2022. <span>“Differential
Geometry of Surfaces.”</span> January 14, 2022. <a
href="https://en.wikipedia.org/wiki/Differential_geometry_of_surfaces">https://en.wikipedia.org/wiki/Differential_geometry_of_surfaces</a>.
</div>
<div id="ref-wikipedia-contributors-2022H" class="csl-entry"
role="doc-biblioentry">
Wikipedia: Distribución de probabilidad. 2022. <span>“Distribución de
Probabilidad.”</span> February 28, 2022. <a
href="https://es.wikipedia.org/wiki/Distribuci%C3%B3n_de_probabilidad">https://es.wikipedia.org/wiki/Distribuci%C3%B3n_de_probabilidad</a>.
</div>
<div id="ref-wikipedia-contributors-2022L" class="csl-entry"
role="doc-biblioentry">
Wikipedia: Estimador. 2022. <span>“Estimador.”</span> March 14, 2022. <a
href="https://es.wikipedia.org/wiki/Estimador?oldformat=true">https://es.wikipedia.org/wiki/Estimador?oldformat=true</a>.
</div>
<div id="ref-wikipedia-contributors-2022J" class="csl-entry"
role="doc-biblioentry">
Wikipedia: Expected value. 2022. <span>“Expected Value.”</span> March
14, 2022. <a
href="https://en.wikipedia.org/wiki/Expected_value">https://en.wikipedia.org/wiki/Expected_value</a>.
</div>
<div
id="ref-wikipedia-funcion-de-distribucion-de-reflectancia-bidireccional-2022"
class="csl-entry" role="doc-biblioentry">
Wikipedia: Función de distribución de reflectancia bidireccional. 2022.
<span>“Función de Distribución de Reflectancia Bidireccional.”</span>
January 28, 2022. <a
href="https://es.wikipedia.org/wiki/Funci%C3%B3n_de_distribuci%C3%B3n_de_reflectancia_bidireccional">https://es.wikipedia.org/wiki/Funci%C3%B3n_de_distribuci%C3%B3n_de_reflectancia_bidireccional</a>.
</div>
<div id="ref-wikipedia-contributors-2022I" class="csl-entry"
role="doc-biblioentry">
Wikipedia: Función de probabilidad. 2022. <span>“Función de
Probabilidad.”</span> February 10, 2022. <a
href="https://es.wikipedia.org/wiki/Funci%C3%B3n_de_probabilidad">https://es.wikipedia.org/wiki/Funci%C3%B3n_de_probabilidad</a>.
</div>
<div id="ref-wikipedia-contributors-2022A" class="csl-entry"
role="doc-biblioentry">
Wikipedia: history of photography. 2022. <span>“History of
Photography.”</span> March 18, 2022. <a
href="https://en.wikipedia.org/wiki/History_of_photography">https://en.wikipedia.org/wiki/History_of_photography</a>.
</div>
<div id="ref-wikipedia-contributors-2022F" class="csl-entry"
role="doc-biblioentry">
Wikipedia: Implicit surface. 2022. <span>“Implicit Surface.”</span>
March 13, 2022. <a
href="https://en.wikipedia.org/wiki/Implicit_surface">https://en.wikipedia.org/wiki/Implicit_surface</a>.
</div>
<div id="ref-wikipedia-contributors-2022B" class="csl-entry"
role="doc-biblioentry">
Wikipedia: Kodak. 2022. <span>“Kodak.”</span> March 14, 2022. <a
href="https://es.wikipedia.org/wiki/Kodak">https://es.wikipedia.org/wiki/Kodak</a>.
</div>
<div id="ref-wikipedia-contributors-2022M" class="csl-entry"
role="doc-biblioentry">
Wikipedia: Método de la transformada inversa. 2022. <span>“Método de La
Transformada Inversa.”</span> February 20, 2022. <a
href="https://es.wikipedia.org/wiki/M%C3%A9todo_de_la_transformada_inversa">https://es.wikipedia.org/wiki/M%C3%A9todo_de_la_transformada_inversa</a>.
</div>
<div id="ref-wikipedia-contributors-2021A" class="csl-entry"
role="doc-biblioentry">
Wikipedia: Parametric surface. 2021. <span>“Parametric Surface.”</span>
December 15, 2021. <a
href="https://en.wikipedia.org/wiki/Parametric_surface">https://en.wikipedia.org/wiki/Parametric_surface</a>.
</div>
<div id="ref-wikipedia-contributors-2022K" class="csl-entry"
role="doc-biblioentry">
Wikipedia: Probability density function. 2022. <span>“Probability
Density Function.”</span> March 17, 2022. <a
href="https://en.wikipedia.org/wiki/Probability_density_function">https://en.wikipedia.org/wiki/Probability_density_function</a>.
</div>
<div id="ref-wikipedia-contributors-2021D" class="csl-entry"
role="doc-biblioentry">
Wikipedia: Radiometry. 2021. <span>“Radiometry.”</span> September 12,
2021. <a
href="https://en.wikipedia.org/wiki/Radiometry">https://en.wikipedia.org/wiki/Radiometry</a>.
</div>
<div id="ref-wikipedia-contributors-2022N" class="csl-entry"
role="doc-biblioentry">
Wikipedia: Rejection sampling. 2022. <span>“Rejection Sampling.”</span>
February 4, 2022. <a
href="https://en.wikipedia.org/wiki/Rejection_sampling">https://en.wikipedia.org/wiki/Rejection_sampling</a>.
</div>
<div id="ref-wikipedia-contributors-2022D" class="csl-entry"
role="doc-biblioentry">
Wikipedia: rendering (computer graphics). 2022. <span>“Rendering
(Computer Graphics).”</span> March 8, 2022. <a
href="https://en.wikipedia.org/wiki/Rendering_(computer_graphics)">https://en.wikipedia.org/wiki/Rendering_(computer_graphics)</a>.
</div>
<div id="ref-wikipedia-contributors-2021B" class="csl-entry"
role="doc-biblioentry">
Wikipedia: Rendering equation. 2021. <span>“Rendering Equation.”</span>
March 9, 2021. <a
href="https://en.wikipedia.org/wiki/Rendering_equation">https://en.wikipedia.org/wiki/Rendering_equation</a>.
</div>
<div id="ref-wikipedia-transmittance-2021" class="csl-entry"
role="doc-biblioentry">
Wikipedia: Transmittance. 2021. <span>“Transmittance.”</span> January 3,
2021. <a
href="https://en.wikipedia.org/wiki/Transmittance">https://en.wikipedia.org/wiki/Transmittance</a>.
</div>
<div id="ref-wikipedia-contributors-2021C" class="csl-entry"
role="doc-biblioentry">
Wikipedia: Variable aleatoria. 2021. <span>“Variable Aleatoria.”</span>
August 30, 2021. <a
href="https://es.wikipedia.org/wiki/Variable_aleatoria">https://es.wikipedia.org/wiki/Variable_aleatoria</a>.
</div>
</div>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>En su defecto, si tenemos una función
de densidad <span class="math inline">\(f_X\)</span>, podemos hallar la
función de distribución haciendo <span class="math inline">\(F_X(x) =
P[X &lt; x] = \int_{x_{min}}^{x}{f_X(t)dt}\)</span><a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>No entraremos en detalle sobre la
naturaleza de la luz. Sin embargo, si te pica la curiosidad, hay muchos
divulgadores como <span class="citation"
data-cites="quantumfracture-2021">(<a href="#ref-quantumfracture-2021"
role="doc-biblioref">QuantumFracture 2021</a>)</span> que han tratado el
tema con suficiente profundidad.<a href="#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>Recuerda que estamos omitiendo la
longitud de onda <span class="math inline">\(\lambda\)</span>.<a
href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>Esto no es del todo cierto. Aunque
generalmente suelen ser excepciones debido al coste computacional de RT
en tiempo real, existen algunas implementaciones que son capaces de
correrlo por software. Notablemente, el motor de Crytek, CryEngine, es
capaz de mover ray tracing basado en hardware y en software <span
class="citation" data-cites="crytek-2020">(<a href="#ref-crytek-2020"
role="doc-biblioref">Crytek 2020</a>)</span><a href="#fnref4"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>Afortunadamente, esto tampoco es
completamente cierto. La compañía desarrolladora y distribuidora de
videojuegos Valve Corporation ha creado una pieza de software
fascinante: <a
href="https://github.com/ValveSoftware/Proton">Proton</a>. Proton
utiliza Wine para emular software en Linux que solo puede correr en
plataformas Windows. La versión 2.5 añadió soporte para traducción de
bindings de DXR a KHR, lo que permite utilizar DirectX12 ray tracing en
sistemas basados en Linux. El motivo de este software es expandir el
mercado de videojuegos disponibles en su consola, la Steam Deck.<a
href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
