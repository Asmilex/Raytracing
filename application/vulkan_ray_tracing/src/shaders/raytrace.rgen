#version 460
#extension GL_EXT_ray_tracing : require
#extension GL_GOOGLE_include_directive : enable
#extension GL_EXT_shader_explicit_arithmetic_types_int64 : require

#include "globals.glsl"
#include "host_device.h"
#include "random.glsl"

layout(location = 0) rayPayloadEXT HitPayload prd;

layout(set = 0, binding = eTlas) uniform accelerationStructureEXT topLevelAS;
layout(set = 0, binding = eOutImage, rgba32f) uniform image2D image;
layout(set = 1, binding = eGlobals) uniform _GlobalUniforms { GlobalUniforms uni; };
layout(push_constant) uniform _PushConstantRay { PushConstantRay pcRay; };

/*
    The buffer of camera uses binding = 0 (eGlobalsUniform) as described in host_device.h.
    The set = 1 comes from the fact that it is the second descriptor set passed to
    pipelineLayoutCreateInfo.pSetLayouts in HelloVulkan::createRtPipeline().
*/


void main()
{
    /*
        For a given value of m_maxFrames and NBSAMPLE,  the image will have
            m_maxFrames * NBSAMPLE
        antialiasing samples. For instance,
            m_maxFrames = 10 and NBSAMPLE = 10 == m_maxFrames = 100 and NBSAMPLE = 1.

        However, using NBSAMPLE = 10 in the ray generation shader will be faster
        than calling raytrace() with NBSAMPLE=1 10 times in a row.
    */

    ivec2 image_res    = ivec2(gl_LaunchSizeEXT.x, gl_LaunchSizeEXT.y);
    ivec2 image_coords = ivec2(gl_LaunchIDEXT.xy);

    prd.seed     = tea(image_coords.y * image_coords.x + image_coords.x, pcRay.frame);

    vec3 hit_value   = vec3(0);  // Para el frame actual
    vec3 pixel_color = vec3(0);  // El color final de la imagen



// ────────────────────────────────────── BUCLE CORRESPONDIENTE A UNA MUESTRA ─────

    for (int smpl = 0; smpl < pcRay.nb_samples; smpl++) {     // sample is a keyword, so we use smpl
        float r1 = rnd(prd.seed);
        float r2 = rnd(prd.seed);

        // Subpixel jitter: send the ray through a different position inside the pixel each time to provide antialiasing
        vec2 subpixel_jitter = pcRay.frame == 0
            ? vec2(0.5f, 0.5f)
            : vec2(r1, r2);

        const vec2 pixelCenter = vec2(image_coords.xy) + subpixel_jitter;
        const vec2 inUV        = pixelCenter/vec2(image_res.xy);
        vec2  d                = inUV * 2.0 - 1.0;

        vec4 origin    = uni.viewInverse * vec4(0, 0, 0, 1);
        vec4 target    = uni.projInverse * vec4(d.x, d.y, 1, 1);
        vec4 direction = uni.viewInverse * vec4(normalize(target.xyz), 0);

        uint rayFlags = gl_RayFlagsNoneEXT;
        float tMin = 0.001;
        float tMax = 10000.0;

        // Llamada a la generación del rayo.
        // Para saber por qué ponemos esos valores en sbtRecordOffset y sbtRecordStride, mira este artículo:
        // https://www.willusher.io/graphics/2019/11/20/the-sbt-three-ways
        // (Y mira en general el capítulo 11 de nvpro tutorial que esto tiene mucha chicha)

        // Inicializar el payload correctamente
        prd.depth     = 0;
        prd.hit_value  = vec3(0);
        prd.ray_origin = origin.xyz;
        prd.ray_dir    = direction.xyz;
        prd.weight    = vec3(0);
        //prd.attenuation = vec3(1.f, 1.f, 1.f);    // No debería ser necesario con path tracing
        // seed ya estaba puesto

        vec3 current_weight = vec3(1);
             hit_value       = vec3(0);

        // Con este bucle evitamos generar rayos desde el closest hit
        for (; prd.depth < pcRay.max_depth; prd.depth++) {
            // Cada vez que impactemos con algo, se actualizará el origen y la nueva dirección.
            // Dependerá del closest hit poner los parámetros de impacto correctos.
            traceRayEXT(topLevelAS, // acceleration structure
                rayFlags,       // rayFlags
                0xFF,           // cullMask
                0,              // sbtRecordOffset
                0,              // sbtRecordStride
                0,              // missIndex
                prd.ray_origin,  // ray origin
                tMin,           // ray min range
                prd.ray_dir,     // ray direction
                tMax,           // ray max range
                0               // payload (location = 0)
            );

            // A partir de aquí, debemos determinar el color que vaya adquiriendo.
            hit_value += prd.hit_value * current_weight;
            current_weight *= prd.weight;
        }

        pixel_color += hit_value;
    }

// ──────────────────────────────────────────────────────── FIN DE LA MUESTRA ─────

    // Tenemos varios frames acumulados en pixel_color -> dividimos por el número de samples
    // para obtener el frame resultante.
    pixel_color = pixel_color / pcRay.nb_samples;

    if (pcRay.frame > 0) {
        vec3 old_color = imageLoad(image, image_coords).xyz;
        vec3 new_result = mix(
            old_color,
            pixel_color,
            1.f / float(pcRay.frame + 1)
        );

        imageStore(image, image_coords, vec4(new_result, 1.f));
    }
    else {
        imageStore(image, image_coords, vec4(pixel_color, 1.0));
    }
}
